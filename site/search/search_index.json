{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Engineering Playbook Un ingeniero que trabaja en un proyecto del CoE... Tiene responsabilidades para con su equipo: mentor, coach y l\u00edder. Conoce su playbook . Sigue su playbook. Corrige su playbook cuando encuentra alg\u00fan error. Si encuentran un playbook mejor, lo copia. Si alguien puede utilizar su playbook, lo comparte. Predica con el ejemplo. Modela los comportamientos que deseamos tanto interpersonal como t\u00e9cnicamente. Se esfuerza por comprender c\u00f3mo encaja su trabajo en un contexto m\u00e1s amplio y garantiza el resultado. Este es nuestro playbook. Todas las contribuciones son bienvenidas! Por favor, no dudes en enviar un pull request para participar. Por qu\u00e9 tener un playbook Para aumentar la eficiencia de los miembros del equipo y de todo el equipo en general. Para reducir el n\u00famero de errores y evitar las dificultades m\u00e1s comunes. Para esforzarse por ser mejores ingenieros y aprender de la experiencia compartida de otras personas. Checklist Siga la lista de comprobaci\u00f3n de los fundamentos de la ingenier\u00eda ! Estructura de un sprint La estructura de un sprint es un desglose de las secciones del playbook seg\u00fan la estructura de un sprint \u00e1gil. Gu\u00eda general Mantenga alta la vara de la calidad del c\u00f3digo. Valore la calidad y la precisi\u00f3n por encima de \"hacer el trabajo\". Trabaje con diligencia en lo \u00fanico importante. Como equipo distribuido, t\u00f3mate el tiempo necesario para compartir el contexto a trav\u00e9s de la wiki, los equipos y los \u00edtems del backlog. Haz que lo m\u00e1s sencillo funcione ahora. Construye menos funciones hoy, pero aseg\u00farate de que funcionan de forma incre\u00edble. Despu\u00e9s, a\u00f1ade m\u00e1s funciones ma\u00f1ana. Evita a\u00f1adir alcance a un elemento del backlog, en su lugar a\u00f1ade un nuevo elemento del backlog. Nuestro objetivo es ofrecer un valor incremental al cliente. Mant\u00e9n los detalles de los elementos del backlog actualizados para comunicar el estado de las cosas al resto de tu equipo. Informar de los problemas encontrados en el producto y proporcionar una retroalimentaci\u00f3n de ingenier\u00eda clara y repetible. Todos somos due\u00f1os de nuestro c\u00f3digo y cada uno de nosotros tiene la obligaci\u00f3n de hacer que todas las partes de la soluci\u00f3n sean excelentes. Fundamentos de ingenier\u00eda Desarrollo \u00e1gil Pruebas automatizadas Revisiones de c\u00f3digo Entrega continua (CD) Integraci\u00f3n continua (CI) Experiencia del desarrollador Documentaci\u00f3n Observabilidad Seguridad Control de versiones Fundamentos para \u00e1reas tecnol\u00f3gicas espec\u00edficas Fundamentos del aprendizaje autom\u00e1tico","title":"Engineering Playbook"},{"location":"#engineering-playbook","text":"Un ingeniero que trabaja en un proyecto del CoE... Tiene responsabilidades para con su equipo: mentor, coach y l\u00edder. Conoce su playbook . Sigue su playbook. Corrige su playbook cuando encuentra alg\u00fan error. Si encuentran un playbook mejor, lo copia. Si alguien puede utilizar su playbook, lo comparte. Predica con el ejemplo. Modela los comportamientos que deseamos tanto interpersonal como t\u00e9cnicamente. Se esfuerza por comprender c\u00f3mo encaja su trabajo en un contexto m\u00e1s amplio y garantiza el resultado. Este es nuestro playbook. Todas las contribuciones son bienvenidas! Por favor, no dudes en enviar un pull request para participar.","title":"Engineering Playbook"},{"location":"#por-que-tener-un-playbook","text":"Para aumentar la eficiencia de los miembros del equipo y de todo el equipo en general. Para reducir el n\u00famero de errores y evitar las dificultades m\u00e1s comunes. Para esforzarse por ser mejores ingenieros y aprender de la experiencia compartida de otras personas.","title":"Por qu\u00e9 tener un playbook"},{"location":"#checklist","text":"Siga la lista de comprobaci\u00f3n de los fundamentos de la ingenier\u00eda !","title":"Checklist"},{"location":"#estructura-de-un-sprint","text":"La estructura de un sprint es un desglose de las secciones del playbook seg\u00fan la estructura de un sprint \u00e1gil.","title":"Estructura de un sprint"},{"location":"#guia-general","text":"Mantenga alta la vara de la calidad del c\u00f3digo. Valore la calidad y la precisi\u00f3n por encima de \"hacer el trabajo\". Trabaje con diligencia en lo \u00fanico importante. Como equipo distribuido, t\u00f3mate el tiempo necesario para compartir el contexto a trav\u00e9s de la wiki, los equipos y los \u00edtems del backlog. Haz que lo m\u00e1s sencillo funcione ahora. Construye menos funciones hoy, pero aseg\u00farate de que funcionan de forma incre\u00edble. Despu\u00e9s, a\u00f1ade m\u00e1s funciones ma\u00f1ana. Evita a\u00f1adir alcance a un elemento del backlog, en su lugar a\u00f1ade un nuevo elemento del backlog. Nuestro objetivo es ofrecer un valor incremental al cliente. Mant\u00e9n los detalles de los elementos del backlog actualizados para comunicar el estado de las cosas al resto de tu equipo. Informar de los problemas encontrados en el producto y proporcionar una retroalimentaci\u00f3n de ingenier\u00eda clara y repetible. Todos somos due\u00f1os de nuestro c\u00f3digo y cada uno de nosotros tiene la obligaci\u00f3n de hacer que todas las partes de la soluci\u00f3n sean excelentes.","title":"Gu\u00eda general"},{"location":"#fundamentos-de-ingenieria","text":"Desarrollo \u00e1gil Pruebas automatizadas Revisiones de c\u00f3digo Entrega continua (CD) Integraci\u00f3n continua (CI) Experiencia del desarrollador Documentaci\u00f3n Observabilidad Seguridad Control de versiones","title":"Fundamentos de ingenier\u00eda"},{"location":"#fundamentos-para-areas-tecnologicas-especificas","text":"Fundamentos del aprendizaje autom\u00e1tico","title":"Fundamentos para \u00e1reas tecnol\u00f3gicas espec\u00edficas"},{"location":"eng-fundamentals-checklist/","text":"Checklist de los fundamentos de la ingenier\u00eda Esta checklist ayuda a garantizar que nuestros proyectos cumplen con nuestros fundamentos de ingenier\u00eda. Control del c\u00f3digo fuente La rama principal est\u00e1 bloqueada. Las fusiones se realizan a trav\u00e9s de PRs. Los PRs hacen referencia a elementos de trabajo relacionados. El historial de commit es consistente y los mensajes de commit son informativos. Convenciones de nomenclatura de ramas consistentes. Documentaci\u00f3n clara de la estructura del repositorio. Los secretos no forman parte del historial de confirmaciones ni se hacen p\u00fablicos. M\u00e1s detalles sobre el control de c\u00f3digo fuente Seguimiento de elementos de trabajo Todos los elementos se registran en Azure DevOps (o similar). El tablero est\u00e1 organizado (swim lanes, feature tags, technology tags). M\u00e1s detalles sobre la gesti\u00f3n del backlog Testing Las pruebas unitarias cubren la mayor\u00eda de los componentes (>90% si es posible). Las pruebas de integraci\u00f3n se ejecutan para probar la soluci\u00f3n e2e. M\u00e1s detalles sobre las pruebas automatizadas CI/CD El proyecto ejecuta CI con construcci\u00f3n y pruebas automatizadas en cada PR. El proyecto utiliza CD para gestionar los despliegues en un entorno de r\u00e9plica antes de fusionar los PR. La rama principal siempre est\u00e1 disponible. M\u00e1s detalles sobre la integraci\u00f3n y entrega continua Seguridad El acceso s\u00f3lo se concede en funci\u00f3n de las necesidades Los secretos se almacenan en lugares seguros y no se registran en el c\u00f3digo Los datos se cifran en tr\u00e1nsito y en reposo y las contrase\u00f1as se codifican. \u00bfEst\u00e1 el sistema dividido en segmentos l\u00f3gicos con separaci\u00f3n de intereses? Esto ayuda a limitar las vulnerabilidades de seguridad. M\u00e1s detalles sobre la seguridad Observabilidad Los eventos funcionales y de negocio significativos se rastrean y se recogen las m\u00e9tricas relacionadas. Se registran los fallos y errores de la aplicaci\u00f3n. Se supervisa la salud del sistema. Los datos de observabilidad del lado del cliente y del servidor pueden diferenciarse. La configuraci\u00f3n del log puede modificarse sin necesidad de cambiar el c\u00f3digo. El contexto del tracing entrante se propaga para permitir la depuraci\u00f3n de problemas de producci\u00f3n. M\u00e1s detalles sobre la observabilidad Agilidad/Scrum El l\u00edder del proceso (fijo/rotativo) dirige el standup diario El proceso \u00e1gil est\u00e1 claramente definido dentro del equipo. El Dev Lead (+ PO/Otros) es responsable de la gesti\u00f3n y el refinamiento del backlog. Se establece un acuerdo de trabajo entre los miembros del equipo y el cliente. M\u00e1s detalles sobre el desarrollo \u00e1gil Revisiones del c\u00f3digo Existe un acuerdo claro en el equipo sobre la funci\u00f3n de las revisiones de c\u00f3digo. El equipo tiene una checklist de la revisi\u00f3n del c\u00f3digo o un proceso establecido. Un n\u00famero m\u00ednimo de revisores (normalmente 2) para una fusi\u00f3n de PR se hace cumplir por pol\u00edtica. Se establecen linters/analizadores de c\u00f3digo, pruebas unitarias y compilaciones exitosas para las fusiones de PR. Hay un proceso para imponer una revisi\u00f3n r\u00e1pida. M\u00e1s detalles sobre las revisiones de c\u00f3digo Retrospectivas Las retrospectivas se realizan al final de cada sprint. El equipo identifica de 1 a 3 experimentos propuestos para probar cada sprint para mejorar el proceso. Los experimentos tienen propietarios y se a\u00f1aden al backlog del proyecto. El equipo lleva a cabo una retrospectiva m\u00e1s larga para los hitos y la finalizaci\u00f3n del proyecto. M\u00e1s detalles sobre las retrospectivas Experiencia del desarrollador (DevEx) Los desarrolladores del equipo pueden Construir/Compilar el c\u00f3digo fuente para verificar que no tiene errores de sintaxis y que se compila. Ejecutar todas las pruebas automatizadas. Iniciar el lanzamiento de extremo a extremo para simular la ejecuci\u00f3n en un entorno desplegado. Adjuntar un depurador a la soluci\u00f3n iniciada o a las pruebas automatizadas en ejecuci\u00f3n, establecer puntos de interrupci\u00f3n, recorrer el c\u00f3digo e inspeccionar las variables. Instalar autom\u00e1ticamente las dependencias en su IDE. Utilizar los valores de configuraci\u00f3n locales de dev. M\u00e1s detalles sobre la experiencia del desarrollador","title":"Checklist de los fundamentos de la ingenier\u00eda"},{"location":"eng-fundamentals-checklist/#checklist-de-los-fundamentos-de-la-ingenieria","text":"Esta checklist ayuda a garantizar que nuestros proyectos cumplen con nuestros fundamentos de ingenier\u00eda.","title":"Checklist de los fundamentos de la ingenier\u00eda"},{"location":"eng-fundamentals-checklist/#control-del-codigo-fuente","text":"La rama principal est\u00e1 bloqueada. Las fusiones se realizan a trav\u00e9s de PRs. Los PRs hacen referencia a elementos de trabajo relacionados. El historial de commit es consistente y los mensajes de commit son informativos. Convenciones de nomenclatura de ramas consistentes. Documentaci\u00f3n clara de la estructura del repositorio. Los secretos no forman parte del historial de confirmaciones ni se hacen p\u00fablicos. M\u00e1s detalles sobre el control de c\u00f3digo fuente","title":"Control del c\u00f3digo fuente"},{"location":"eng-fundamentals-checklist/#seguimiento-de-elementos-de-trabajo","text":"Todos los elementos se registran en Azure DevOps (o similar). El tablero est\u00e1 organizado (swim lanes, feature tags, technology tags). M\u00e1s detalles sobre la gesti\u00f3n del backlog","title":"Seguimiento de elementos de trabajo"},{"location":"eng-fundamentals-checklist/#testing","text":"Las pruebas unitarias cubren la mayor\u00eda de los componentes (>90% si es posible). Las pruebas de integraci\u00f3n se ejecutan para probar la soluci\u00f3n e2e. M\u00e1s detalles sobre las pruebas automatizadas","title":"Testing"},{"location":"eng-fundamentals-checklist/#cicd","text":"El proyecto ejecuta CI con construcci\u00f3n y pruebas automatizadas en cada PR. El proyecto utiliza CD para gestionar los despliegues en un entorno de r\u00e9plica antes de fusionar los PR. La rama principal siempre est\u00e1 disponible. M\u00e1s detalles sobre la integraci\u00f3n y entrega continua","title":"CI/CD"},{"location":"eng-fundamentals-checklist/#seguridad","text":"El acceso s\u00f3lo se concede en funci\u00f3n de las necesidades Los secretos se almacenan en lugares seguros y no se registran en el c\u00f3digo Los datos se cifran en tr\u00e1nsito y en reposo y las contrase\u00f1as se codifican. \u00bfEst\u00e1 el sistema dividido en segmentos l\u00f3gicos con separaci\u00f3n de intereses? Esto ayuda a limitar las vulnerabilidades de seguridad. M\u00e1s detalles sobre la seguridad","title":"Seguridad"},{"location":"eng-fundamentals-checklist/#observabilidad","text":"Los eventos funcionales y de negocio significativos se rastrean y se recogen las m\u00e9tricas relacionadas. Se registran los fallos y errores de la aplicaci\u00f3n. Se supervisa la salud del sistema. Los datos de observabilidad del lado del cliente y del servidor pueden diferenciarse. La configuraci\u00f3n del log puede modificarse sin necesidad de cambiar el c\u00f3digo. El contexto del tracing entrante se propaga para permitir la depuraci\u00f3n de problemas de producci\u00f3n. M\u00e1s detalles sobre la observabilidad","title":"Observabilidad"},{"location":"eng-fundamentals-checklist/#agilidadscrum","text":"El l\u00edder del proceso (fijo/rotativo) dirige el standup diario El proceso \u00e1gil est\u00e1 claramente definido dentro del equipo. El Dev Lead (+ PO/Otros) es responsable de la gesti\u00f3n y el refinamiento del backlog. Se establece un acuerdo de trabajo entre los miembros del equipo y el cliente. M\u00e1s detalles sobre el desarrollo \u00e1gil","title":"Agilidad/Scrum"},{"location":"eng-fundamentals-checklist/#revisiones-del-codigo","text":"Existe un acuerdo claro en el equipo sobre la funci\u00f3n de las revisiones de c\u00f3digo. El equipo tiene una checklist de la revisi\u00f3n del c\u00f3digo o un proceso establecido. Un n\u00famero m\u00ednimo de revisores (normalmente 2) para una fusi\u00f3n de PR se hace cumplir por pol\u00edtica. Se establecen linters/analizadores de c\u00f3digo, pruebas unitarias y compilaciones exitosas para las fusiones de PR. Hay un proceso para imponer una revisi\u00f3n r\u00e1pida. M\u00e1s detalles sobre las revisiones de c\u00f3digo","title":"Revisiones del c\u00f3digo"},{"location":"eng-fundamentals-checklist/#retrospectivas","text":"Las retrospectivas se realizan al final de cada sprint. El equipo identifica de 1 a 3 experimentos propuestos para probar cada sprint para mejorar el proceso. Los experimentos tienen propietarios y se a\u00f1aden al backlog del proyecto. El equipo lleva a cabo una retrospectiva m\u00e1s larga para los hitos y la finalizaci\u00f3n del proyecto. M\u00e1s detalles sobre las retrospectivas","title":"Retrospectivas"},{"location":"eng-fundamentals-checklist/#experiencia-del-desarrollador-devex","text":"Los desarrolladores del equipo pueden Construir/Compilar el c\u00f3digo fuente para verificar que no tiene errores de sintaxis y que se compila. Ejecutar todas las pruebas automatizadas. Iniciar el lanzamiento de extremo a extremo para simular la ejecuci\u00f3n en un entorno desplegado. Adjuntar un depurador a la soluci\u00f3n iniciada o a las pruebas automatizadas en ejecuci\u00f3n, establecer puntos de interrupci\u00f3n, recorrer el c\u00f3digo e inspeccionar las variables. Instalar autom\u00e1ticamente las dependencias en su IDE. Utilizar los valores de configuraci\u00f3n locales de dev. M\u00e1s detalles sobre la experiencia del desarrollador","title":"Experiencia del desarrollador (DevEx)"},{"location":"sprint-structure/","text":"Estructura de un Sprint El prop\u00f3sito de este documento es: Organizar el contenido en el playbook para una r\u00e1pida referencia y descubrimiento Proporcionar el contenido en una estructura l\u00f3gica que refleje el proceso de ingenier\u00eda Una jerarqu\u00eda extensible que permita a los equipos compartir conocimientos profundos sobre el tema La primera semana de un proyecto Antes de comenzar el proyecto Discutir y empezar a redactar los Acuerdos de Equipo. Actualice estos documentos con cualquier decisi\u00f3n de proceso tomada a lo largo del proyecto Acuerdo de trabajo Definici\u00f3n de Listo Definici\u00f3n de Hecho Estimaci\u00f3n Establecer el/los repositorio/s Decidir la estructura del repositorio A\u00f1adir README.md, .gitignore, etc. Construir un Backlog de Producto Configurar un proyecto en la herramienta de gesti\u00f3n de proyectos elegida (Azure DevOps) Invertir en buenas historias de usuario y criterios de aceptaci\u00f3n Gu\u00eda sobre los requisitos no funcionales D\u00eda 1 Planificar el primer sprint Acordar el objetivo del sprint y c\u00f3mo medir el progreso del mismo Determinar la capacidad del equipo Asignar historias de usuario al sprint y dividir las historias de usuario en tareas Establecer los l\u00edmites del trabajo en curso (WIP) Decidir los frameworks de test y discutir las estrategias de testeo Discutir el prop\u00f3sito y los objetivos de los tests y c\u00f3mo medir la cobertura de los mismos Acordar c\u00f3mo separar los tests unitarios de los de integraci\u00f3n, carga y humo Dise\u00f1ar los primeros casos de prueba Decidir la denominaci\u00f3n de las ramas Discutir las necesidades de seguridad y verificar que los secretos se mantienen fuera del control de origen D\u00eda 2 Configurar el control de c\u00f3digo fuente Acordar las mejores pr\u00e1cticas para los commits Configurar la integraci\u00f3n continua b\u00e1sica con linters y pruebas automatizadas Establecer reuniones para los Stand-ups diarios Discutir el prop\u00f3sito, los objetivos, los participantes y la gu\u00eda de facilitaci\u00f3n Discutir el calendario y c\u00f3mo llevar a cabo una reuni\u00f3n eficaz. Si el proyecto tiene subequipos, establecer un Scrum de Scrums D\u00eda 3 Acordar el estilo de c\u00f3digo y c\u00f3mo asignar los Pull Requests Establecer la validaci\u00f3n de la compilaci\u00f3n para los Pull Requests (2 revisores, linters, pruebas automatizadas) y acordar la definici\u00f3n de Hecho Acordar una estrategia de fusi\u00f3n de c\u00f3digo Acordar frameworks y estrategias de logging y observabilidad D\u00eda 4 Configurar el despliegue continuo Determinar qu\u00e9 entornos son apropiados para esta soluci\u00f3n Para cada entorno, discutir el prop\u00f3sito, cu\u00e1ndo debe activarse el despliegue, los aprobadores de predespliegue, la cancelaci\u00f3n del despliegue. Decidir una estrategia de versiones D\u00eda 5 Realizaci\u00f3n de una Demo del Sprint Realizar una retrospectiva Determinar los participantes necesarios, la forma de captar las aportaciones (herramientas) y los resultados Establecer un calendario y discutir la facilitaci\u00f3n, la estructura de la reuni\u00f3n, etc. Refinar el Backlog Determinar los participantes necesarios Actualizar la definici\u00f3n de \"listo\". Actualizar las estimaciones y el documento de estimaci\u00f3n","title":"Estructura de un Sprint"},{"location":"sprint-structure/#estructura-de-un-sprint","text":"El prop\u00f3sito de este documento es: Organizar el contenido en el playbook para una r\u00e1pida referencia y descubrimiento Proporcionar el contenido en una estructura l\u00f3gica que refleje el proceso de ingenier\u00eda Una jerarqu\u00eda extensible que permita a los equipos compartir conocimientos profundos sobre el tema","title":"Estructura de un Sprint"},{"location":"sprint-structure/#la-primera-semana-de-un-proyecto","text":"","title":"La primera semana de un proyecto"},{"location":"sprint-structure/#antes-de-comenzar-el-proyecto","text":"Discutir y empezar a redactar los Acuerdos de Equipo. Actualice estos documentos con cualquier decisi\u00f3n de proceso tomada a lo largo del proyecto Acuerdo de trabajo Definici\u00f3n de Listo Definici\u00f3n de Hecho Estimaci\u00f3n Establecer el/los repositorio/s Decidir la estructura del repositorio A\u00f1adir README.md, .gitignore, etc. Construir un Backlog de Producto Configurar un proyecto en la herramienta de gesti\u00f3n de proyectos elegida (Azure DevOps) Invertir en buenas historias de usuario y criterios de aceptaci\u00f3n Gu\u00eda sobre los requisitos no funcionales","title":"Antes de comenzar el proyecto"},{"location":"sprint-structure/#dia-1","text":"Planificar el primer sprint Acordar el objetivo del sprint y c\u00f3mo medir el progreso del mismo Determinar la capacidad del equipo Asignar historias de usuario al sprint y dividir las historias de usuario en tareas Establecer los l\u00edmites del trabajo en curso (WIP) Decidir los frameworks de test y discutir las estrategias de testeo Discutir el prop\u00f3sito y los objetivos de los tests y c\u00f3mo medir la cobertura de los mismos Acordar c\u00f3mo separar los tests unitarios de los de integraci\u00f3n, carga y humo Dise\u00f1ar los primeros casos de prueba Decidir la denominaci\u00f3n de las ramas Discutir las necesidades de seguridad y verificar que los secretos se mantienen fuera del control de origen","title":"D\u00eda 1"},{"location":"sprint-structure/#dia-2","text":"Configurar el control de c\u00f3digo fuente Acordar las mejores pr\u00e1cticas para los commits Configurar la integraci\u00f3n continua b\u00e1sica con linters y pruebas automatizadas Establecer reuniones para los Stand-ups diarios Discutir el prop\u00f3sito, los objetivos, los participantes y la gu\u00eda de facilitaci\u00f3n Discutir el calendario y c\u00f3mo llevar a cabo una reuni\u00f3n eficaz. Si el proyecto tiene subequipos, establecer un Scrum de Scrums","title":"D\u00eda 2"},{"location":"sprint-structure/#dia-3","text":"Acordar el estilo de c\u00f3digo y c\u00f3mo asignar los Pull Requests Establecer la validaci\u00f3n de la compilaci\u00f3n para los Pull Requests (2 revisores, linters, pruebas automatizadas) y acordar la definici\u00f3n de Hecho Acordar una estrategia de fusi\u00f3n de c\u00f3digo Acordar frameworks y estrategias de logging y observabilidad","title":"D\u00eda 3"},{"location":"sprint-structure/#dia-4","text":"Configurar el despliegue continuo Determinar qu\u00e9 entornos son apropiados para esta soluci\u00f3n Para cada entorno, discutir el prop\u00f3sito, cu\u00e1ndo debe activarse el despliegue, los aprobadores de predespliegue, la cancelaci\u00f3n del despliegue. Decidir una estrategia de versiones","title":"D\u00eda 4"},{"location":"sprint-structure/#dia-5","text":"Realizaci\u00f3n de una Demo del Sprint Realizar una retrospectiva Determinar los participantes necesarios, la forma de captar las aportaciones (herramientas) y los resultados Establecer un calendario y discutir la facilitaci\u00f3n, la estructura de la reuni\u00f3n, etc. Refinar el Backlog Determinar los participantes necesarios Actualizar la definici\u00f3n de \"listo\". Actualizar las estimaciones y el documento de estimaci\u00f3n","title":"D\u00eda 5"},{"location":"CI_CD/","text":"Integraci\u00f3n y entrega continuas La integraci\u00f3n continua es la pr\u00e1ctica de ingenier\u00eda que consiste en comitear frecuentemente el c\u00f3digo en un repositorio compartido, idealmente varias veces al d\u00eda, y realizar una compilaci\u00f3n automatizada sobre \u00e9l. Estos cambios se compilan con otros cambios simult\u00e1neos en el sistema, lo que permite la detecci\u00f3n temprana de problemas de integraci\u00f3n entre varios desarrolladores que trabajan en un proyecto. Las interrupciones de la compilaci\u00f3n debidas a fallos de integraci\u00f3n se tratan como el problema de mayor prioridad para todos los desarrolladores de un equipo y, por lo general, el trabajo se detiene hasta que se solucionan. Junto con un enfoque de pruebas automatizadas, la integraci\u00f3n continua tambi\u00e9n nos permite probar la compilaci\u00f3n integrada, de modo que podamos verificar no s\u00f3lo que la base de c\u00f3digo sigue compilandose correctamente, sino que tambi\u00e9n sigue siendo funcionalmente correcta. Esta es tambi\u00e9n una de las mejores pr\u00e1cticas para construir sistemas de software robustos y flexibles. La entrega continua lleva el concepto de integraci\u00f3n continua m\u00e1s all\u00e1 para probar tambi\u00e9n los despliegues de la base de c\u00f3digo integrada en una r\u00e9plica del entorno en el que se desplegar\u00e1 finalmente. Esto nos permite conocer con antelaci\u00f3n cualquier problema imprevisto que surja de nuestros cambios con la mayor rapidez posible y tambi\u00e9n conocer las brechas en nuestra cobertura de pruebas. El objetivo de todo esto es asegurar que la rama principal sea siempre implementable, lo que significa que podr\u00edamos, si lo necesit\u00e1ramos, tomar una compilaci\u00f3n de la rama principal e implementarla en producci\u00f3n. Para reforzar estos conceptos puedes leer sobre la Integraci\u00f3n Continua y la Entrega Continua . Para una comprensi\u00f3n mucho m\u00e1s profunda de todos estos conceptos, los libros Continuous Integration y Continuous Delivery proporcionan una base completa. Herramientas Azure Pipelines Jenkins TravisCI CircleCI","title":"Integraci\u00f3n y entrega continuas"},{"location":"CI_CD/#integracion-y-entrega-continuas","text":"La integraci\u00f3n continua es la pr\u00e1ctica de ingenier\u00eda que consiste en comitear frecuentemente el c\u00f3digo en un repositorio compartido, idealmente varias veces al d\u00eda, y realizar una compilaci\u00f3n automatizada sobre \u00e9l. Estos cambios se compilan con otros cambios simult\u00e1neos en el sistema, lo que permite la detecci\u00f3n temprana de problemas de integraci\u00f3n entre varios desarrolladores que trabajan en un proyecto. Las interrupciones de la compilaci\u00f3n debidas a fallos de integraci\u00f3n se tratan como el problema de mayor prioridad para todos los desarrolladores de un equipo y, por lo general, el trabajo se detiene hasta que se solucionan. Junto con un enfoque de pruebas automatizadas, la integraci\u00f3n continua tambi\u00e9n nos permite probar la compilaci\u00f3n integrada, de modo que podamos verificar no s\u00f3lo que la base de c\u00f3digo sigue compilandose correctamente, sino que tambi\u00e9n sigue siendo funcionalmente correcta. Esta es tambi\u00e9n una de las mejores pr\u00e1cticas para construir sistemas de software robustos y flexibles. La entrega continua lleva el concepto de integraci\u00f3n continua m\u00e1s all\u00e1 para probar tambi\u00e9n los despliegues de la base de c\u00f3digo integrada en una r\u00e9plica del entorno en el que se desplegar\u00e1 finalmente. Esto nos permite conocer con antelaci\u00f3n cualquier problema imprevisto que surja de nuestros cambios con la mayor rapidez posible y tambi\u00e9n conocer las brechas en nuestra cobertura de pruebas. El objetivo de todo esto es asegurar que la rama principal sea siempre implementable, lo que significa que podr\u00edamos, si lo necesit\u00e1ramos, tomar una compilaci\u00f3n de la rama principal e implementarla en producci\u00f3n. Para reforzar estos conceptos puedes leer sobre la Integraci\u00f3n Continua y la Entrega Continua . Para una comprensi\u00f3n mucho m\u00e1s profunda de todos estos conceptos, los libros Continuous Integration y Continuous Delivery proporcionan una base completa.","title":"Integraci\u00f3n y entrega continuas"},{"location":"CI_CD/#herramientas","text":"Azure Pipelines Jenkins TravisCI CircleCI","title":"Herramientas"},{"location":"CI_CD/continuous-delivery/","text":"Continuous Delivery La inspiraci\u00f3n detr\u00e1s de la entrega continua es entregar constantemente software valioso a los usuarios con mayor frecuencia. La aplicaci\u00f3n de los principios y pr\u00e1cticas expuestos en este documento le ayudar\u00e1 a reducir el riesgo, eliminar las operaciones manuales y aumentar la calidad y la confianza. El despliegue de software implica los siguientes principios: Aprovisionar y gestionar el tiempo de ejecuci\u00f3n del entorno de la nube para su aplicaci\u00f3n. Instalar la versi\u00f3n de la aplicaci\u00f3n de destino en sus entornos de nube. Configurar su aplicaci\u00f3n, incluyendo los datos necesarios. Una canalizaci\u00f3n de entrega continua es una manifestaci\u00f3n automatizada de su proceso para agilizar estos mismos principios de forma coherente y repetible. Objetivo Seguir las mejores pr\u00e1cticas de la industria para entregar los cambios de software a los clientes. Establecer la coherencia de los principios rectores y las mejores pr\u00e1cticas al ensamblar flujos de trabajo de entrega continua. Gu\u00eda general Definir una estrategia de release Es importante establecer un entendimiento com\u00fan en torno a la estrategia/dise\u00f1o de release durante la fase de planificaci\u00f3n de un proyecto. Este entendimiento incluye el despliegue y el mantenimiento de la aplicaci\u00f3n a lo largo de su SDLC. Principios de la estrategia de release Continuous Delivery por Jez Humble, David Farley cubren las consideraciones clave a seguir cuando se crea una estrategia de release: Partes encargadas de los despliegues en cada entorno, as\u00ed como encargadas del release. Estrategia de gesti\u00f3n de activos y configuraci\u00f3n. Enumeraci\u00f3n de los entornos disponibles para las pruebas de aceptaci\u00f3n, capacidad, integraci\u00f3n y aceptaci\u00f3n por parte del usuario, as\u00ed como el proceso por el que se mover\u00e1n las compilaciones a trav\u00e9s de estos entornos. Descripci\u00f3n de los procesos que se seguir\u00e1n para el despliegue en los entornos de prueba y producci\u00f3n, como las solicitudes de cambio que se abrir\u00e1n y las aprobaciones que deben concederse. Descripci\u00f3n del m\u00e9todo por el que se gestionar\u00e1 la configuraci\u00f3n en tiempo de despliegue y de ejecuci\u00f3n de la aplicaci\u00f3n, y c\u00f3mo se relaciona esto con el proceso de despliegue automatizado. Descripci\u00f3n de la integraci\u00f3n con cualquier sistema externo. \u00bfEn qu\u00e9 fase y c\u00f3mo se prueban como parte de un release? \u00bfC\u00f3mo se comunica el operador t\u00e9cnico con el proveedor en caso de problema? Un plan de recuperaci\u00f3n de desastres para poder recuperar el estado de la aplicaci\u00f3n tras un desastre. \u00bfQu\u00e9 pasos habr\u00e1 que dar para reiniciar o volver a desplegar la aplicaci\u00f3n en caso de que falle? Planificaci\u00f3n del tama\u00f1o y la capacidad de producci\u00f3n: \u00bfCu\u00e1ntos datos crear\u00e1 su aplicaci\u00f3n en vivo? \u00bfCu\u00e1ntos archivos de log o bases de datos necesitar\u00e1? \u00bfCu\u00e1nto ancho de banda y espacio en disco necesitar\u00e1? \u00bfQu\u00e9 latencia esperan los clientes? C\u00f3mo funciona el despliegue inicial en producci\u00f3n. C\u00f3mo se gestionar\u00e1 la correcci\u00f3n de defectos y la aplicaci\u00f3n de parches en el entorno de producci\u00f3n. C\u00f3mo se gestionar\u00e1n las actualizaciones del entorno de producci\u00f3n, incluida la migraci\u00f3n de datos. C\u00f3mo se llevar\u00e1n a cabo las actualizaciones de la aplicaci\u00f3n sin destruir su estado. Release de la aplicaci\u00f3n y promoci\u00f3n del entorno Su proceso de release debe tomar el artefacto de compilaci\u00f3n desplegable creado desde su etapa de commit y desplegarlo en todos los entornos de la nube, comenzando con su entorno de test. El entorno de test act\u00faa como una puerta para validar si su conjunto de pruebas se completa con \u00e9xito. Esta validaci\u00f3n siempre debe comenzar en un entorno de prueba mientras se inspecciona la versi\u00f3n desplegada integrada desde la rama de features / release que contiene sus cambios de c\u00f3digo. Los cambios de c\u00f3digo liberados en el entorno de pruebas suelen tener como objetivo la rama principal o la rama de release. El primer despliegue El primer despliegue de cualquier aplicaci\u00f3n debe mostrarse al cliente en un entorno similar al de producci\u00f3n (UAT) para solicitar su opini\u00f3n desde el principio. El entorno de UAT se utiliza para obtener la aceptaci\u00f3n del propietario del producto y, en \u00faltima instancia, promover el release a producci\u00f3n. Criterios para un entorno similar al de producci\u00f3n Ejecuta el mismo sistema operativo que producci\u00f3n. Tiene instalado el mismo software que producci\u00f3n. Tiene el mismo tama\u00f1o y configuraci\u00f3n que producci\u00f3n. Refleja la topolog\u00eda de red de producci\u00f3n. Se ejecutan pruebas de carga simuladas similares a las de producci\u00f3n despu\u00e9s de un release para hacer visible cualquier degradaci\u00f3n de la latencia o el rendimiento. Modelado del pipeline de release Es fundamental modelar su proceso de prueba y release para establecer un entendimiento com\u00fan entre los ingenieros de aplicaciones y las partes interesadas del cliente. Espec\u00edficamente, alinear las expectativas de cu\u00e1ntos entornos de nube deben ser pre-aprovisionados, as\u00ed como definir las funciones y responsabilidades. Etapas del pipeline de release El pipeline de release debe tener en cuenta las siguientes condiciones: Selecci\u00f3n del release: El desarrollador que lleva a cabo las pruebas de la aplicaci\u00f3n debe tener la capacidad de seleccionar la versi\u00f3n de release que va a desplegar en el entorno de test. Despliegue: liberar el artefacto de compilaci\u00f3n desplegable de la aplicaci\u00f3n en el entorno de nube de destino. Configuraci\u00f3n: Las aplicaciones deben ser configuradas de forma consistente en todos sus entornos. Esta configuraci\u00f3n se aplica en el momento del despliegue. Los datos confidenciales, como los secretos y certificados de la aplicaci\u00f3n, deben estar guardados en un almac\u00e9n de claves y secretos de PaaS totalmente gestionado. Todos los secretos utilizados por la aplicaci\u00f3n deben obtenerse internamente dentro de la propia aplicaci\u00f3n. Los secretos no deber\u00edan estar expuestos dentro del entorno de ejecuci\u00f3n. Migraci\u00f3n de datos: Prepueble el estado de la aplicaci\u00f3n y/o los registros de datos que se necesitan para su entorno de tiempo de ejecuci\u00f3n. Esto tambi\u00e9n puede incluir los datos de prueba necesarios para su conjunto de pruebas de integraci\u00f3n. Prueba de humo de despliegue. Su prueba de humo tambi\u00e9n debe verificar que su aplicaci\u00f3n est\u00e1 apuntando a la configuraci\u00f3n correcta. Realice cualquier escenario de prueba de aceptaci\u00f3n manual o automatizada. Apruebe la puerta de release para promover la versi\u00f3n de la aplicaci\u00f3n al entorno de la nube de destino. Releases de preproducci\u00f3n Las aplicaciones candidatas deben desplegarse en un entorno similar al de producci\u00f3n para llevar a cabo las pruebas finales manuales/automatizadas (incluidas las pruebas de capacidad). Reversi\u00f3n de releases Su estrategia de release debe tener en cuenta los escenarios de reversi\u00f3n en caso de fallos inesperados despu\u00e9s de un despliegue. La reversi\u00f3n de releases puede ser complicada. Si no hay cambios en los datos que deban ser revertidos, entonces puede simplemente activar un nuevo release candidato para la \u00faltima versi\u00f3n de producci\u00f3n conocida y promover ese release a lo largo de su pipeline de CD. Referencias Entrega continua por Jez Humble, David Farley. Integraci\u00f3n continua vs. entrega continua vs. despliegue continuo Anillos de despliegue Herramientas Flux para gitops Flujo de trabajo CI/CD usando GitOps Tekton para pipelines nativos de Kubernetes Argo Workflows Flagger para potentes lanzamientos nativos de Kubernetes, incluyendo blue/green, canary y A/B testing. No est\u00e1 muy relacionado con Kubernetes, pero echa un vistazo a jsonnet , un lenguaje de plantillas para reducir la repetici\u00f3n de tareas y aumentar el intercambio entre sus manifiestos yaml/json.","title":"Continuous Delivery"},{"location":"CI_CD/continuous-delivery/#continuous-delivery","text":"La inspiraci\u00f3n detr\u00e1s de la entrega continua es entregar constantemente software valioso a los usuarios con mayor frecuencia. La aplicaci\u00f3n de los principios y pr\u00e1cticas expuestos en este documento le ayudar\u00e1 a reducir el riesgo, eliminar las operaciones manuales y aumentar la calidad y la confianza. El despliegue de software implica los siguientes principios: Aprovisionar y gestionar el tiempo de ejecuci\u00f3n del entorno de la nube para su aplicaci\u00f3n. Instalar la versi\u00f3n de la aplicaci\u00f3n de destino en sus entornos de nube. Configurar su aplicaci\u00f3n, incluyendo los datos necesarios. Una canalizaci\u00f3n de entrega continua es una manifestaci\u00f3n automatizada de su proceso para agilizar estos mismos principios de forma coherente y repetible.","title":"Continuous Delivery"},{"location":"CI_CD/continuous-delivery/#objetivo","text":"Seguir las mejores pr\u00e1cticas de la industria para entregar los cambios de software a los clientes. Establecer la coherencia de los principios rectores y las mejores pr\u00e1cticas al ensamblar flujos de trabajo de entrega continua.","title":"Objetivo"},{"location":"CI_CD/continuous-delivery/#guia-general","text":"","title":"Gu\u00eda general"},{"location":"CI_CD/continuous-delivery/#definir-una-estrategia-de-release","text":"Es importante establecer un entendimiento com\u00fan en torno a la estrategia/dise\u00f1o de release durante la fase de planificaci\u00f3n de un proyecto. Este entendimiento incluye el despliegue y el mantenimiento de la aplicaci\u00f3n a lo largo de su SDLC.","title":"Definir una estrategia de release"},{"location":"CI_CD/continuous-delivery/#principios-de-la-estrategia-de-release","text":"Continuous Delivery por Jez Humble, David Farley cubren las consideraciones clave a seguir cuando se crea una estrategia de release: Partes encargadas de los despliegues en cada entorno, as\u00ed como encargadas del release. Estrategia de gesti\u00f3n de activos y configuraci\u00f3n. Enumeraci\u00f3n de los entornos disponibles para las pruebas de aceptaci\u00f3n, capacidad, integraci\u00f3n y aceptaci\u00f3n por parte del usuario, as\u00ed como el proceso por el que se mover\u00e1n las compilaciones a trav\u00e9s de estos entornos. Descripci\u00f3n de los procesos que se seguir\u00e1n para el despliegue en los entornos de prueba y producci\u00f3n, como las solicitudes de cambio que se abrir\u00e1n y las aprobaciones que deben concederse. Descripci\u00f3n del m\u00e9todo por el que se gestionar\u00e1 la configuraci\u00f3n en tiempo de despliegue y de ejecuci\u00f3n de la aplicaci\u00f3n, y c\u00f3mo se relaciona esto con el proceso de despliegue automatizado. Descripci\u00f3n de la integraci\u00f3n con cualquier sistema externo. \u00bfEn qu\u00e9 fase y c\u00f3mo se prueban como parte de un release? \u00bfC\u00f3mo se comunica el operador t\u00e9cnico con el proveedor en caso de problema? Un plan de recuperaci\u00f3n de desastres para poder recuperar el estado de la aplicaci\u00f3n tras un desastre. \u00bfQu\u00e9 pasos habr\u00e1 que dar para reiniciar o volver a desplegar la aplicaci\u00f3n en caso de que falle? Planificaci\u00f3n del tama\u00f1o y la capacidad de producci\u00f3n: \u00bfCu\u00e1ntos datos crear\u00e1 su aplicaci\u00f3n en vivo? \u00bfCu\u00e1ntos archivos de log o bases de datos necesitar\u00e1? \u00bfCu\u00e1nto ancho de banda y espacio en disco necesitar\u00e1? \u00bfQu\u00e9 latencia esperan los clientes? C\u00f3mo funciona el despliegue inicial en producci\u00f3n. C\u00f3mo se gestionar\u00e1 la correcci\u00f3n de defectos y la aplicaci\u00f3n de parches en el entorno de producci\u00f3n. C\u00f3mo se gestionar\u00e1n las actualizaciones del entorno de producci\u00f3n, incluida la migraci\u00f3n de datos. C\u00f3mo se llevar\u00e1n a cabo las actualizaciones de la aplicaci\u00f3n sin destruir su estado.","title":"Principios de la estrategia de release"},{"location":"CI_CD/continuous-delivery/#release-de-la-aplicacion-y-promocion-del-entorno","text":"Su proceso de release debe tomar el artefacto de compilaci\u00f3n desplegable creado desde su etapa de commit y desplegarlo en todos los entornos de la nube, comenzando con su entorno de test. El entorno de test act\u00faa como una puerta para validar si su conjunto de pruebas se completa con \u00e9xito. Esta validaci\u00f3n siempre debe comenzar en un entorno de prueba mientras se inspecciona la versi\u00f3n desplegada integrada desde la rama de features / release que contiene sus cambios de c\u00f3digo. Los cambios de c\u00f3digo liberados en el entorno de pruebas suelen tener como objetivo la rama principal o la rama de release.","title":"Release de la aplicaci\u00f3n y promoci\u00f3n del entorno"},{"location":"CI_CD/continuous-delivery/#el-primer-despliegue","text":"El primer despliegue de cualquier aplicaci\u00f3n debe mostrarse al cliente en un entorno similar al de producci\u00f3n (UAT) para solicitar su opini\u00f3n desde el principio. El entorno de UAT se utiliza para obtener la aceptaci\u00f3n del propietario del producto y, en \u00faltima instancia, promover el release a producci\u00f3n.","title":"El primer despliegue"},{"location":"CI_CD/continuous-delivery/#criterios-para-un-entorno-similar-al-de-produccion","text":"Ejecuta el mismo sistema operativo que producci\u00f3n. Tiene instalado el mismo software que producci\u00f3n. Tiene el mismo tama\u00f1o y configuraci\u00f3n que producci\u00f3n. Refleja la topolog\u00eda de red de producci\u00f3n. Se ejecutan pruebas de carga simuladas similares a las de producci\u00f3n despu\u00e9s de un release para hacer visible cualquier degradaci\u00f3n de la latencia o el rendimiento.","title":"Criterios para un entorno similar al de producci\u00f3n"},{"location":"CI_CD/continuous-delivery/#modelado-del-pipeline-de-release","text":"Es fundamental modelar su proceso de prueba y release para establecer un entendimiento com\u00fan entre los ingenieros de aplicaciones y las partes interesadas del cliente. Espec\u00edficamente, alinear las expectativas de cu\u00e1ntos entornos de nube deben ser pre-aprovisionados, as\u00ed como definir las funciones y responsabilidades.","title":"Modelado del pipeline de release"},{"location":"CI_CD/continuous-delivery/#etapas-del-pipeline-de-release","text":"El pipeline de release debe tener en cuenta las siguientes condiciones: Selecci\u00f3n del release: El desarrollador que lleva a cabo las pruebas de la aplicaci\u00f3n debe tener la capacidad de seleccionar la versi\u00f3n de release que va a desplegar en el entorno de test. Despliegue: liberar el artefacto de compilaci\u00f3n desplegable de la aplicaci\u00f3n en el entorno de nube de destino. Configuraci\u00f3n: Las aplicaciones deben ser configuradas de forma consistente en todos sus entornos. Esta configuraci\u00f3n se aplica en el momento del despliegue. Los datos confidenciales, como los secretos y certificados de la aplicaci\u00f3n, deben estar guardados en un almac\u00e9n de claves y secretos de PaaS totalmente gestionado. Todos los secretos utilizados por la aplicaci\u00f3n deben obtenerse internamente dentro de la propia aplicaci\u00f3n. Los secretos no deber\u00edan estar expuestos dentro del entorno de ejecuci\u00f3n. Migraci\u00f3n de datos: Prepueble el estado de la aplicaci\u00f3n y/o los registros de datos que se necesitan para su entorno de tiempo de ejecuci\u00f3n. Esto tambi\u00e9n puede incluir los datos de prueba necesarios para su conjunto de pruebas de integraci\u00f3n. Prueba de humo de despliegue. Su prueba de humo tambi\u00e9n debe verificar que su aplicaci\u00f3n est\u00e1 apuntando a la configuraci\u00f3n correcta. Realice cualquier escenario de prueba de aceptaci\u00f3n manual o automatizada. Apruebe la puerta de release para promover la versi\u00f3n de la aplicaci\u00f3n al entorno de la nube de destino.","title":"Etapas del pipeline de release"},{"location":"CI_CD/continuous-delivery/#releases-de-preproduccion","text":"Las aplicaciones candidatas deben desplegarse en un entorno similar al de producci\u00f3n para llevar a cabo las pruebas finales manuales/automatizadas (incluidas las pruebas de capacidad).","title":"Releases de preproducci\u00f3n"},{"location":"CI_CD/continuous-delivery/#reversion-de-releases","text":"Su estrategia de release debe tener en cuenta los escenarios de reversi\u00f3n en caso de fallos inesperados despu\u00e9s de un despliegue. La reversi\u00f3n de releases puede ser complicada. Si no hay cambios en los datos que deban ser revertidos, entonces puede simplemente activar un nuevo release candidato para la \u00faltima versi\u00f3n de producci\u00f3n conocida y promover ese release a lo largo de su pipeline de CD.","title":"Reversi\u00f3n de releases"},{"location":"CI_CD/continuous-delivery/#referencias","text":"Entrega continua por Jez Humble, David Farley. Integraci\u00f3n continua vs. entrega continua vs. despliegue continuo Anillos de despliegue","title":"Referencias"},{"location":"CI_CD/continuous-delivery/#herramientas","text":"Flux para gitops Flujo de trabajo CI/CD usando GitOps Tekton para pipelines nativos de Kubernetes Argo Workflows Flagger para potentes lanzamientos nativos de Kubernetes, incluyendo blue/green, canary y A/B testing. No est\u00e1 muy relacionado con Kubernetes, pero echa un vistazo a jsonnet , un lenguaje de plantillas para reducir la repetici\u00f3n de tareas y aumentar el intercambio entre sus manifiestos yaml/json.","title":"Herramientas"},{"location":"CI_CD/continuous-integration/","text":"Continuous Integration Alentamos a los equipos de ingenier\u00eda a realizar una inversi\u00f3n inicial durante el Sprint 0 de un proyecto para establecer una canalizaci\u00f3n automatizada y repetible que integre continuamente el c\u00f3digo y libere los ejecutables del sistema para los entornos de nube de destino. Cada integraci\u00f3n debe ser verificada por un proceso de compilaci\u00f3n automatizado que asegure que pasa un conjunto de tests de validaci\u00f3n y detecte cualquier error. Estos principios mapean directamente las pr\u00e1cticas \u00e1giles del ciclo de vida del desarrollo de software. Metas La automatizaci\u00f3n de integraci\u00f3n continua es una parte integral del ciclo de vida de desarrollo de software destinado a reducir los errores de integraci\u00f3n de compilaci\u00f3n y maximizar la velocidad en un equipo de desarrollo. Una s\u00f3lida canalizaci\u00f3n de automatizaci\u00f3n de compilaci\u00f3n: Acelera la velocidad del equipo Previene problemas de integraci\u00f3n Evita el caos de \u00faltima hora durante las fechas de lanzamiento Proporciona un ciclo r\u00e1pido de retroalimentaci\u00f3n para el impacto de los cambios locales en todo el sistema Separa etapas de compilaci\u00f3n e implementaci\u00f3n Mide e informa m\u00e9tricas sobre fallas/\u00e9xitos de compilaci\u00f3n Aumenta la visibilidad en todo el equipo permitiendo una comunicaci\u00f3n m\u00e1s estrecha Reduce los errores humanos, que es probablemente la parte m\u00e1s importante de la automatizaci\u00f3n de las compilaciones. Definici\u00f3n de compilaci\u00f3n administrada en Git Los artefactos de c\u00f3digo/manifiesto requeridos para construir su proyecto deben mantenerse dentro de su(s) repositorio(s) de git de su(s) proyecto(s) Las definiciones de canalizaci\u00f3n de compilaci\u00f3n espec\u00edficas del proveedor de CI deben residir dentro de su(s) repositorio(s) de git de proyecto(s). Automatizaci\u00f3n de compilaci\u00f3n Una compilaci\u00f3n automatizada debe abarcar los siguientes principios: Compilaci\u00f3n Un solo paso dentro de su canalizaci\u00f3n de compilaci\u00f3n que compila su proyecto de c\u00f3digo en un solo artefacto de compilaci\u00f3n. Unit Testing Su definici\u00f3n de compilaci\u00f3n incluye pasos de validaci\u00f3n para ejecutar un conjunto de tests unitarios automatizados para garantizar que los componentes de la aplicaci\u00f3n cumplan con su dise\u00f1o y se comporten seg\u00fan lo previsto. Comprobaciones de estilo de c\u00f3digo El c\u00f3digo debe formatearse seg\u00fan los est\u00e1ndares de codificaci\u00f3n acordados. Dichos est\u00e1ndares mantienen el c\u00f3digo consistente y, lo que es m\u00e1s importante, f\u00e1cil de leer y refactorizar para el equipo. La consistencia en el estilo del c\u00f3digo fomenta la propiedad colectiva de los equipos Scrum del proyecto. Hay varias herramientas de validaci\u00f3n de estilo de c\u00f3digo abierto disponibles para elegir ( code style checks , StyleCop ). La secci\u00f3n Code Reviews tiene sugerencias para linters y estilos preferidos para varios lenguajes. Recomendamos incorporar herramientas de an\u00e1lisis de seguridad dentro de la etapa de compilaci\u00f3n de su canalizaci\u00f3n, como: esc\u00e1ner de credenciales, detecci\u00f3n de riesgos de seguridad, an\u00e1lisis est\u00e1tico, etc. Los est\u00e1ndares de c\u00f3digo se mantienen dentro de un \u00fanico archivo de configuraci\u00f3n. Debe haber un paso en la canalizaci\u00f3n de compilaci\u00f3n que afirme que el c\u00f3digo en el \u00faltimo commit se ajusta a la definici\u00f3n de estilo conocida. Script de compilaci\u00f3n Un solo comando debe tener la capacidad de compilar el sistema. Esto tambi\u00e9n es cierto para las compilaciones que se ejecutan en un servidor CI o en una m\u00e1quina local de desarrolladores. Sin dependencias IDE Es esencial tener una compilaci\u00f3n que se pueda ejecutar a trav\u00e9s de scripts independientes y que no dependa de un IDE en particular. Los destinos de canalizaci\u00f3n de compilaci\u00f3n se pueden activar localmente en sus escritorios a trav\u00e9s del IDE de su elecci\u00f3n. El proceso de compilaci\u00f3n tambi\u00e9n debe mantener la flexibilidad suficiente para ejecutarse dentro de un servidor de CI. Comprobaciones de seguridad de DevOps Introduzca seguridad a su proyecto en las primeras etapas. Siga la secci\u00f3n DevSecOps para introducir pr\u00e1cticas de seguridad, automatizaci\u00f3n, herramientas y frameworks como parte de la CI. Dependencias del entorno de compilaci\u00f3n Configuraci\u00f3n del entorno local automatizado Alentamos a mantener una experiencia de desarrollador consistente para todos los miembros del equipo. Debe haber un manifiesto/proceso automatizado central que agilice la instalaci\u00f3n y configuraci\u00f3n de cualquier dependencia de software. De esta forma, los desarrolladores pueden replicar localmente el mismo entorno de compilaci\u00f3n que el que se ejecuta en un servidor de CI. Los scripts de automatizaci\u00f3n de compilaci\u00f3n a menudo requieren paquetes de software espec\u00edficos y una versi\u00f3n preinstalada dentro del entorno de tiempo de ejecuci\u00f3n del sistema operativo. Todos los desarrolladores del equipo deber\u00edan poder emular el entorno de compilaci\u00f3n desde su escritorio local, independientemente de su sistema operativo. Para los proyectos que usan VS Code, aprovechar Dev Containers realmente puede ayudar a estandarizar la experiencia del desarrollador local en todo el equipo. Se deben considerar herramientas de empaquetado de software bien establecidas como Docker, Maven, npm, etc. al dise\u00f1ar su cadena de herramientas de automatizaci\u00f3n de compilaci\u00f3n. Documentaci\u00f3n de la configuraci\u00f3n local El proceso de configuraci\u00f3n para un entorno de compilaci\u00f3n local debe estar bien documentado y ser f\u00e1cil de seguir para los desarrolladores. Infrastructure as Code Administre la mayor cantidad posible de lo siguiente, como c\u00f3digo: Archivos de configuraci\u00f3n Gesti\u00f3n de configuraci\u00f3n (es decir, automatizaci\u00f3n de variables de entorno) Gesti\u00f3n de secretos Aprovisionamiento de recursos en la nube Asignaciones de roles Escenarios de prueba de carga Reglas y condiciones de monitoreo/alertas de disponibilidad Desvincular la infraestructura del c\u00f3digo base de la aplicaci\u00f3n simplifica el paso de los equipos de ingenier\u00eda a las aplicaciones nativas de la nube. Por qu\u00e9 Los cambios repetibles y auditables en la infraestructura facilitan la reversi\u00f3n a buenas configuraciones conocidas y la r\u00e1pida expansi\u00f3n sin tener que conectar manualmente los recursos de la nube. Los proyectos de referencia de IAC probados permiten que m\u00e1s equipos de ingenier\u00eda implementen soluciones seguras y escalables a un ritmo mucho m\u00e1s r\u00e1pido Permite simplificar los escenarios de \"lift and shift\" abstrayendo las complejidades de la computaci\u00f3n nativa en la nube lejos de los equipos de desarrolladores de aplicaciones. IAC DevOPS: operaciones por Pull Request El proceso de implementaci\u00f3n de la infraestructura se basa en un repositorio que contiene el estado esperado actual del sistema/entorno de Azure. Los cambios operativos se realizan en el sistema en ejecuci\u00f3n al realizar confirmaciones en este repositorio. Git tambi\u00e9n proporciona un modelo simple para auditar implementaciones y retroceder a un estado anterior. Patrones recomendados Usted define la infraestructura como c\u00f3digo en las plantillas de Terraform/ARM/Ansible Las plantillas son pilas de recursos en la nube repetibles que se centran en conjuntos de configuraci\u00f3n alineados con las necesidades de escalado y rendimiento de la aplicaci\u00f3n. Principios de la IAC Automatice el entorno de Azure Todos los recursos de la nube se aprovisionan a trav\u00e9s de un conjunto de infraestructura como plantillas de c\u00f3digo. Esto tambi\u00e9n incluye secretos, ajustes de configuraci\u00f3n de servicios, asignaciones de roles y condiciones de monitoreo. Azure Portal debe proporcionar una vista de solo lectura de los recursos del entorno. Cualquier cambio aplicado al entorno debe realizarse \u00fanicamente a trav\u00e9s de la cadena de herramientas IAC CI. El aprovisionamiento de entornos en la nube debe ser un proceso repetible que se basa en los artefactos del c\u00f3digo de infraestructura registrados en nuestro repositorio de git. Flujo de trabajo de CI de IAC Cuando los archivos de plantilla de IAC cambian a trav\u00e9s de un flujo de trabajo basado en Git, una canalizaci\u00f3n de compilaci\u00f3n de CI crea, valida y concilia el estado actual del entorno de infraestructura de destino con el estado esperado. El plan de ejecuci\u00f3n de infraestructura candidato para estos entornos fijos es revisado por un administrador como verificaci\u00f3n de entrada antes de la etapa de implementaci\u00f3n de la canalizaci\u00f3n que aplica el plan de ejecuci\u00f3n. Acceso de solo lectura del desarrollador a los recursos de la nube Las cuentas de desarrollador en Azure Portal deben tener acceso de solo lectura a los recursos del entorno de IAC en Azure. Automatizaci\u00f3n de secretos Las plantillas de IAC se implementan a trav\u00e9s de un sistema CI/CD que tiene integrada la automatizaci\u00f3n de secretos. Evite aplicar cambios a secretos y/o certificados directamente en Azure Portal. Automatizaci\u00f3n de tests de integraci\u00f3n de infraestructura Los tests de integraci\u00f3n de un extremo a otro se ejecutan como parte de su proceso de IAC CI para inspeccionar y validar que un entorno est\u00e9 listo para usar. Documentaci\u00f3n de Infraestructura La implementaci\u00f3n y la topolog\u00eda de la plantilla de recursos en la nube deben documentarse y comprenderse bien con el README del repositorio git de IAC. Se deben documentar los pasos de configuraci\u00f3n del entorno local y del flujo de trabajo de CI. Validaci\u00f3n de la configuraci\u00f3n Las aplicaciones utilizan la configuraci\u00f3n para permitir diferentes comportamientos en tiempo de ejecuci\u00f3n y es bastante com\u00fan utilizar archivos para esto. Como desarrolladores, podemos introducir errores al editar estos archivos, lo que causar\u00eda problemas para que la aplicaci\u00f3n se inicie y/o se ejecute correctamente. Aplicando t\u00e9cnicas de validaci\u00f3n tanto en la sintaxis como en la sem\u00e1ntica de nuestra configuraci\u00f3n, podemos detectar errores antes de que la aplicaci\u00f3n se despliegue y ejecute, mejorando la experiencia del desarrollador. Ejemplos de archivos de configuraci\u00f3n de aplicaciones JSON, con soporte para tipos de datos y estructuras de datos complejas YAML, un superconjunto de JSON con soporte para tipos de datos y estructuras complejas TOML, un superconjunto de JSON y un formato de archivo de configuraci\u00f3n formalmente especificado \u00bfPor qu\u00e9 validar la configuraci\u00f3n de la aplicaci\u00f3n como un paso separado? Depuraci\u00f3n m\u00e1s f\u00e1cil y ahorro de tiempo: Con un paso de validaci\u00f3n de la configuraci\u00f3n en nuestro pipeline, podemos evitar ejecutar la aplicaci\u00f3n s\u00f3lo para descubrir que falla. Se ahorra tiempo en tener que desplegar y ejecutar, esperar y luego darse cuenta de que algo est\u00e1 mal en la configuraci\u00f3n. Adem\u00e1s, tambi\u00e9n ahorra tiempo en revisar los logs para averiguar qu\u00e9 fall\u00f3 y por qu\u00e9. Mejor experiencia del usuario/desarrollador: Un simple recordatorio al usuario de que algo en la configuraci\u00f3n no est\u00e1 en el formato correcto puede marcar la diferencia entre un proceso de despliegue exitoso y la frustraci\u00f3n de tener que adivinar lo que sali\u00f3 mal. Evitar la corrupci\u00f3n de datos y las brechas de seguridad: Dado que los datos llegan desde una fuente no confiable, como un usuario o un servicio web externo, es particularmente importante validar la entrada. \u00bfQu\u00e9 es el esquema Json? JSON-Schema es el est\u00e1ndar de los documentos JSON que describe la estructura y los requisitos de sus datos JSON. Aunque se llama JSON-Schema, tambi\u00e9n es com\u00fan utilizar este m\u00e9todo para los YAML, ya que es un superconjunto de JSON. El esquema es muy sencillo; se\u00f1alar qu\u00e9 campos pueden existir, cu\u00e1les son obligatorios u opcionales, qu\u00e9 formato de datos utilizan. Sobre esa premisa b\u00e1sica se pueden a\u00f1adir otras reglas de validaci\u00f3n, junto con informaci\u00f3n legible para el ser humano. Los metadatos viven en los esquemas, que tambi\u00e9n son archivos .json. \u00bfC\u00f3mo implementar la validaci\u00f3n de esquemas? La implementaci\u00f3n de la validaci\u00f3n de esquemas se divide en dos: la generaci\u00f3n de los esquemas y la validaci\u00f3n de los archivos yaml/json con esos esquemas. Generaci\u00f3n Hay dos opciones para generar un esquema: Desde el c\u00f3digo : podemos aprovechar los modelos y objetos existentes en el c\u00f3digo y generar un esquema personalizado. Desde los datos : podemos tomar muestros yaml/json que reflejen la configuraci\u00f3n en general y utilizar las distintas herramientas online para generar un esquema. Validaci\u00f3n El esquema tiene m\u00e1s de 30 validadores para diferentes lenguajes, por lo que no es necesario que lo codifiques t\u00fa mismo. Validaci\u00f3n de la integraci\u00f3n Una manera eficaz de identificar los errores en su compilaci\u00f3n a un ritmo r\u00e1pido es invertir temprano en un conjunto fiable de tests automatizados que validan la funcionalidad de base del sistema: Tests de integraci\u00f3n de extremo a extremo Incluya pruebas en su proceso para validar que la versi\u00f3n candidata se ajusta a las afirmaciones de funcionalidad empresarial automatizada. Cualquier error debe ser reportado en los resultados de los tests, incluyendo la prueba fallida y el seguimiento de la pila correspondiente. Todas los tests deben ser invocadas a trav\u00e9s de un \u00fanico comando. Mantenga la compilaci\u00f3n r\u00e1pida. Tenga en cuenta el tiempo de ejecuci\u00f3n de los tests automatizados cuando decida introducir dependencias como bases de datos, servicios externos y carga de datos simulados. Considere la posibilidad de a\u00f1adir l\u00edmites m\u00e1ximos de tiempo de espera para las validaciones largas para fallar r\u00e1pidamente y mantener una alta velocidad en todo el equipo. Evitar el checkin de compilaciones falladas Las comprobaciones automatizadas de las compilaciones, los tests, las ejecuciones de lint, etc. deber\u00edan validarse localmente antes de confirmar los cambios en el repositorio. Informar de los fallos de compilaci\u00f3n Si el paso de compilaci\u00f3n falla, el estado de ejecuci\u00f3n de la cadena de compilaci\u00f3n debe ser reportado como fallido, incluyendo los logs relevantes y las trazas de pila. Dependencias de datos de automatizaci\u00f3n de tests Cualquier conjunto de datos simulado que se utilice para los tests unitarios y de integraci\u00f3n debe ser chequeado en el repositorio principal. Minimice cualquier dependencia de datos externos con su proceso de compilaci\u00f3n. Comprobaci\u00f3n de la cobertura del c\u00f3digo Recomendamos integrar las herramientas de cobertura del c\u00f3digo en la fase de compilaci\u00f3n. La mayor\u00eda de las herramientas de cobertura suspenden las compilaciones cuando la cobertura de los tests cae por debajo de un umbral m\u00ednimo. El informe de cobertura deber\u00eda publicarse en su sistema CI para hacer un seguimiento de una serie de variaciones en el tiempo. Flujo de trabajo basado en Git Compilar en el momento del commit Cada commit en el repositorio base debe activar el canal de CI para crear un nuevo candidato a la compilaci\u00f3n. Los artefactos de compilaci\u00f3n se construyen, empaquetan, validan y despliegan continuamente en un entorno de no producci\u00f3n por cada commit. Cada commit contra el repositorio resulta en una ejecuci\u00f3n de CI que comprueba las fuentes en la m\u00e1quina de integraci\u00f3n, inicia una compilaci\u00f3n y notifica el resultado de la compilaci\u00f3n. Evitar comentar los tests que fallan Evita comentar los tests en la rama principal. Al comentar los tests, obtenemos una indicaci\u00f3n incorrecta del estado de la compilaci\u00f3n. Aplicaci\u00f3n de la pol\u00edtica de rama Las pol\u00edticas de rama protegida deben ser configuradas en la rama principal para asegurar que las etapas de CI han pasado antes de comenzar una revisi\u00f3n de c\u00f3digo. Los aprobadores de la revisi\u00f3n del c\u00f3digo s\u00f3lo comenzar\u00e1n a revisar un PR una vez que la ejecuci\u00f3n de la canalizaci\u00f3n de CI haya pasado. Las compilaciones rotas deber\u00edan bloquear las revisiones de los PRs. Evita que los commits vayan directamente a la rama principal. Estrategia de las ramas Las ramas de release deber\u00edan activar autom\u00e1ticamente el despliegue de un artefacto de compilaci\u00f3n en su entorno de nube de destino. Puedes encontrar una gu\u00eda en el sitio de documentaci\u00f3n de Azure DevOps en la secci\u00f3n Manage deployments . Entrega r\u00e1pida y diaria En aras de la transparencia y de la comunicaci\u00f3n frecuente entre el equipo de desarrollo, animamos a los desarrolladores a que env\u00eden el c\u00f3digo a diario. Este enfoque proporciona visibilidad y acelera la programaci\u00f3n por pares en todo el equipo. Estos son algunos principios a tener en cuenta: Todos comitean al repositorio cada d\u00eda El c\u00f3digo registrado al final del d\u00eda debe contener pruebas unitarias como m\u00ednimo. Ejecuta la compilaci\u00f3n localmente antes de hacer el check-in para evitar la saturaci\u00f3n de fallos de la canalizaci\u00f3n CI. Deber\u00edas verificar qu\u00e9 caus\u00f3 el error, y tratar de resolverlo tan pronto como sea posible. Animamos a los desarrolladores a seguir los principios lean de SDLC . A\u00edsle el trabajo en peque\u00f1as partes que se relacionen directamente con el valor del negocio y refactorice de forma incremental. Entornos aislados Uno de los objetivos clave de la validaci\u00f3n de la compilaci\u00f3n es aislar e identificar los fallos en los entornos de test y minimizar cualquier interrupci\u00f3n de producci\u00f3n. Las pruebas automatizadas E2E deben ejecutarse en un entorno que imite el entorno de producci\u00f3n (en la medida de lo posible). Test en un clon de producci\u00f3n El entorno de producci\u00f3n debe duplicarse en un entorno de test (QA y/o Pre-Prod) como m\u00ednimo. Las actualizaciones PR desencadenan releases escalonados Los nuevos commits relacionados con un pull request deben desencadenar una compilaci\u00f3n / release en un entorno de integraci\u00f3n. El entorno de producci\u00f3n debe estar totalmente aislado de este proceso. Promover los cambios de infraestructura en entornos fijos Los cambios en la infraestructura como c\u00f3digo deben probarse en un entorno de integraci\u00f3n y promoverse a todos los entornos fijos, para luego migrar a producci\u00f3n sin que haya tiempo de inactividad para los usuarios del sistema. Tests en producci\u00f3n Existen varios enfoques para llevar a cabo de forma segura las pruebas automatizadas para los despliegues de producci\u00f3n. Algunos de ellos pueden ser: Feature flagging A/B testing Traffic shifting Acceso de los desarrolladores a los \u00faltimos artefactos de la versi\u00f3n Nuestro flujo de trabajo de desarrollo debe permitir a los desarrolladores obtener, instalar y ejecutar el \u00faltimo ejecutable del sistema. Los ejecutables de la versi\u00f3n deben ser generados autom\u00e1ticamente como parte de nuestros procesos CI/CD. Los desarrolladores pueden acceder al \u00faltimo ejecutable El \u00faltimo ejecutable del sistema est\u00e1 disponible para todos los desarrolladores del equipo. Debe haber un lugar bien conocido donde los desarrolladores puedan hacer referencia al artefacto. Observabilidad de la integraci\u00f3n Los cambios de estado aplicados a la compilaci\u00f3n principal deben estar disponibles y ser comunicados a todo el equipo. La centralizaci\u00f3n de los logs y el estado de los fallos es esencial para los desarrolladores que investigan las compilaciones falladas. Recomendamos integrar Teams o Slack con las ejecuciones CI/CD, lo que ayuda a mantener al equipo continuamente conectado a los fallos y al estado de las compilaciones. Dashboard de alto nivel de integraci\u00f3n continua Los proveedores de integraci\u00f3n continua modernos tienen la capacidad de consolidar e informar del estado de la compilaci\u00f3n en un dashboard determinado. Tu dashboard de integraci\u00f3n continua deber\u00eda ser capaz de correlacionar un fallo de compilaci\u00f3n con un commit de git. Badge del estado de compilaci\u00f3n en el readme del proyecto Deber\u00eda haber una badge del estado de la compilaci\u00f3n incluida en el README ra\u00edz del proyecto. Notificaciones de compilaci\u00f3n Tu proceso de CI deber\u00eda estar configurado para enviar notificaciones a plataformas de mensajer\u00eda como Teams / Slack una vez que la compilaci\u00f3n se complete. Recomendamos crear un canal separado para ayudar a consolidar y aislar estas notificaciones. Recursos Mejores pr\u00e1cticas de integraci\u00f3n continua de Martin Fowler Pipelines multietapa de Azure DevOps Conceptos clave de Azure Pipeline Entornos de Azure Pipeline Artefactos en Azure Pipelines Permisos y roles de seguridad en Azure Pipeline Aprobaciones y comprobaciones del entorno de Azure Proveedor de Terraform Azure DevOps Gu\u00eda de inicio de Terraform con Azure Configuraci\u00f3n de Terraform Remote State Azure Terratest - Marco de infraestructura de unidades e integraci\u00f3n Documentaci\u00f3n Bicep Ejemplos de Bicep","title":"Continuous Integration"},{"location":"CI_CD/continuous-integration/#continuous-integration","text":"Alentamos a los equipos de ingenier\u00eda a realizar una inversi\u00f3n inicial durante el Sprint 0 de un proyecto para establecer una canalizaci\u00f3n automatizada y repetible que integre continuamente el c\u00f3digo y libere los ejecutables del sistema para los entornos de nube de destino. Cada integraci\u00f3n debe ser verificada por un proceso de compilaci\u00f3n automatizado que asegure que pasa un conjunto de tests de validaci\u00f3n y detecte cualquier error. Estos principios mapean directamente las pr\u00e1cticas \u00e1giles del ciclo de vida del desarrollo de software.","title":"Continuous Integration"},{"location":"CI_CD/continuous-integration/#metas","text":"La automatizaci\u00f3n de integraci\u00f3n continua es una parte integral del ciclo de vida de desarrollo de software destinado a reducir los errores de integraci\u00f3n de compilaci\u00f3n y maximizar la velocidad en un equipo de desarrollo. Una s\u00f3lida canalizaci\u00f3n de automatizaci\u00f3n de compilaci\u00f3n: Acelera la velocidad del equipo Previene problemas de integraci\u00f3n Evita el caos de \u00faltima hora durante las fechas de lanzamiento Proporciona un ciclo r\u00e1pido de retroalimentaci\u00f3n para el impacto de los cambios locales en todo el sistema Separa etapas de compilaci\u00f3n e implementaci\u00f3n Mide e informa m\u00e9tricas sobre fallas/\u00e9xitos de compilaci\u00f3n Aumenta la visibilidad en todo el equipo permitiendo una comunicaci\u00f3n m\u00e1s estrecha Reduce los errores humanos, que es probablemente la parte m\u00e1s importante de la automatizaci\u00f3n de las compilaciones.","title":"Metas"},{"location":"CI_CD/continuous-integration/#definicion-de-compilacion-administrada-en-git","text":"","title":"Definici\u00f3n de compilaci\u00f3n administrada en Git"},{"location":"CI_CD/continuous-integration/#los-artefactos-de-codigomanifiesto-requeridos-para-construir-su-proyecto-deben-mantenerse-dentro-de-sus-repositorios-de-git-de-sus-proyectos","text":"Las definiciones de canalizaci\u00f3n de compilaci\u00f3n espec\u00edficas del proveedor de CI deben residir dentro de su(s) repositorio(s) de git de proyecto(s).","title":"Los artefactos de c\u00f3digo/manifiesto requeridos para construir su proyecto deben mantenerse dentro de su(s) repositorio(s) de git de su(s) proyecto(s)"},{"location":"CI_CD/continuous-integration/#automatizacion-de-compilacion","text":"Una compilaci\u00f3n automatizada debe abarcar los siguientes principios:","title":"Automatizaci\u00f3n de compilaci\u00f3n"},{"location":"CI_CD/continuous-integration/#compilacion","text":"Un solo paso dentro de su canalizaci\u00f3n de compilaci\u00f3n que compila su proyecto de c\u00f3digo en un solo artefacto de compilaci\u00f3n.","title":"Compilaci\u00f3n"},{"location":"CI_CD/continuous-integration/#unit-testing","text":"Su definici\u00f3n de compilaci\u00f3n incluye pasos de validaci\u00f3n para ejecutar un conjunto de tests unitarios automatizados para garantizar que los componentes de la aplicaci\u00f3n cumplan con su dise\u00f1o y se comporten seg\u00fan lo previsto.","title":"Unit Testing"},{"location":"CI_CD/continuous-integration/#comprobaciones-de-estilo-de-codigo","text":"El c\u00f3digo debe formatearse seg\u00fan los est\u00e1ndares de codificaci\u00f3n acordados. Dichos est\u00e1ndares mantienen el c\u00f3digo consistente y, lo que es m\u00e1s importante, f\u00e1cil de leer y refactorizar para el equipo. La consistencia en el estilo del c\u00f3digo fomenta la propiedad colectiva de los equipos Scrum del proyecto. Hay varias herramientas de validaci\u00f3n de estilo de c\u00f3digo abierto disponibles para elegir ( code style checks , StyleCop ). La secci\u00f3n Code Reviews tiene sugerencias para linters y estilos preferidos para varios lenguajes. Recomendamos incorporar herramientas de an\u00e1lisis de seguridad dentro de la etapa de compilaci\u00f3n de su canalizaci\u00f3n, como: esc\u00e1ner de credenciales, detecci\u00f3n de riesgos de seguridad, an\u00e1lisis est\u00e1tico, etc. Los est\u00e1ndares de c\u00f3digo se mantienen dentro de un \u00fanico archivo de configuraci\u00f3n. Debe haber un paso en la canalizaci\u00f3n de compilaci\u00f3n que afirme que el c\u00f3digo en el \u00faltimo commit se ajusta a la definici\u00f3n de estilo conocida.","title":"Comprobaciones de estilo de c\u00f3digo"},{"location":"CI_CD/continuous-integration/#script-de-compilacion","text":"Un solo comando debe tener la capacidad de compilar el sistema. Esto tambi\u00e9n es cierto para las compilaciones que se ejecutan en un servidor CI o en una m\u00e1quina local de desarrolladores.","title":"Script de compilaci\u00f3n"},{"location":"CI_CD/continuous-integration/#sin-dependencias-ide","text":"Es esencial tener una compilaci\u00f3n que se pueda ejecutar a trav\u00e9s de scripts independientes y que no dependa de un IDE en particular. Los destinos de canalizaci\u00f3n de compilaci\u00f3n se pueden activar localmente en sus escritorios a trav\u00e9s del IDE de su elecci\u00f3n. El proceso de compilaci\u00f3n tambi\u00e9n debe mantener la flexibilidad suficiente para ejecutarse dentro de un servidor de CI.","title":"Sin dependencias IDE"},{"location":"CI_CD/continuous-integration/#comprobaciones-de-seguridad-de-devops","text":"Introduzca seguridad a su proyecto en las primeras etapas. Siga la secci\u00f3n DevSecOps para introducir pr\u00e1cticas de seguridad, automatizaci\u00f3n, herramientas y frameworks como parte de la CI.","title":"Comprobaciones de seguridad de DevOps"},{"location":"CI_CD/continuous-integration/#dependencias-del-entorno-de-compilacion","text":"","title":"Dependencias del entorno de compilaci\u00f3n"},{"location":"CI_CD/continuous-integration/#configuracion-del-entorno-local-automatizado","text":"Alentamos a mantener una experiencia de desarrollador consistente para todos los miembros del equipo. Debe haber un manifiesto/proceso automatizado central que agilice la instalaci\u00f3n y configuraci\u00f3n de cualquier dependencia de software. De esta forma, los desarrolladores pueden replicar localmente el mismo entorno de compilaci\u00f3n que el que se ejecuta en un servidor de CI. Los scripts de automatizaci\u00f3n de compilaci\u00f3n a menudo requieren paquetes de software espec\u00edficos y una versi\u00f3n preinstalada dentro del entorno de tiempo de ejecuci\u00f3n del sistema operativo. Todos los desarrolladores del equipo deber\u00edan poder emular el entorno de compilaci\u00f3n desde su escritorio local, independientemente de su sistema operativo. Para los proyectos que usan VS Code, aprovechar Dev Containers realmente puede ayudar a estandarizar la experiencia del desarrollador local en todo el equipo. Se deben considerar herramientas de empaquetado de software bien establecidas como Docker, Maven, npm, etc. al dise\u00f1ar su cadena de herramientas de automatizaci\u00f3n de compilaci\u00f3n.","title":"Configuraci\u00f3n del entorno local automatizado"},{"location":"CI_CD/continuous-integration/#documentacion-de-la-configuracion-local","text":"El proceso de configuraci\u00f3n para un entorno de compilaci\u00f3n local debe estar bien documentado y ser f\u00e1cil de seguir para los desarrolladores.","title":"Documentaci\u00f3n de la configuraci\u00f3n local"},{"location":"CI_CD/continuous-integration/#infrastructure-as-code","text":"Administre la mayor cantidad posible de lo siguiente, como c\u00f3digo: Archivos de configuraci\u00f3n Gesti\u00f3n de configuraci\u00f3n (es decir, automatizaci\u00f3n de variables de entorno) Gesti\u00f3n de secretos Aprovisionamiento de recursos en la nube Asignaciones de roles Escenarios de prueba de carga Reglas y condiciones de monitoreo/alertas de disponibilidad Desvincular la infraestructura del c\u00f3digo base de la aplicaci\u00f3n simplifica el paso de los equipos de ingenier\u00eda a las aplicaciones nativas de la nube.","title":"Infrastructure as Code"},{"location":"CI_CD/continuous-integration/#por-que","text":"Los cambios repetibles y auditables en la infraestructura facilitan la reversi\u00f3n a buenas configuraciones conocidas y la r\u00e1pida expansi\u00f3n sin tener que conectar manualmente los recursos de la nube. Los proyectos de referencia de IAC probados permiten que m\u00e1s equipos de ingenier\u00eda implementen soluciones seguras y escalables a un ritmo mucho m\u00e1s r\u00e1pido Permite simplificar los escenarios de \"lift and shift\" abstrayendo las complejidades de la computaci\u00f3n nativa en la nube lejos de los equipos de desarrolladores de aplicaciones.","title":"Por qu\u00e9"},{"location":"CI_CD/continuous-integration/#iac-devops-operaciones-por-pull-request","text":"El proceso de implementaci\u00f3n de la infraestructura se basa en un repositorio que contiene el estado esperado actual del sistema/entorno de Azure. Los cambios operativos se realizan en el sistema en ejecuci\u00f3n al realizar confirmaciones en este repositorio. Git tambi\u00e9n proporciona un modelo simple para auditar implementaciones y retroceder a un estado anterior.","title":"IAC DevOPS: operaciones por Pull Request"},{"location":"CI_CD/continuous-integration/#patrones-recomendados","text":"Usted define la infraestructura como c\u00f3digo en las plantillas de Terraform/ARM/Ansible Las plantillas son pilas de recursos en la nube repetibles que se centran en conjuntos de configuraci\u00f3n alineados con las necesidades de escalado y rendimiento de la aplicaci\u00f3n.","title":"Patrones recomendados"},{"location":"CI_CD/continuous-integration/#principios-de-la-iac","text":"","title":"Principios de la IAC"},{"location":"CI_CD/continuous-integration/#automatice-el-entorno-de-azure","text":"Todos los recursos de la nube se aprovisionan a trav\u00e9s de un conjunto de infraestructura como plantillas de c\u00f3digo. Esto tambi\u00e9n incluye secretos, ajustes de configuraci\u00f3n de servicios, asignaciones de roles y condiciones de monitoreo. Azure Portal debe proporcionar una vista de solo lectura de los recursos del entorno. Cualquier cambio aplicado al entorno debe realizarse \u00fanicamente a trav\u00e9s de la cadena de herramientas IAC CI. El aprovisionamiento de entornos en la nube debe ser un proceso repetible que se basa en los artefactos del c\u00f3digo de infraestructura registrados en nuestro repositorio de git.","title":"Automatice el entorno de Azure"},{"location":"CI_CD/continuous-integration/#flujo-de-trabajo-de-ci-de-iac","text":"Cuando los archivos de plantilla de IAC cambian a trav\u00e9s de un flujo de trabajo basado en Git, una canalizaci\u00f3n de compilaci\u00f3n de CI crea, valida y concilia el estado actual del entorno de infraestructura de destino con el estado esperado. El plan de ejecuci\u00f3n de infraestructura candidato para estos entornos fijos es revisado por un administrador como verificaci\u00f3n de entrada antes de la etapa de implementaci\u00f3n de la canalizaci\u00f3n que aplica el plan de ejecuci\u00f3n.","title":"Flujo de trabajo de CI de IAC"},{"location":"CI_CD/continuous-integration/#acceso-de-solo-lectura-del-desarrollador-a-los-recursos-de-la-nube","text":"Las cuentas de desarrollador en Azure Portal deben tener acceso de solo lectura a los recursos del entorno de IAC en Azure.","title":"Acceso de solo lectura del desarrollador a los recursos de la nube"},{"location":"CI_CD/continuous-integration/#automatizacion-de-secretos","text":"Las plantillas de IAC se implementan a trav\u00e9s de un sistema CI/CD que tiene integrada la automatizaci\u00f3n de secretos. Evite aplicar cambios a secretos y/o certificados directamente en Azure Portal.","title":"Automatizaci\u00f3n de secretos"},{"location":"CI_CD/continuous-integration/#automatizacion-de-tests-de-integracion-de-infraestructura","text":"Los tests de integraci\u00f3n de un extremo a otro se ejecutan como parte de su proceso de IAC CI para inspeccionar y validar que un entorno est\u00e9 listo para usar.","title":"Automatizaci\u00f3n de tests de integraci\u00f3n de infraestructura"},{"location":"CI_CD/continuous-integration/#documentacion-de-infraestructura","text":"La implementaci\u00f3n y la topolog\u00eda de la plantilla de recursos en la nube deben documentarse y comprenderse bien con el README del repositorio git de IAC. Se deben documentar los pasos de configuraci\u00f3n del entorno local y del flujo de trabajo de CI.","title":"Documentaci\u00f3n de Infraestructura"},{"location":"CI_CD/continuous-integration/#validacion-de-la-configuracion","text":"Las aplicaciones utilizan la configuraci\u00f3n para permitir diferentes comportamientos en tiempo de ejecuci\u00f3n y es bastante com\u00fan utilizar archivos para esto. Como desarrolladores, podemos introducir errores al editar estos archivos, lo que causar\u00eda problemas para que la aplicaci\u00f3n se inicie y/o se ejecute correctamente. Aplicando t\u00e9cnicas de validaci\u00f3n tanto en la sintaxis como en la sem\u00e1ntica de nuestra configuraci\u00f3n, podemos detectar errores antes de que la aplicaci\u00f3n se despliegue y ejecute, mejorando la experiencia del desarrollador.","title":"Validaci\u00f3n de la configuraci\u00f3n"},{"location":"CI_CD/continuous-integration/#ejemplos-de-archivos-de-configuracion-de-aplicaciones","text":"JSON, con soporte para tipos de datos y estructuras de datos complejas YAML, un superconjunto de JSON con soporte para tipos de datos y estructuras complejas TOML, un superconjunto de JSON y un formato de archivo de configuraci\u00f3n formalmente especificado","title":"Ejemplos de archivos de configuraci\u00f3n de aplicaciones"},{"location":"CI_CD/continuous-integration/#por-que-validar-la-configuracion-de-la-aplicacion-como-un-paso-separado","text":"Depuraci\u00f3n m\u00e1s f\u00e1cil y ahorro de tiempo: Con un paso de validaci\u00f3n de la configuraci\u00f3n en nuestro pipeline, podemos evitar ejecutar la aplicaci\u00f3n s\u00f3lo para descubrir que falla. Se ahorra tiempo en tener que desplegar y ejecutar, esperar y luego darse cuenta de que algo est\u00e1 mal en la configuraci\u00f3n. Adem\u00e1s, tambi\u00e9n ahorra tiempo en revisar los logs para averiguar qu\u00e9 fall\u00f3 y por qu\u00e9. Mejor experiencia del usuario/desarrollador: Un simple recordatorio al usuario de que algo en la configuraci\u00f3n no est\u00e1 en el formato correcto puede marcar la diferencia entre un proceso de despliegue exitoso y la frustraci\u00f3n de tener que adivinar lo que sali\u00f3 mal. Evitar la corrupci\u00f3n de datos y las brechas de seguridad: Dado que los datos llegan desde una fuente no confiable, como un usuario o un servicio web externo, es particularmente importante validar la entrada.","title":"\u00bfPor qu\u00e9 validar la configuraci\u00f3n de la aplicaci\u00f3n como un paso separado?"},{"location":"CI_CD/continuous-integration/#que-es-el-esquema-json","text":"JSON-Schema es el est\u00e1ndar de los documentos JSON que describe la estructura y los requisitos de sus datos JSON. Aunque se llama JSON-Schema, tambi\u00e9n es com\u00fan utilizar este m\u00e9todo para los YAML, ya que es un superconjunto de JSON. El esquema es muy sencillo; se\u00f1alar qu\u00e9 campos pueden existir, cu\u00e1les son obligatorios u opcionales, qu\u00e9 formato de datos utilizan. Sobre esa premisa b\u00e1sica se pueden a\u00f1adir otras reglas de validaci\u00f3n, junto con informaci\u00f3n legible para el ser humano. Los metadatos viven en los esquemas, que tambi\u00e9n son archivos .json.","title":"\u00bfQu\u00e9 es el esquema Json?"},{"location":"CI_CD/continuous-integration/#como-implementar-la-validacion-de-esquemas","text":"La implementaci\u00f3n de la validaci\u00f3n de esquemas se divide en dos: la generaci\u00f3n de los esquemas y la validaci\u00f3n de los archivos yaml/json con esos esquemas.","title":"\u00bfC\u00f3mo implementar la validaci\u00f3n de esquemas?"},{"location":"CI_CD/continuous-integration/#generacion","text":"Hay dos opciones para generar un esquema: Desde el c\u00f3digo : podemos aprovechar los modelos y objetos existentes en el c\u00f3digo y generar un esquema personalizado. Desde los datos : podemos tomar muestros yaml/json que reflejen la configuraci\u00f3n en general y utilizar las distintas herramientas online para generar un esquema.","title":"Generaci\u00f3n"},{"location":"CI_CD/continuous-integration/#validacion","text":"El esquema tiene m\u00e1s de 30 validadores para diferentes lenguajes, por lo que no es necesario que lo codifiques t\u00fa mismo.","title":"Validaci\u00f3n"},{"location":"CI_CD/continuous-integration/#validacion-de-la-integracion","text":"Una manera eficaz de identificar los errores en su compilaci\u00f3n a un ritmo r\u00e1pido es invertir temprano en un conjunto fiable de tests automatizados que validan la funcionalidad de base del sistema:","title":"Validaci\u00f3n de la integraci\u00f3n"},{"location":"CI_CD/continuous-integration/#tests-de-integracion-de-extremo-a-extremo","text":"Incluya pruebas en su proceso para validar que la versi\u00f3n candidata se ajusta a las afirmaciones de funcionalidad empresarial automatizada. Cualquier error debe ser reportado en los resultados de los tests, incluyendo la prueba fallida y el seguimiento de la pila correspondiente. Todas los tests deben ser invocadas a trav\u00e9s de un \u00fanico comando. Mantenga la compilaci\u00f3n r\u00e1pida. Tenga en cuenta el tiempo de ejecuci\u00f3n de los tests automatizados cuando decida introducir dependencias como bases de datos, servicios externos y carga de datos simulados. Considere la posibilidad de a\u00f1adir l\u00edmites m\u00e1ximos de tiempo de espera para las validaciones largas para fallar r\u00e1pidamente y mantener una alta velocidad en todo el equipo.","title":"Tests de integraci\u00f3n de extremo a extremo"},{"location":"CI_CD/continuous-integration/#evitar-el-checkin-de-compilaciones-falladas","text":"Las comprobaciones automatizadas de las compilaciones, los tests, las ejecuciones de lint, etc. deber\u00edan validarse localmente antes de confirmar los cambios en el repositorio.","title":"Evitar el checkin de compilaciones falladas"},{"location":"CI_CD/continuous-integration/#informar-de-los-fallos-de-compilacion","text":"Si el paso de compilaci\u00f3n falla, el estado de ejecuci\u00f3n de la cadena de compilaci\u00f3n debe ser reportado como fallido, incluyendo los logs relevantes y las trazas de pila.","title":"Informar de los fallos de compilaci\u00f3n"},{"location":"CI_CD/continuous-integration/#dependencias-de-datos-de-automatizacion-de-tests","text":"Cualquier conjunto de datos simulado que se utilice para los tests unitarios y de integraci\u00f3n debe ser chequeado en el repositorio principal. Minimice cualquier dependencia de datos externos con su proceso de compilaci\u00f3n.","title":"Dependencias de datos de automatizaci\u00f3n de tests"},{"location":"CI_CD/continuous-integration/#comprobacion-de-la-cobertura-del-codigo","text":"Recomendamos integrar las herramientas de cobertura del c\u00f3digo en la fase de compilaci\u00f3n. La mayor\u00eda de las herramientas de cobertura suspenden las compilaciones cuando la cobertura de los tests cae por debajo de un umbral m\u00ednimo. El informe de cobertura deber\u00eda publicarse en su sistema CI para hacer un seguimiento de una serie de variaciones en el tiempo.","title":"Comprobaci\u00f3n de la cobertura del c\u00f3digo"},{"location":"CI_CD/continuous-integration/#flujo-de-trabajo-basado-en-git","text":"","title":"Flujo de trabajo basado en Git"},{"location":"CI_CD/continuous-integration/#compilar-en-el-momento-del-commit","text":"Cada commit en el repositorio base debe activar el canal de CI para crear un nuevo candidato a la compilaci\u00f3n. Los artefactos de compilaci\u00f3n se construyen, empaquetan, validan y despliegan continuamente en un entorno de no producci\u00f3n por cada commit. Cada commit contra el repositorio resulta en una ejecuci\u00f3n de CI que comprueba las fuentes en la m\u00e1quina de integraci\u00f3n, inicia una compilaci\u00f3n y notifica el resultado de la compilaci\u00f3n.","title":"Compilar en el momento del commit"},{"location":"CI_CD/continuous-integration/#evitar-comentar-los-tests-que-fallan","text":"Evita comentar los tests en la rama principal. Al comentar los tests, obtenemos una indicaci\u00f3n incorrecta del estado de la compilaci\u00f3n.","title":"Evitar comentar los tests que fallan"},{"location":"CI_CD/continuous-integration/#aplicacion-de-la-politica-de-rama","text":"Las pol\u00edticas de rama protegida deben ser configuradas en la rama principal para asegurar que las etapas de CI han pasado antes de comenzar una revisi\u00f3n de c\u00f3digo. Los aprobadores de la revisi\u00f3n del c\u00f3digo s\u00f3lo comenzar\u00e1n a revisar un PR una vez que la ejecuci\u00f3n de la canalizaci\u00f3n de CI haya pasado. Las compilaciones rotas deber\u00edan bloquear las revisiones de los PRs. Evita que los commits vayan directamente a la rama principal.","title":"Aplicaci\u00f3n de la pol\u00edtica de rama"},{"location":"CI_CD/continuous-integration/#estrategia-de-las-ramas","text":"Las ramas de release deber\u00edan activar autom\u00e1ticamente el despliegue de un artefacto de compilaci\u00f3n en su entorno de nube de destino. Puedes encontrar una gu\u00eda en el sitio de documentaci\u00f3n de Azure DevOps en la secci\u00f3n Manage deployments .","title":"Estrategia de las ramas"},{"location":"CI_CD/continuous-integration/#entrega-rapida-y-diaria","text":"En aras de la transparencia y de la comunicaci\u00f3n frecuente entre el equipo de desarrollo, animamos a los desarrolladores a que env\u00eden el c\u00f3digo a diario. Este enfoque proporciona visibilidad y acelera la programaci\u00f3n por pares en todo el equipo. Estos son algunos principios a tener en cuenta:","title":"Entrega r\u00e1pida y diaria"},{"location":"CI_CD/continuous-integration/#todos-comitean-al-repositorio-cada-dia","text":"El c\u00f3digo registrado al final del d\u00eda debe contener pruebas unitarias como m\u00ednimo. Ejecuta la compilaci\u00f3n localmente antes de hacer el check-in para evitar la saturaci\u00f3n de fallos de la canalizaci\u00f3n CI. Deber\u00edas verificar qu\u00e9 caus\u00f3 el error, y tratar de resolverlo tan pronto como sea posible. Animamos a los desarrolladores a seguir los principios lean de SDLC . A\u00edsle el trabajo en peque\u00f1as partes que se relacionen directamente con el valor del negocio y refactorice de forma incremental.","title":"Todos comitean al repositorio cada d\u00eda"},{"location":"CI_CD/continuous-integration/#entornos-aislados","text":"Uno de los objetivos clave de la validaci\u00f3n de la compilaci\u00f3n es aislar e identificar los fallos en los entornos de test y minimizar cualquier interrupci\u00f3n de producci\u00f3n. Las pruebas automatizadas E2E deben ejecutarse en un entorno que imite el entorno de producci\u00f3n (en la medida de lo posible).","title":"Entornos aislados"},{"location":"CI_CD/continuous-integration/#test-en-un-clon-de-produccion","text":"El entorno de producci\u00f3n debe duplicarse en un entorno de test (QA y/o Pre-Prod) como m\u00ednimo.","title":"Test en un clon de producci\u00f3n"},{"location":"CI_CD/continuous-integration/#las-actualizaciones-pr-desencadenan-releases-escalonados","text":"Los nuevos commits relacionados con un pull request deben desencadenar una compilaci\u00f3n / release en un entorno de integraci\u00f3n. El entorno de producci\u00f3n debe estar totalmente aislado de este proceso.","title":"Las actualizaciones PR desencadenan releases escalonados"},{"location":"CI_CD/continuous-integration/#promover-los-cambios-de-infraestructura-en-entornos-fijos","text":"Los cambios en la infraestructura como c\u00f3digo deben probarse en un entorno de integraci\u00f3n y promoverse a todos los entornos fijos, para luego migrar a producci\u00f3n sin que haya tiempo de inactividad para los usuarios del sistema.","title":"Promover los cambios de infraestructura en entornos fijos"},{"location":"CI_CD/continuous-integration/#tests-en-produccion","text":"Existen varios enfoques para llevar a cabo de forma segura las pruebas automatizadas para los despliegues de producci\u00f3n. Algunos de ellos pueden ser: Feature flagging A/B testing Traffic shifting","title":"Tests en producci\u00f3n"},{"location":"CI_CD/continuous-integration/#acceso-de-los-desarrolladores-a-los-ultimos-artefactos-de-la-version","text":"Nuestro flujo de trabajo de desarrollo debe permitir a los desarrolladores obtener, instalar y ejecutar el \u00faltimo ejecutable del sistema. Los ejecutables de la versi\u00f3n deben ser generados autom\u00e1ticamente como parte de nuestros procesos CI/CD.","title":"Acceso de los desarrolladores a los \u00faltimos artefactos de la versi\u00f3n"},{"location":"CI_CD/continuous-integration/#los-desarrolladores-pueden-acceder-al-ultimo-ejecutable","text":"El \u00faltimo ejecutable del sistema est\u00e1 disponible para todos los desarrolladores del equipo. Debe haber un lugar bien conocido donde los desarrolladores puedan hacer referencia al artefacto.","title":"Los desarrolladores pueden acceder al \u00faltimo ejecutable"},{"location":"CI_CD/continuous-integration/#observabilidad-de-la-integracion","text":"Los cambios de estado aplicados a la compilaci\u00f3n principal deben estar disponibles y ser comunicados a todo el equipo. La centralizaci\u00f3n de los logs y el estado de los fallos es esencial para los desarrolladores que investigan las compilaciones falladas. Recomendamos integrar Teams o Slack con las ejecuciones CI/CD, lo que ayuda a mantener al equipo continuamente conectado a los fallos y al estado de las compilaciones.","title":"Observabilidad de la integraci\u00f3n"},{"location":"CI_CD/continuous-integration/#dashboard-de-alto-nivel-de-integracion-continua","text":"Los proveedores de integraci\u00f3n continua modernos tienen la capacidad de consolidar e informar del estado de la compilaci\u00f3n en un dashboard determinado. Tu dashboard de integraci\u00f3n continua deber\u00eda ser capaz de correlacionar un fallo de compilaci\u00f3n con un commit de git.","title":"Dashboard de alto nivel de integraci\u00f3n continua"},{"location":"CI_CD/continuous-integration/#badge-del-estado-de-compilacion-en-el-readme-del-proyecto","text":"Deber\u00eda haber una badge del estado de la compilaci\u00f3n incluida en el README ra\u00edz del proyecto.","title":"Badge del estado de compilaci\u00f3n en el readme del proyecto"},{"location":"CI_CD/continuous-integration/#notificaciones-de-compilacion","text":"Tu proceso de CI deber\u00eda estar configurado para enviar notificaciones a plataformas de mensajer\u00eda como Teams / Slack una vez que la compilaci\u00f3n se complete. Recomendamos crear un canal separado para ayudar a consolidar y aislar estas notificaciones.","title":"Notificaciones de compilaci\u00f3n"},{"location":"CI_CD/continuous-integration/#recursos","text":"Mejores pr\u00e1cticas de integraci\u00f3n continua de Martin Fowler Pipelines multietapa de Azure DevOps Conceptos clave de Azure Pipeline Entornos de Azure Pipeline Artefactos en Azure Pipelines Permisos y roles de seguridad en Azure Pipeline Aprobaciones y comprobaciones del entorno de Azure Proveedor de Terraform Azure DevOps Gu\u00eda de inicio de Terraform con Azure Configuraci\u00f3n de Terraform Remote State Azure Terratest - Marco de infraestructura de unidades e integraci\u00f3n Documentaci\u00f3n Bicep Ejemplos de Bicep","title":"Recursos"},{"location":"CI_CD/dev-sec-ops/","text":"DevSecOps El concepto de DevSecOps DevSecOps o DevOps seguro trata de introducir la seguridad antes en el ciclo de vida del desarrollo de aplicaciones, minimizando as\u00ed el impacto de las vulnerabilidades y acercando la seguridad al equipo de desarrollo. Por qu\u00e9 Al adoptar la mentalidad de \"cambio a la izquierda\", DevSecOps alienta a las organizaciones a cerrar la brecha que a menudo existe entre los equipos de desarrollo y seguridad hasta el punto en que muchos de los procesos de seguridad est\u00e1n automatizados y son manejados de manera efectiva por el equipo de desarrollo. Pr\u00e1cticas de DevSecOps Esta secci\u00f3n cubre diferentes herramientas, frameworks y recursos que permiten la introducci\u00f3n de las mejores pr\u00e1cticas de DevSecOps a su proyecto en las primeras etapas de desarrollo. T\u00f3picos cubiertos: Escaneo de credenciales : inspecci\u00f3n autom\u00e1tica de un proyecto para garantizar que no se incluyan secretos en el c\u00f3digo fuente del proyecto. Rotaci\u00f3n de secretos : proceso automatizado mediante el cual el secreto, utilizado por la aplicaci\u00f3n, se actualiza y se reemplaza por un nuevo secreto. An\u00e1lisis de c\u00f3digo est\u00e1tico : analice el c\u00f3digo fuente o las versiones compiladas del c\u00f3digo para ayudar a encontrar fallas de seguridad. Pruebas de penetraci\u00f3n : un ataque simulado contra su aplicaci\u00f3n para verificar vulnerabilidades explotables. Escaneo de dependencias de contenedores : busca vulnerabilidades en sistemas operativos de contenedores, paquetes de lenguajes y dependencias de aplicaciones.","title":"DevSecOps"},{"location":"CI_CD/dev-sec-ops/#devsecops","text":"","title":"DevSecOps"},{"location":"CI_CD/dev-sec-ops/#el-concepto-de-devsecops","text":"DevSecOps o DevOps seguro trata de introducir la seguridad antes en el ciclo de vida del desarrollo de aplicaciones, minimizando as\u00ed el impacto de las vulnerabilidades y acercando la seguridad al equipo de desarrollo.","title":"El concepto de DevSecOps"},{"location":"CI_CD/dev-sec-ops/#por-que","text":"Al adoptar la mentalidad de \"cambio a la izquierda\", DevSecOps alienta a las organizaciones a cerrar la brecha que a menudo existe entre los equipos de desarrollo y seguridad hasta el punto en que muchos de los procesos de seguridad est\u00e1n automatizados y son manejados de manera efectiva por el equipo de desarrollo.","title":"Por qu\u00e9"},{"location":"CI_CD/dev-sec-ops/#practicas-de-devsecops","text":"Esta secci\u00f3n cubre diferentes herramientas, frameworks y recursos que permiten la introducci\u00f3n de las mejores pr\u00e1cticas de DevSecOps a su proyecto en las primeras etapas de desarrollo. T\u00f3picos cubiertos: Escaneo de credenciales : inspecci\u00f3n autom\u00e1tica de un proyecto para garantizar que no se incluyan secretos en el c\u00f3digo fuente del proyecto. Rotaci\u00f3n de secretos : proceso automatizado mediante el cual el secreto, utilizado por la aplicaci\u00f3n, se actualiza y se reemplaza por un nuevo secreto. An\u00e1lisis de c\u00f3digo est\u00e1tico : analice el c\u00f3digo fuente o las versiones compiladas del c\u00f3digo para ayudar a encontrar fallas de seguridad. Pruebas de penetraci\u00f3n : un ataque simulado contra su aplicaci\u00f3n para verificar vulnerabilidades explotables. Escaneo de dependencias de contenedores : busca vulnerabilidades en sistemas operativos de contenedores, paquetes de lenguajes y dependencias de aplicaciones.","title":"Pr\u00e1cticas de DevSecOps"},{"location":"CI_CD/dev-sec-ops/dependency_container_scanning/","text":"","title":"Dependency container scanning"},{"location":"CI_CD/dev-sec-ops/penetration_testing/","text":"","title":"Penetration testing"},{"location":"CI_CD/dev-sec-ops/static_code_analysis/","text":"","title":"Static code analysis"},{"location":"CI_CD/dev-sec-ops/gesti%C3%B3n%20de%20secretos/credential_scanning/","text":"","title":"Credential scanning"},{"location":"CI_CD/dev-sec-ops/gesti%C3%B3n%20de%20secretos/secrets_rotation/","text":"","title":"Secrets rotation"},{"location":"observabilidad/","text":"Observabilidad La creaci\u00f3n de sistemas observables permite a los equipos de desarrollo medir qu\u00e9 tan bien se est\u00e1 comportando la aplicaci\u00f3n. La observabilidad sirve para los siguientes objetivos: Proporcionar una visi\u00f3n hol\u00edstica del estado de la aplicaci\u00f3n. Ayudar a medir el rendimiento empresarial para el cliente. Medir el rendimiento operativo del sistema. Identificar y diagnosticar fallas para llegar al problema r\u00e1pidamente. Pilares de Observabilidad Logs M\u00e9tricas Trazas Logs vs M\u00e9tricas vs Trazas Insights Dashboards y Reportes Herramientas, patrones y pr\u00e1cticas recomendadas Herramientas y Patrones Observabilidad como c\u00f3digo Pr\u00e1cticas Recomendadas Herramientas de diagn\u00f3stico OpenTelemetry Facetas de la observabilidad Observabilidad para Microservicios Observabilidad en el aprendizaje autom\u00e1tico Observabilidad de canalizaciones de CI/CD Observabilidad en Azure Databricks Recetas Enlaces \u00fatiles Gu\u00eda de requisitos no funcionales","title":"Observabilidad"},{"location":"observabilidad/#observabilidad","text":"La creaci\u00f3n de sistemas observables permite a los equipos de desarrollo medir qu\u00e9 tan bien se est\u00e1 comportando la aplicaci\u00f3n. La observabilidad sirve para los siguientes objetivos: Proporcionar una visi\u00f3n hol\u00edstica del estado de la aplicaci\u00f3n. Ayudar a medir el rendimiento empresarial para el cliente. Medir el rendimiento operativo del sistema. Identificar y diagnosticar fallas para llegar al problema r\u00e1pidamente.","title":"Observabilidad"},{"location":"observabilidad/#pilares-de-observabilidad","text":"Logs M\u00e9tricas Trazas Logs vs M\u00e9tricas vs Trazas","title":"Pilares de Observabilidad"},{"location":"observabilidad/#insights","text":"Dashboards y Reportes","title":"Insights"},{"location":"observabilidad/#herramientas-patrones-y-practicas-recomendadas","text":"Herramientas y Patrones Observabilidad como c\u00f3digo Pr\u00e1cticas Recomendadas Herramientas de diagn\u00f3stico OpenTelemetry","title":"Herramientas, patrones y pr\u00e1cticas recomendadas"},{"location":"observabilidad/#facetas-de-la-observabilidad","text":"Observabilidad para Microservicios Observabilidad en el aprendizaje autom\u00e1tico Observabilidad de canalizaciones de CI/CD Observabilidad en Azure Databricks Recetas","title":"Facetas de la observabilidad"},{"location":"observabilidad/#enlaces-utiles","text":"Gu\u00eda de requisitos no funcionales","title":"Enlaces \u00fatiles"},{"location":"observabilidad/alerting/","text":"Gu\u00eda para Alertas Uno de los objetivos de construir sistemas altamente observables es proporcionar informaci\u00f3n valiosa sobre el comportamiento de la aplicaci\u00f3n. Los sistemas observables permiten que los problemas se identifiquen y emerjan a trav\u00e9s de alertas antes de que los usuarios finales se vean afectados. Mejores pr\u00e1cticas Lo m\u00e1s importante que debe hacer antes de crear alertas es implementar la observabilidad. Sin sistemas de monitoreo implementados, se vuelve casi imposible saber qu\u00e9 actividades deben monitorearse y cu\u00e1ndo alertar a los equipos. Identificar cu\u00e1l debe ser la calidad de servicio viable m\u00ednima de la aplicaci\u00f3n. No es lo que pretende entregar, pero es aceptable para el cliente. Estos Service Level Objectives (SLO) son una m\u00e9trica para medir el rendimiento de la aplicaci\u00f3n. Los SLO se definen con respecto a los usuarios finales. Las alertas deben buscar un impacto visible para el usuario. Por ejemplo, alertas sobre la tasa de solicitudes, la latencia y los errores. Utilizar herramientas de script automatizadas para imitar las rutas de c\u00f3digo importantes relacionadas con actividades en la aplicaci\u00f3n. Cree pol\u00edticas de alerta sobre los eventos que impactan al usuario. Se recomienda a los ingenieros que presten atenci\u00f3n a su sistema de monitoreo para que se puedan definir alertas y umbrales precisos. Establecer un canal principal para las alertas que necesitan atenci\u00f3n inmediata y etiquete al equipo o personas indicadas seg\u00fan la naturaleza del incidente. No es necesario enviar todas las alertas al canal principal de guardia. Establecer un canal secundario para los elementos que deben investigarse y que a\u00fan no afectan a los usuarios. Estos elementos ser\u00e1n los que los servicios de ingenier\u00eda revisar\u00e1n regularmente para monitorear la salud del sistema. Es importante aprender de cada incidente y mejorar continuamente el proceso. Despu\u00e9s de que se haya clasificado cada incidente, realice una autopsia del escenario. Ocurrir\u00e1n escenarios y situaciones que no se consideraron inicialmente, y el flujo de trabajo post-mortem es una excelente manera de resaltar eso para mejorar el monitoreo/alertas del sistema.","title":"Gu\u00eda para Alertas"},{"location":"observabilidad/alerting/#guia-para-alertas","text":"Uno de los objetivos de construir sistemas altamente observables es proporcionar informaci\u00f3n valiosa sobre el comportamiento de la aplicaci\u00f3n. Los sistemas observables permiten que los problemas se identifiquen y emerjan a trav\u00e9s de alertas antes de que los usuarios finales se vean afectados.","title":"Gu\u00eda para Alertas"},{"location":"observabilidad/alerting/#mejores-practicas","text":"Lo m\u00e1s importante que debe hacer antes de crear alertas es implementar la observabilidad. Sin sistemas de monitoreo implementados, se vuelve casi imposible saber qu\u00e9 actividades deben monitorearse y cu\u00e1ndo alertar a los equipos. Identificar cu\u00e1l debe ser la calidad de servicio viable m\u00ednima de la aplicaci\u00f3n. No es lo que pretende entregar, pero es aceptable para el cliente. Estos Service Level Objectives (SLO) son una m\u00e9trica para medir el rendimiento de la aplicaci\u00f3n. Los SLO se definen con respecto a los usuarios finales. Las alertas deben buscar un impacto visible para el usuario. Por ejemplo, alertas sobre la tasa de solicitudes, la latencia y los errores. Utilizar herramientas de script automatizadas para imitar las rutas de c\u00f3digo importantes relacionadas con actividades en la aplicaci\u00f3n. Cree pol\u00edticas de alerta sobre los eventos que impactan al usuario. Se recomienda a los ingenieros que presten atenci\u00f3n a su sistema de monitoreo para que se puedan definir alertas y umbrales precisos. Establecer un canal principal para las alertas que necesitan atenci\u00f3n inmediata y etiquete al equipo o personas indicadas seg\u00fan la naturaleza del incidente. No es necesario enviar todas las alertas al canal principal de guardia. Establecer un canal secundario para los elementos que deben investigarse y que a\u00fan no afectan a los usuarios. Estos elementos ser\u00e1n los que los servicios de ingenier\u00eda revisar\u00e1n regularmente para monitorear la salud del sistema. Es importante aprender de cada incidente y mejorar continuamente el proceso. Despu\u00e9s de que se haya clasificado cada incidente, realice una autopsia del escenario. Ocurrir\u00e1n escenarios y situaciones que no se consideraron inicialmente, y el flujo de trabajo post-mortem es una excelente manera de resaltar eso para mejorar el monitoreo/alertas del sistema.","title":"Mejores pr\u00e1cticas"},{"location":"observabilidad/best-practices/","text":"Pr\u00e1cticas Recomendadas Id. de correlaci\u00f3n: incluya un identificador \u00fanico al comienzo de la interacci\u00f3n para vincular los datos agregados de varios componentes del sistema y proporcionar una vista hol\u00edstica. Supervisar el estado de los servicios y proporcionar informaci\u00f3n sobre el rendimiento y el comportamiento del sistema. Los servicios dependientes se deben supervisar correctamente. Adem\u00e1s, las m\u00e9tricas relacionadas con los servicios dependientes deben capturarse y registrarse. Los defectos, bloqueos y fallas se registran como eventos discretos. Esto ayuda a los ingenieros a identificar las \u00e1reas problem\u00e1ticas durante las fallas. La configuraci\u00f3n de logueo se puede controlar sin cambios en el c\u00f3digo. Las m\u00e9tricas sobre la latencia y la duraci\u00f3n se recopilen y se puedan agregar. Comience poco a poco y agregue donde haya impacto en el cliente. Es importante que todos los datos que se recopilen contengan un contexto rico y relevante. La informaci\u00f3n de identificaci\u00f3n personal o cualquier otra informaci\u00f3n confidencial nunca debe registrarse. Comprobaciones de estado: se deben agregar comprobaciones de estado adecuadas para determinar si el servicio est\u00e1 en buen estado y listo para atender el tr\u00e1fico.","title":"Pr\u00e1cticas Recomendadas"},{"location":"observabilidad/best-practices/#practicas-recomendadas","text":"Id. de correlaci\u00f3n: incluya un identificador \u00fanico al comienzo de la interacci\u00f3n para vincular los datos agregados de varios componentes del sistema y proporcionar una vista hol\u00edstica. Supervisar el estado de los servicios y proporcionar informaci\u00f3n sobre el rendimiento y el comportamiento del sistema. Los servicios dependientes se deben supervisar correctamente. Adem\u00e1s, las m\u00e9tricas relacionadas con los servicios dependientes deben capturarse y registrarse. Los defectos, bloqueos y fallas se registran como eventos discretos. Esto ayuda a los ingenieros a identificar las \u00e1reas problem\u00e1ticas durante las fallas. La configuraci\u00f3n de logueo se puede controlar sin cambios en el c\u00f3digo. Las m\u00e9tricas sobre la latencia y la duraci\u00f3n se recopilen y se puedan agregar. Comience poco a poco y agregue donde haya impacto en el cliente. Es importante que todos los datos que se recopilen contengan un contexto rico y relevante. La informaci\u00f3n de identificaci\u00f3n personal o cualquier otra informaci\u00f3n confidencial nunca debe registrarse. Comprobaciones de estado: se deben agregar comprobaciones de estado adecuadas para determinar si el servicio est\u00e1 en buen estado y listo para atender el tr\u00e1fico.","title":"Pr\u00e1cticas Recomendadas"},{"location":"observabilidad/diagnostic-tools/","text":"Herramientas de diagnostico Adem\u00e1s de logging, tracing y m\u00e9tricas, existen herramientas adicionales para ayudar a diagnosticar problemas cuando las aplicaciones no se comportan como se esperaba. En estos casos, las herramientas de diagn\u00f3stico espec\u00edficas de la plataforma o el lenguaje de programaci\u00f3n entran en juego y son \u00fatiles para depurar problemas de memoria, perfilar el uso de la CPU o la causa de los retrasos. Perfiladores y analizadores de memoria Hay dos tipos de herramientas de diagn\u00f3stico que puede utilizar: generadores de perfiles y analizadores de memoria. Profiling La creaci\u00f3n de perfiles es una t\u00e9cnica en la que toma peque\u00f1as instant\u00e1neas de todos los subprocesos en una aplicaci\u00f3n en ejecuci\u00f3n para ver el seguimiento de la pila de cada subproceso durante un per\u00edodo espec\u00edfico. Esta herramienta puede ayudarlo a identificar d\u00f3nde est\u00e1 gastando tiempo de CPU durante la ejecuci\u00f3n de su aplicaci\u00f3n. Hay dos t\u00e9cnicas principales para lograr esto: muestreo de CPU e instrumentaci\u00f3n. El muestreo de CPU es un m\u00e9todo no invasivo que toma instant\u00e1neas de todas las pilas en un intervalo establecido. Es la t\u00e9cnica m\u00e1s com\u00fan para generar perfiles y no requiere ninguna modificaci\u00f3n en su c\u00f3digo. La instrumentaci\u00f3n es la otra t\u00e9cnica en la que inserta un peque\u00f1o fragmento de c\u00f3digo al principio y al final de cada funci\u00f3n que le indicar\u00e1 al generador de perfiles el tiempo dedicado a la funci\u00f3n, el nombre de la funci\u00f3n, los par\u00e1metros y otros. De esta manera, modifica el c\u00f3digo de su aplicaci\u00f3n en ejecuci\u00f3n. Esto tiene dos efectos: su c\u00f3digo puede ejecutarse un poco m\u00e1s lento, pero por otro lado, tiene una vista m\u00e1s precisa de cada funci\u00f3n y clase que se ha ejecutado. Analizadores de memoria Los analizadores de memoria y los volcados de memoria son otro conjunto de herramientas de diagn\u00f3stico que puede utilizar para identificar problemas en su proceso. Normalmente, este tipo de herramientas toman toda la memoria que el proceso est\u00e1 usando en un momento dado y la guardan en un archivo que se puede analizar. Hay varias formas de realizar un volcado de memoria seg\u00fan el sistema operativo que est\u00e9 utilizando. Adem\u00e1s, cada sistema operativo tiene su propio depurador que puede cargar este volcado de memoria y explorar el estado del proceso en el momento en que se realiz\u00f3 el volcado de memoria. Los depuradores m\u00e1s comunes son: Windows: WinDbg y WinDgbNext (incluidos en el SDK de Windows), Visual Studio tambi\u00e9n puede cargar un volcado de memoria para un proceso de .NET Framework y .NET Core Linux - GDB es el depurador de GNU Mac OS - LLDB Debugger Hay una gama de herramientas de diagn\u00f3stico espec\u00edficas de la plataforma del desarrollador que se pueden utilizar: .NET Core , GitHub Repo Java Python Node.js Entorno para perfilado Para crear un perfil de aplicaci\u00f3n lo m\u00e1s cercano posible a la producci\u00f3n, se debe considerar el entorno en el que se pretende que la aplicaci\u00f3n se ejecute en producci\u00f3n y podr\u00eda ser necesario realizar una instant\u00e1nea del estado de la aplicaci\u00f3n bajo carga. Diagn\u00f3stico en contenedores Para aplicaciones monol\u00edticas, las herramientas de diagn\u00f3stico se pueden instalar y ejecutar en la m\u00e1quina virtual que las aloja. La mayor\u00eda de las aplicaciones escalables se desarrollan como microservicios y tienen interacciones complejas que requieren instalar las herramientas en los contenedores que ejecutan el proceso o aprovechar un contenedor sidecar . Algunas plataformas exponen endpoints para interactuar con la aplicaci\u00f3n y devolver un volcado.","title":"Herramientas de diagnostico"},{"location":"observabilidad/diagnostic-tools/#herramientas-de-diagnostico","text":"Adem\u00e1s de logging, tracing y m\u00e9tricas, existen herramientas adicionales para ayudar a diagnosticar problemas cuando las aplicaciones no se comportan como se esperaba. En estos casos, las herramientas de diagn\u00f3stico espec\u00edficas de la plataforma o el lenguaje de programaci\u00f3n entran en juego y son \u00fatiles para depurar problemas de memoria, perfilar el uso de la CPU o la causa de los retrasos.","title":"Herramientas de diagnostico"},{"location":"observabilidad/diagnostic-tools/#perfiladores-y-analizadores-de-memoria","text":"Hay dos tipos de herramientas de diagn\u00f3stico que puede utilizar: generadores de perfiles y analizadores de memoria.","title":"Perfiladores y analizadores de memoria"},{"location":"observabilidad/diagnostic-tools/#profiling","text":"La creaci\u00f3n de perfiles es una t\u00e9cnica en la que toma peque\u00f1as instant\u00e1neas de todos los subprocesos en una aplicaci\u00f3n en ejecuci\u00f3n para ver el seguimiento de la pila de cada subproceso durante un per\u00edodo espec\u00edfico. Esta herramienta puede ayudarlo a identificar d\u00f3nde est\u00e1 gastando tiempo de CPU durante la ejecuci\u00f3n de su aplicaci\u00f3n. Hay dos t\u00e9cnicas principales para lograr esto: muestreo de CPU e instrumentaci\u00f3n. El muestreo de CPU es un m\u00e9todo no invasivo que toma instant\u00e1neas de todas las pilas en un intervalo establecido. Es la t\u00e9cnica m\u00e1s com\u00fan para generar perfiles y no requiere ninguna modificaci\u00f3n en su c\u00f3digo. La instrumentaci\u00f3n es la otra t\u00e9cnica en la que inserta un peque\u00f1o fragmento de c\u00f3digo al principio y al final de cada funci\u00f3n que le indicar\u00e1 al generador de perfiles el tiempo dedicado a la funci\u00f3n, el nombre de la funci\u00f3n, los par\u00e1metros y otros. De esta manera, modifica el c\u00f3digo de su aplicaci\u00f3n en ejecuci\u00f3n. Esto tiene dos efectos: su c\u00f3digo puede ejecutarse un poco m\u00e1s lento, pero por otro lado, tiene una vista m\u00e1s precisa de cada funci\u00f3n y clase que se ha ejecutado.","title":"Profiling"},{"location":"observabilidad/diagnostic-tools/#analizadores-de-memoria","text":"Los analizadores de memoria y los volcados de memoria son otro conjunto de herramientas de diagn\u00f3stico que puede utilizar para identificar problemas en su proceso. Normalmente, este tipo de herramientas toman toda la memoria que el proceso est\u00e1 usando en un momento dado y la guardan en un archivo que se puede analizar. Hay varias formas de realizar un volcado de memoria seg\u00fan el sistema operativo que est\u00e9 utilizando. Adem\u00e1s, cada sistema operativo tiene su propio depurador que puede cargar este volcado de memoria y explorar el estado del proceso en el momento en que se realiz\u00f3 el volcado de memoria. Los depuradores m\u00e1s comunes son: Windows: WinDbg y WinDgbNext (incluidos en el SDK de Windows), Visual Studio tambi\u00e9n puede cargar un volcado de memoria para un proceso de .NET Framework y .NET Core Linux - GDB es el depurador de GNU Mac OS - LLDB Debugger Hay una gama de herramientas de diagn\u00f3stico espec\u00edficas de la plataforma del desarrollador que se pueden utilizar: .NET Core , GitHub Repo Java Python Node.js","title":"Analizadores de memoria"},{"location":"observabilidad/diagnostic-tools/#entorno-para-perfilado","text":"Para crear un perfil de aplicaci\u00f3n lo m\u00e1s cercano posible a la producci\u00f3n, se debe considerar el entorno en el que se pretende que la aplicaci\u00f3n se ejecute en producci\u00f3n y podr\u00eda ser necesario realizar una instant\u00e1nea del estado de la aplicaci\u00f3n bajo carga.","title":"Entorno para perfilado"},{"location":"observabilidad/diagnostic-tools/#diagnostico-en-contenedores","text":"Para aplicaciones monol\u00edticas, las herramientas de diagn\u00f3stico se pueden instalar y ejecutar en la m\u00e1quina virtual que las aloja. La mayor\u00eda de las aplicaciones escalables se desarrollan como microservicios y tienen interacciones complejas que requieren instalar las herramientas en los contenedores que ejecutan el proceso o aprovechar un contenedor sidecar . Algunas plataformas exponen endpoints para interactuar con la aplicaci\u00f3n y devolver un volcado.","title":"Diagn\u00f3stico en contenedores"},{"location":"observabilidad/log-vs-metric-vs-trace/","text":"Logs vs M\u00e9tricas vs Trazas M\u00e9tricas Su prop\u00f3sito es informar sobre la salud y las operaciones con respecto a un componente o sistema. Una m\u00e9trica representa una medida de un punto en el tiempo de una fuente en particular. Las m\u00e9tricas tambi\u00e9n se prestan muy bien a la agregaci\u00f3n previa dentro del componente antes de la recopilaci\u00f3n, lo que reduce el costo de c\u00f3mputo para procesar y almacenar grandes cantidades de series temporales. Debido a la eficiencia con la que se procesan y almacenan las m\u00e9tricas, se presta muy bien para su uso en alertas automatizadas. Logs Informan sobre los eventos discretos que ocurrieron dentro de un componente o un conjunto de componentes. Estos datos enriquecidos tienden a ser mucho m\u00e1s grandes que los datos m\u00e9tricos y pueden causar problemas de procesamiento, especialmente si los componentes se registran de forma demasiado detallada. Por lo tanto, el uso de datos de log tiende a evitarse y depende de las m\u00e9tricas para esos datos. Una vez que la telemetr\u00eda resalta las posibles fuentes de problemas, los datos de log filtrados para esas fuentes se pueden usar para comprender lo que ocurri\u00f3. Trazas A diferencia del logueo, abarca una vista mucho m\u00e1s amplia y continua de una aplicaci\u00f3n. El objetivo es seguir el flujo de un programa y la progresi\u00f3n de los datos. Su prop\u00f3sito no es reactivo, sino que se centra en la optimizaci\u00f3n. Al tracear a trav\u00e9s de una pila, los desarrolladores pueden identificar cuellos de botella y enfocarse en mejorar el rendimiento. Cuando ocurre un problema, el tracing le permite ver c\u00f3mo lleg\u00f3 all\u00ed: Cual funci\u00f3n. La duraci\u00f3n de la funci\u00f3n. Par\u00e1metros pasados. Gu\u00eda de uso Utilice m\u00e9tricas para realizar un seguimiento de la ocurrencia de un evento, el conteo de elementos, el tiempo necesario para realizar una acci\u00f3n o para informar el valor actual de un recurso (CPU, memoria, etc.) Utilice logs para realizar un seguimiento de la informaci\u00f3n detallada sobre un evento tambi\u00e9n supervisado por una m\u00e9trica, en particular errores, advertencias u otras situaciones excepcionales. Una traza proporciona visibilidad sobre c\u00f3mo se procesa una solicitud en varios servicios en un entorno de microservicios.","title":"Logs vs M\u00e9tricas vs Trazas"},{"location":"observabilidad/log-vs-metric-vs-trace/#logs-vs-metricas-vs-trazas","text":"","title":"Logs vs M\u00e9tricas vs Trazas"},{"location":"observabilidad/log-vs-metric-vs-trace/#metricas","text":"Su prop\u00f3sito es informar sobre la salud y las operaciones con respecto a un componente o sistema. Una m\u00e9trica representa una medida de un punto en el tiempo de una fuente en particular. Las m\u00e9tricas tambi\u00e9n se prestan muy bien a la agregaci\u00f3n previa dentro del componente antes de la recopilaci\u00f3n, lo que reduce el costo de c\u00f3mputo para procesar y almacenar grandes cantidades de series temporales. Debido a la eficiencia con la que se procesan y almacenan las m\u00e9tricas, se presta muy bien para su uso en alertas automatizadas.","title":"M\u00e9tricas"},{"location":"observabilidad/log-vs-metric-vs-trace/#logs","text":"Informan sobre los eventos discretos que ocurrieron dentro de un componente o un conjunto de componentes. Estos datos enriquecidos tienden a ser mucho m\u00e1s grandes que los datos m\u00e9tricos y pueden causar problemas de procesamiento, especialmente si los componentes se registran de forma demasiado detallada. Por lo tanto, el uso de datos de log tiende a evitarse y depende de las m\u00e9tricas para esos datos. Una vez que la telemetr\u00eda resalta las posibles fuentes de problemas, los datos de log filtrados para esas fuentes se pueden usar para comprender lo que ocurri\u00f3.","title":"Logs"},{"location":"observabilidad/log-vs-metric-vs-trace/#trazas","text":"A diferencia del logueo, abarca una vista mucho m\u00e1s amplia y continua de una aplicaci\u00f3n. El objetivo es seguir el flujo de un programa y la progresi\u00f3n de los datos. Su prop\u00f3sito no es reactivo, sino que se centra en la optimizaci\u00f3n. Al tracear a trav\u00e9s de una pila, los desarrolladores pueden identificar cuellos de botella y enfocarse en mejorar el rendimiento. Cuando ocurre un problema, el tracing le permite ver c\u00f3mo lleg\u00f3 all\u00ed: Cual funci\u00f3n. La duraci\u00f3n de la funci\u00f3n. Par\u00e1metros pasados.","title":"Trazas"},{"location":"observabilidad/log-vs-metric-vs-trace/#guia-de-uso","text":"Utilice m\u00e9tricas para realizar un seguimiento de la ocurrencia de un evento, el conteo de elementos, el tiempo necesario para realizar una acci\u00f3n o para informar el valor actual de un recurso (CPU, memoria, etc.) Utilice logs para realizar un seguimiento de la informaci\u00f3n detallada sobre un evento tambi\u00e9n supervisado por una m\u00e9trica, en particular errores, advertencias u otras situaciones excepcionales. Una traza proporciona visibilidad sobre c\u00f3mo se procesa una solicitud en varios servicios en un entorno de microservicios.","title":"Gu\u00eda de uso"},{"location":"observabilidad/ml-observability/","text":"Observabilidad en Machine Learning El proceso de desarrollo del sistema de software con componente de aprendizaje autom\u00e1tico es m\u00e1s complejo que el software tradicional. Necesitamos monitorear cambios y variaciones en tres dimensiones: el c\u00f3digo, el modelo y los datos. Podemos distinguir dos etapas de la vida \u00fatil de dicho sistema: la experimentaci\u00f3n y la producci\u00f3n que requieren diferentes enfoques de la observabilidad, como se analiza a continuaci\u00f3n: Modelo en experimentaci\u00f3n y tuning La experimentaci\u00f3n es un proceso para encontrar un modelo de aprendizaje autom\u00e1tico adecuado y sus par\u00e1metros mediante el entrenamiento y la evaluaci\u00f3n de dichos modelos con uno o m\u00e1s conjuntos de datos. Al desarrollar y ajustar modelos de aprendizaje autom\u00e1tico, los cient\u00edficos de datos est\u00e1n interesados en observar y comparar m\u00e9tricas de rendimiento seleccionadas para varios par\u00e1metros del modelo. Tambi\u00e9n necesitan una forma confiable de reproducir un proceso de entrenamiento, de modo que un conjunto de datos y par\u00e1metros dados produzcan los mismos modelos. Hay muchas soluciones de evaluaci\u00f3n de m\u00e9tricas de modelos disponibles, tanto de c\u00f3digo abierto (MLFlow, TensorBoard) como propietarias (Azure Machine Learning, Application Insights). Modelo en producci\u00f3n El modelo entrenado se puede implementar en producci\u00f3n como contenedor. El servicio Azure Machine Learning proporciona SDK para implementar el modelo como Azure Container Instance y publica el punto de conexi\u00f3n REST. Puede monitorearlo utilizando m\u00e9todos de observabilidad de microservicios. MLFLow es una forma alternativa de implementar el modelo ML como servicio. Entrenamiento y reentrenamiento Para volver a entrenar autom\u00e1ticamente el modelo, puede usar AML Pipelines o Azure Databricks. Al volver a entrenarse con AML Pipelines, puede monitorear la informaci\u00f3n de cada ejecuci\u00f3n, incluida la salida, los logs y varias m\u00e9tricas en el panel de experimentos de Azure Portal, o extraerla manualmente con el SDK de AML. Rendimiento del modelo a lo largo del tiempo: data drift Volvemos a entrenar los modelos de aprendizaje autom\u00e1tico para mejorar su rendimiento y hacer que los modelos est\u00e9n mejor alineados con los datos que cambian con el tiempo. Sin embargo, en algunos casos, el rendimiento del modelo puede degradarse. Esto puede suceder en caso de que los datos cambien dr\u00e1sticamente y ya no muestren los patrones que observamos durante el desarrollo del modelo. Este efecto se denomina data drift. Azure Machine Learning Service tiene una funci\u00f3n de vista previa para observar e informar la deriva de datos. Este art\u00edculo lo describe en detalle. Versionado de datos Se recomienda como pr\u00e1ctica agregar una versi\u00f3n a todos los conjuntos de datos. Puede crear un conjunto de datos de Azure ML con versi\u00f3n para este prop\u00f3sito, o crear una versi\u00f3n manual si usa otros sistemas.","title":"Observabilidad en Machine Learning"},{"location":"observabilidad/ml-observability/#observabilidad-en-machine-learning","text":"El proceso de desarrollo del sistema de software con componente de aprendizaje autom\u00e1tico es m\u00e1s complejo que el software tradicional. Necesitamos monitorear cambios y variaciones en tres dimensiones: el c\u00f3digo, el modelo y los datos. Podemos distinguir dos etapas de la vida \u00fatil de dicho sistema: la experimentaci\u00f3n y la producci\u00f3n que requieren diferentes enfoques de la observabilidad, como se analiza a continuaci\u00f3n:","title":"Observabilidad en Machine Learning"},{"location":"observabilidad/ml-observability/#modelo-en-experimentacion-y-tuning","text":"La experimentaci\u00f3n es un proceso para encontrar un modelo de aprendizaje autom\u00e1tico adecuado y sus par\u00e1metros mediante el entrenamiento y la evaluaci\u00f3n de dichos modelos con uno o m\u00e1s conjuntos de datos. Al desarrollar y ajustar modelos de aprendizaje autom\u00e1tico, los cient\u00edficos de datos est\u00e1n interesados en observar y comparar m\u00e9tricas de rendimiento seleccionadas para varios par\u00e1metros del modelo. Tambi\u00e9n necesitan una forma confiable de reproducir un proceso de entrenamiento, de modo que un conjunto de datos y par\u00e1metros dados produzcan los mismos modelos. Hay muchas soluciones de evaluaci\u00f3n de m\u00e9tricas de modelos disponibles, tanto de c\u00f3digo abierto (MLFlow, TensorBoard) como propietarias (Azure Machine Learning, Application Insights).","title":"Modelo en experimentaci\u00f3n y tuning"},{"location":"observabilidad/ml-observability/#modelo-en-produccion","text":"El modelo entrenado se puede implementar en producci\u00f3n como contenedor. El servicio Azure Machine Learning proporciona SDK para implementar el modelo como Azure Container Instance y publica el punto de conexi\u00f3n REST. Puede monitorearlo utilizando m\u00e9todos de observabilidad de microservicios. MLFLow es una forma alternativa de implementar el modelo ML como servicio.","title":"Modelo en producci\u00f3n"},{"location":"observabilidad/ml-observability/#entrenamiento-y-reentrenamiento","text":"Para volver a entrenar autom\u00e1ticamente el modelo, puede usar AML Pipelines o Azure Databricks. Al volver a entrenarse con AML Pipelines, puede monitorear la informaci\u00f3n de cada ejecuci\u00f3n, incluida la salida, los logs y varias m\u00e9tricas en el panel de experimentos de Azure Portal, o extraerla manualmente con el SDK de AML.","title":"Entrenamiento y reentrenamiento"},{"location":"observabilidad/ml-observability/#rendimiento-del-modelo-a-lo-largo-del-tiempo-data-drift","text":"Volvemos a entrenar los modelos de aprendizaje autom\u00e1tico para mejorar su rendimiento y hacer que los modelos est\u00e9n mejor alineados con los datos que cambian con el tiempo. Sin embargo, en algunos casos, el rendimiento del modelo puede degradarse. Esto puede suceder en caso de que los datos cambien dr\u00e1sticamente y ya no muestren los patrones que observamos durante el desarrollo del modelo. Este efecto se denomina data drift. Azure Machine Learning Service tiene una funci\u00f3n de vista previa para observar e informar la deriva de datos. Este art\u00edculo lo describe en detalle.","title":"Rendimiento del modelo a lo largo del tiempo: data drift"},{"location":"observabilidad/ml-observability/#versionado-de-datos","text":"Se recomienda como pr\u00e1ctica agregar una versi\u00f3n a todos los conjuntos de datos. Puede crear un conjunto de datos de Azure ML con versi\u00f3n para este prop\u00f3sito, o crear una versi\u00f3n manual si usa otros sistemas.","title":"Versionado de datos"},{"location":"observabilidad/observability-as-code/","text":"Observability as Code En la medida de lo posible, la configuraci\u00f3n y administraci\u00f3n de los activos de observabilidad, como el aprovisionamiento de recursos en la nube, las alertas de monitoreo y los dashboard, deben administrarse como c\u00f3digo. La observabilidad como c\u00f3digo se logra utilizando cualquiera de las plantillas Terraform / Ansible / ARM / Bicep. Ejemplos de Observability as Code Dashboards as Code: los dashboards de monitoreo se pueden crear como plantillas JSON o XML. Esta plantilla se mantiene con control de c\u00f3digo fuente. La automatizaci\u00f3n se puede construir para habilitar el dashboard. Creaci\u00f3n mediante programaci\u00f3n de paneles de Azure . Alerts as Code: las alertas se pueden crear en Azure mediante el uso de plantillas de Terraform o ARM. Estas alertas se pueden controlar desde el origen y se pueden implementar como parte de las canalizaciones. Algunas referencias de c\u00f3mo hacer esto son: Terraform Monitor Metric Alert . Las alertas tambi\u00e9n se pueden crear en funci\u00f3n de la consulta de log analytics y se pueden definir como c\u00f3digo mediante Terraform Monitor Scheduled Query Rules Alert . Automatizaci\u00f3n de consultas de Log Analytics: hay varios casos de uso en los que puede ser necesaria la automatizaci\u00f3n de consultas de log analytics. Por ejemplo, generaci\u00f3n autom\u00e1tica de informes, ejecuci\u00f3n de consultas personalizadas mediante programaci\u00f3n para an\u00e1lisis, depuraci\u00f3n, etc. Para que estos casos de uso funcionen, las consultas de log deben estar controladas por fuente y la automatizaci\u00f3n se puede crear mediante Log Analytics REST o Azure CLI. Por qu\u00e9 Hace que la configuraci\u00f3n sea repetible y automatizable. Tambi\u00e9n evita la configuraci\u00f3n manual de alertas de monitoreo y dashboards desde cero en todos los entornos. Los dashboards configurados ayudan a solucionar errores durante la integraci\u00f3n y la implementaci\u00f3n (CI/CD). Podemos auditar los cambios y revertirlos si hay alg\u00fan problema. Identificar informaci\u00f3n procesable a partir de los datos de m\u00e9tricas generados en todos los entornos. La configuraci\u00f3n y gesti\u00f3n de los activos de observabilidad como el umbral de alerta, la duraci\u00f3n y los valores de configuraci\u00f3n mediante IaC nos ayudan a evitar errores u omisiones de configuraci\u00f3n durante la implementaci\u00f3n. Al practicar la observabilidad como c\u00f3digo, el equipo puede revisar los cambios de manera similar a otras contribuciones de c\u00f3digo.","title":"Observability as Code"},{"location":"observabilidad/observability-as-code/#observability-as-code","text":"En la medida de lo posible, la configuraci\u00f3n y administraci\u00f3n de los activos de observabilidad, como el aprovisionamiento de recursos en la nube, las alertas de monitoreo y los dashboard, deben administrarse como c\u00f3digo. La observabilidad como c\u00f3digo se logra utilizando cualquiera de las plantillas Terraform / Ansible / ARM / Bicep.","title":"Observability as Code"},{"location":"observabilidad/observability-as-code/#ejemplos-de-observability-as-code","text":"Dashboards as Code: los dashboards de monitoreo se pueden crear como plantillas JSON o XML. Esta plantilla se mantiene con control de c\u00f3digo fuente. La automatizaci\u00f3n se puede construir para habilitar el dashboard. Creaci\u00f3n mediante programaci\u00f3n de paneles de Azure . Alerts as Code: las alertas se pueden crear en Azure mediante el uso de plantillas de Terraform o ARM. Estas alertas se pueden controlar desde el origen y se pueden implementar como parte de las canalizaciones. Algunas referencias de c\u00f3mo hacer esto son: Terraform Monitor Metric Alert . Las alertas tambi\u00e9n se pueden crear en funci\u00f3n de la consulta de log analytics y se pueden definir como c\u00f3digo mediante Terraform Monitor Scheduled Query Rules Alert . Automatizaci\u00f3n de consultas de Log Analytics: hay varios casos de uso en los que puede ser necesaria la automatizaci\u00f3n de consultas de log analytics. Por ejemplo, generaci\u00f3n autom\u00e1tica de informes, ejecuci\u00f3n de consultas personalizadas mediante programaci\u00f3n para an\u00e1lisis, depuraci\u00f3n, etc. Para que estos casos de uso funcionen, las consultas de log deben estar controladas por fuente y la automatizaci\u00f3n se puede crear mediante Log Analytics REST o Azure CLI.","title":"Ejemplos de Observability as Code"},{"location":"observabilidad/observability-as-code/#por-que","text":"Hace que la configuraci\u00f3n sea repetible y automatizable. Tambi\u00e9n evita la configuraci\u00f3n manual de alertas de monitoreo y dashboards desde cero en todos los entornos. Los dashboards configurados ayudan a solucionar errores durante la integraci\u00f3n y la implementaci\u00f3n (CI/CD). Podemos auditar los cambios y revertirlos si hay alg\u00fan problema. Identificar informaci\u00f3n procesable a partir de los datos de m\u00e9tricas generados en todos los entornos. La configuraci\u00f3n y gesti\u00f3n de los activos de observabilidad como el umbral de alerta, la duraci\u00f3n y los valores de configuraci\u00f3n mediante IaC nos ayudan a evitar errores u omisiones de configuraci\u00f3n durante la implementaci\u00f3n. Al practicar la observabilidad como c\u00f3digo, el equipo puede revisar los cambios de manera similar a otras contribuciones de c\u00f3digo.","title":"Por qu\u00e9"},{"location":"observabilidad/observability-pipelines/","text":"Observabilidad de pipelines de CI/CD Con la creciente complejidad de las canalizaciones de entrega, es muy importante tener en cuenta la Observabilidad en el contexto de la creaci\u00f3n y el release de aplicaciones. Beneficios Tener la instrumentaci\u00f3n adecuada durante el tiempo de compilaci\u00f3n ayuda a obtener informaci\u00f3n sobre las diversas etapas del proceso de compilaci\u00f3n y release. Ayuda a los desarrolladores a comprender d\u00f3nde se encuentran los cuellos de botella en el rendimiento de la canalizaci\u00f3n, seg\u00fan los datos recopilados. Esto ayuda a tener conversaciones basadas en datos sobre la identificaci\u00f3n de latencia entre trabajos, problemas de rendimiento, tiempos de carga/descarga de artefactos, lo que proporciona informaci\u00f3n valiosa sobre la disponibilidad y la capacidad de los agentes. Ayuda a identificar tendencias en fallas, lo que permite a los desarrolladores realizar r\u00e1pidamente un an\u00e1lisis de causa ra\u00edz. Ayuda a proporcionar una vista de toda la organizaci\u00f3n del estado de la canalizaci\u00f3n para identificar f\u00e1cilmente las tendencias. Puntos a considerar Es importante identificar los KPIs para evaluar un pipeline de CI/CD exitoso. Cuando sea necesario, se puede agregar un seguimiento adicional para registrar mejor las m\u00e9tricas de KPI. Los informes b\u00e1sicos sobre las canalizaciones est\u00e1n disponibles de forma inmediata. Es importante evaluar estos informes con respecto a los KPI para comprender si se necesita una soluci\u00f3n de informes personalizados para sus canalizaciones. Si es necesario, se pueden crear paneles personalizados con herramientas de terceros como Grafana o Power BI Dashboards.","title":"Observabilidad de pipelines de CI/CD"},{"location":"observabilidad/observability-pipelines/#observabilidad-de-pipelines-de-cicd","text":"Con la creciente complejidad de las canalizaciones de entrega, es muy importante tener en cuenta la Observabilidad en el contexto de la creaci\u00f3n y el release de aplicaciones.","title":"Observabilidad de pipelines de CI/CD"},{"location":"observabilidad/observability-pipelines/#beneficios","text":"Tener la instrumentaci\u00f3n adecuada durante el tiempo de compilaci\u00f3n ayuda a obtener informaci\u00f3n sobre las diversas etapas del proceso de compilaci\u00f3n y release. Ayuda a los desarrolladores a comprender d\u00f3nde se encuentran los cuellos de botella en el rendimiento de la canalizaci\u00f3n, seg\u00fan los datos recopilados. Esto ayuda a tener conversaciones basadas en datos sobre la identificaci\u00f3n de latencia entre trabajos, problemas de rendimiento, tiempos de carga/descarga de artefactos, lo que proporciona informaci\u00f3n valiosa sobre la disponibilidad y la capacidad de los agentes. Ayuda a identificar tendencias en fallas, lo que permite a los desarrolladores realizar r\u00e1pidamente un an\u00e1lisis de causa ra\u00edz. Ayuda a proporcionar una vista de toda la organizaci\u00f3n del estado de la canalizaci\u00f3n para identificar f\u00e1cilmente las tendencias.","title":"Beneficios"},{"location":"observabilidad/observability-pipelines/#puntos-a-considerar","text":"Es importante identificar los KPIs para evaluar un pipeline de CI/CD exitoso. Cuando sea necesario, se puede agregar un seguimiento adicional para registrar mejor las m\u00e9tricas de KPI. Los informes b\u00e1sicos sobre las canalizaciones est\u00e1n disponibles de forma inmediata. Es importante evaluar estos informes con respecto a los KPI para comprender si se necesita una soluci\u00f3n de informes personalizados para sus canalizaciones. Si es necesario, se pueden crear paneles personalizados con herramientas de terceros como Grafana o Power BI Dashboards.","title":"Puntos a considerar"},{"location":"observabilidad/profiling/","text":"Profiling Visi\u00f3n general La creaci\u00f3n de perfiles es una forma de an\u00e1lisis que mide varios componentes, como la asignaci\u00f3n de memoria, garbage collection, los subprocesos y bloqueos, las pilas de llamadas o la frecuencia y duraci\u00f3n de funciones espec\u00edficas. Se puede usar para ver qu\u00e9 funciones son las m\u00e1s costosas, lo que le permite concentrar su esfuerzo en eliminar las mayores ineficiencias lo m\u00e1s r\u00e1pido posible. Puede ayudarlo a encontrar interbloqueos, fugas de memoria o asignaci\u00f3n de memoria ineficiente, y ayudar a informar las decisiones sobre la asignaci\u00f3n de recursos (es decir, CPU o RAM). C\u00f3mo perfilar las aplicaciones La creaci\u00f3n de perfiles depende en cierta medida del lenguaje. Adem\u00e1s, Linux Perf es una buena alternativa, ya que muchos lenguajes tienen enlaces en C/C++. La creaci\u00f3n de perfiles tiene alg\u00fan costo, ya que requiere inspeccionar la pila de llamadas y, a veces, pausar la aplicaci\u00f3n por completo. Considere el costo cuando decida ajustar los par\u00e1metros de perfilaje. Desafortunadamente, cada herramienta de generaci\u00f3n de perfiles generalmente usa su propio formato para almacenar perfiles y viene con su propia visualizaci\u00f3n. Herramientas espec\u00edficas (Java, Go, Python, Ruby, eBPF) Pyroscope : perfilado continuo listo para usar. (Java and Go) Flame : perfilado de contenedores en Kubernetes. (Java, Python, Go) Datadog Continuous Profiler . (Java, Python, Go, Node.js) Instana . (Go) profefe : construye pprof para proporcionar perfiles continuos. (Java) Opsian . (Java) Eclipse Memory Analyzer .","title":"Profiling"},{"location":"observabilidad/profiling/#profiling","text":"","title":"Profiling"},{"location":"observabilidad/profiling/#vision-general","text":"La creaci\u00f3n de perfiles es una forma de an\u00e1lisis que mide varios componentes, como la asignaci\u00f3n de memoria, garbage collection, los subprocesos y bloqueos, las pilas de llamadas o la frecuencia y duraci\u00f3n de funciones espec\u00edficas. Se puede usar para ver qu\u00e9 funciones son las m\u00e1s costosas, lo que le permite concentrar su esfuerzo en eliminar las mayores ineficiencias lo m\u00e1s r\u00e1pido posible. Puede ayudarlo a encontrar interbloqueos, fugas de memoria o asignaci\u00f3n de memoria ineficiente, y ayudar a informar las decisiones sobre la asignaci\u00f3n de recursos (es decir, CPU o RAM).","title":"Visi\u00f3n general"},{"location":"observabilidad/profiling/#como-perfilar-las-aplicaciones","text":"La creaci\u00f3n de perfiles depende en cierta medida del lenguaje. Adem\u00e1s, Linux Perf es una buena alternativa, ya que muchos lenguajes tienen enlaces en C/C++. La creaci\u00f3n de perfiles tiene alg\u00fan costo, ya que requiere inspeccionar la pila de llamadas y, a veces, pausar la aplicaci\u00f3n por completo. Considere el costo cuando decida ajustar los par\u00e1metros de perfilaje. Desafortunadamente, cada herramienta de generaci\u00f3n de perfiles generalmente usa su propio formato para almacenar perfiles y viene con su propia visualizaci\u00f3n.","title":"C\u00f3mo perfilar las aplicaciones"},{"location":"observabilidad/profiling/#herramientas-especificas","text":"(Java, Go, Python, Ruby, eBPF) Pyroscope : perfilado continuo listo para usar. (Java and Go) Flame : perfilado de contenedores en Kubernetes. (Java, Python, Go) Datadog Continuous Profiler . (Java, Python, Go, Node.js) Instana . (Go) profefe : construye pprof para proporcionar perfiles continuos. (Java) Opsian . (Java) Eclipse Memory Analyzer .","title":"Herramientas espec\u00edficas"},{"location":"observabilidad/recipes-observability/","text":"Recetas Application Insights/ASP.NET GitHub Repo , Art\u00edculo Ejemplo: Configuraci\u00f3n de dashboards y alertas de Azure Monitor con Terraform GitHub Repo Reportes de Azure DevOps Pipelines con Power BI GitHub Repo Esta receta de dashboard proporciona visibilidad para canalizaciones de Azure DevOps al mostrar varias m\u00e9tricas en una tabla. Adem\u00e1s, la segunda p\u00e1gina de la plantilla visualiza las tendencias de \u00e9xito y error de canalizaci\u00f3n mediante gr\u00e1ficos de Power BI. Clase Python Logger para Application Insights usando OpenCensus GitHub Repo Este repositorio contiene la clase \"AppLogger\", que es una clase logger de Python para Application Insights mediante Opencensus. Tambi\u00e9n contiene c\u00f3digo de ejemplo que muestra el uso de \"AppLogger\".","title":"Recetas"},{"location":"observabilidad/recipes-observability/#recetas","text":"","title":"Recetas"},{"location":"observabilidad/recipes-observability/#application-insightsaspnet","text":"GitHub Repo , Art\u00edculo","title":"Application Insights/ASP.NET"},{"location":"observabilidad/recipes-observability/#ejemplo-configuracion-de-dashboards-y-alertas-de-azure-monitor-con-terraform","text":"GitHub Repo","title":"Ejemplo: Configuraci\u00f3n de dashboards y alertas de Azure Monitor con Terraform"},{"location":"observabilidad/recipes-observability/#reportes-de-azure-devops-pipelines-con-power-bi","text":"GitHub Repo Esta receta de dashboard proporciona visibilidad para canalizaciones de Azure DevOps al mostrar varias m\u00e9tricas en una tabla. Adem\u00e1s, la segunda p\u00e1gina de la plantilla visualiza las tendencias de \u00e9xito y error de canalizaci\u00f3n mediante gr\u00e1ficos de Power BI.","title":"Reportes de Azure DevOps Pipelines con Power BI"},{"location":"observabilidad/recipes-observability/#clase-python-logger-para-application-insights-usando-opencensus","text":"GitHub Repo Este repositorio contiene la clase \"AppLogger\", que es una clase logger de Python para Application Insights mediante Opencensus. Tambi\u00e9n contiene c\u00f3digo de ejemplo que muestra el uso de \"AppLogger\".","title":"Clase Python Logger para Application Insights usando OpenCensus"},{"location":"observabilidad/herramientas/","text":"Herramientas y Patrones Hay una serie de herramientas modernas para hacer que los sistemas sean observables. Al identificar y/o crear herramientas que funcionen para su sistema, aqu\u00ed hay algunas cosas que debe considerar para ayudar a guiar las opciones. Debe ser simple de integrar y f\u00e1cil de usar. Debe ser posible agregar y visualizar datos. Las herramientas deben proporcionar datos en tiempo real. Debe ser capaz de guiar a los usuarios al \u00e1rea del problema con un contexto apropiado de extremo a extremo. Opciones Loki OpenTelemetry Kubernetes Dashboards Prometheus Malla de servicio (Service Mesh) Aprovechar una malla de servicio que sigue el patr\u00f3n Sidecar configura r\u00e1pidamente un conjunto de m\u00e9tricas y trazas. Un sidecar funciona interceptando todo el tr\u00e1fico entrante y saliente hacia su imagen. Luego agrega encabezados de seguimiento a cada solicitud y emite un conjunto est\u00e1ndar de logs y m\u00e9tricas. Estas m\u00e9tricas son extremadamente poderosas para la observabilidad, lo que permite que cada servicio, ya sea del lado del cliente o del lado del servidor, aproveche un conjunto unificado de m\u00e9tricas, que incluyen: Latencia Bytes Tasa de solicitud Tasa de error","title":"Herramientas y Patrones"},{"location":"observabilidad/herramientas/#herramientas-y-patrones","text":"Hay una serie de herramientas modernas para hacer que los sistemas sean observables. Al identificar y/o crear herramientas que funcionen para su sistema, aqu\u00ed hay algunas cosas que debe considerar para ayudar a guiar las opciones. Debe ser simple de integrar y f\u00e1cil de usar. Debe ser posible agregar y visualizar datos. Las herramientas deben proporcionar datos en tiempo real. Debe ser capaz de guiar a los usuarios al \u00e1rea del problema con un contexto apropiado de extremo a extremo.","title":"Herramientas y Patrones"},{"location":"observabilidad/herramientas/#opciones","text":"Loki OpenTelemetry Kubernetes Dashboards Prometheus","title":"Opciones"},{"location":"observabilidad/herramientas/#malla-de-servicio-service-mesh","text":"Aprovechar una malla de servicio que sigue el patr\u00f3n Sidecar configura r\u00e1pidamente un conjunto de m\u00e9tricas y trazas. Un sidecar funciona interceptando todo el tr\u00e1fico entrante y saliente hacia su imagen. Luego agrega encabezados de seguimiento a cada solicitud y emite un conjunto est\u00e1ndar de logs y m\u00e9tricas. Estas m\u00e9tricas son extremadamente poderosas para la observabilidad, lo que permite que cada servicio, ya sea del lado del cliente o del lado del servidor, aproveche un conjunto unificado de m\u00e9tricas, que incluyen: Latencia Bytes Tasa de solicitud Tasa de error","title":"Malla de servicio (Service Mesh)"},{"location":"observabilidad/herramientas/KubernetesDashboards/","text":"Kubernetes UI Dashboards Este documento cubre las opciones y los beneficios de varios Kubernetes UI Dashboards, que son herramientas \u00fatiles para monitorear y depurar su aplicaci\u00f3n en cl\u00fasteres de Kubernetes. Ventajas y casos de uso Permite la capacidad de ver, administrar y monitorear los aspectos operativos del cl\u00faster de Kubernetes. Los beneficios de usar un dashboard de interfaz de usuario incluyen lo siguiente: Ver una descripci\u00f3n general del cl\u00faster Implementar aplicaciones en el cl\u00faster Solucionar problemas de aplicaciones que se ejecutan en el cl\u00faster Ver, crear, modificar y eliminar recursos de Kubernetes Ver m\u00e9tricas b\u00e1sicas de recursos, incluido el uso de recursos para objetos de Kubernetes Ver y acceder a los registros Ver en vivo el estado de los pods Diferentes dashboards pueden proporcionar diferentes funcionalidades, y el caso de uso para elegir un dashboard en particular depender\u00e1 de los requisitos. Open Source Dashboards Actualmente hay varios dashboards disponibles para monitorear sus aplicaciones o administrarlas con Kubernetes: Octant Prometheus y Grafana Kube Prometheus Stack Chart : proporciona una manera f\u00e1cil de operar el monitoreo de cl\u00fasteres de Kubernetes de un extremo a otro con Prometheus utilizando Prometheus Operator. K8 Dash kube-ops-view : una herramienta para visualizar la ocupaci\u00f3n y utilizaci\u00f3n de nodos Lens : herramienta de escritorio del lado del cliente Thanos y Cortex : implementaciones multicl\u00faster Referencias Alternativas a Kubernetes Dashboard Prometheus y Grafana con Kubernetes","title":"Kubernetes UI Dashboards"},{"location":"observabilidad/herramientas/KubernetesDashboards/#kubernetes-ui-dashboards","text":"Este documento cubre las opciones y los beneficios de varios Kubernetes UI Dashboards, que son herramientas \u00fatiles para monitorear y depurar su aplicaci\u00f3n en cl\u00fasteres de Kubernetes.","title":"Kubernetes UI Dashboards"},{"location":"observabilidad/herramientas/KubernetesDashboards/#ventajas-y-casos-de-uso","text":"Permite la capacidad de ver, administrar y monitorear los aspectos operativos del cl\u00faster de Kubernetes. Los beneficios de usar un dashboard de interfaz de usuario incluyen lo siguiente: Ver una descripci\u00f3n general del cl\u00faster Implementar aplicaciones en el cl\u00faster Solucionar problemas de aplicaciones que se ejecutan en el cl\u00faster Ver, crear, modificar y eliminar recursos de Kubernetes Ver m\u00e9tricas b\u00e1sicas de recursos, incluido el uso de recursos para objetos de Kubernetes Ver y acceder a los registros Ver en vivo el estado de los pods Diferentes dashboards pueden proporcionar diferentes funcionalidades, y el caso de uso para elegir un dashboard en particular depender\u00e1 de los requisitos.","title":"Ventajas y casos de uso"},{"location":"observabilidad/herramientas/KubernetesDashboards/#open-source-dashboards","text":"Actualmente hay varios dashboards disponibles para monitorear sus aplicaciones o administrarlas con Kubernetes: Octant Prometheus y Grafana Kube Prometheus Stack Chart : proporciona una manera f\u00e1cil de operar el monitoreo de cl\u00fasteres de Kubernetes de un extremo a otro con Prometheus utilizando Prometheus Operator. K8 Dash kube-ops-view : una herramienta para visualizar la ocupaci\u00f3n y utilizaci\u00f3n de nodos Lens : herramienta de escritorio del lado del cliente Thanos y Cortex : implementaciones multicl\u00faster","title":"Open Source Dashboards"},{"location":"observabilidad/herramientas/KubernetesDashboards/#referencias","text":"Alternativas a Kubernetes Dashboard Prometheus y Grafana con Kubernetes","title":"Referencias"},{"location":"observabilidad/herramientas/OpenTelemetry/","text":"Open Telemetry OpenTelemetry es un est\u00e1ndar de observabilidad de c\u00f3digo abierto que define c\u00f3mo generar, recopilar y describir la telemetr\u00eda en sistemas distribuidos. OpenTelemetry tambi\u00e9n proporciona una distribuci\u00f3n de punto \u00fanico de un conjunto de API, SDK y bibliotecas de instrumentaci\u00f3n que implementa el est\u00e1ndar de c\u00f3digo abierto, que puede recopilar, procesar y orquestar datos de telemetr\u00eda (se\u00f1ales) como trazas, m\u00e9tricas y logs. Admite m\u00faltiples lenguajes populares. Un punto importante a tener en cuenta es que OpenTelemetry no tiene su propio backend; toda la telemetr\u00eda recopilada por OpenTelemetry Collector debe enviarse a un backend como Prometheus, Jaeger, Zipkin, Azure Monitor, etc. Los dos problemas principales que resuelve OpenTelemetry son: primero, la neutralidad del proveedor para las APIs de tracing, monitoreo y logging y, en segundo lugar, la implementaci\u00f3n de propagaci\u00f3n de contexto multiplataforma lista para usar para el seguimiento distribuido de extremo a extremo sobre componentes heterog\u00e9neos. Conceptos b\u00e1sicos de Open Telemetry Patrones de implementaci\u00f3n de Open Telemetry Comprender los patrones de implementaci\u00f3n b\u00e1sicos lo ayudar\u00e1 a saber qu\u00e9 enfoque se adapta mejor al escenario que est\u00e1 tratando de resolver. Hay tres patrones principales: Telemetr\u00eda autom\u00e1tica: la compatibilidad con la instrumentaci\u00f3n autom\u00e1tica est\u00e1 disponible para algunos lenguajes. Para aquellos disponibles, la instrumentaci\u00f3n automatizada de OpenTelemetry se implementa mediante la ejecuci\u00f3n de OpenTelemetry Agent. El agente se implementar\u00eda con su servicio y se ejecutar\u00eda como un proceso separado o en un sidecar. El agente lee un conjunto de variables de entorno predefinidas que se utilizan para configurar su comportamiento y varias configuraciones de exportador/recopilador. El agente interceptar\u00e1 todas las interacciones y dependencias y enviar\u00e1 autom\u00e1ticamente la telemetr\u00eda a los exportadores configurados. Rastreo manual: esto se debe hacer codificando con el SDK de OpenTelemetry, administrando los objetos tracer para obtener intervalos y formando \u00e1mbitos de OpenTelemetry instrumentados para identificar los segmentos de c\u00f3digo que se rastrear\u00e1n manualmente. Enfoque h\u00edbrido: la mayor\u00eda de los escenarios listos para producci\u00f3n requerir\u00e1n una combinaci\u00f3n de ambas t\u00e9cnicas, utilizando OpenTelemetry Agent para recopilar telemetr\u00eda autom\u00e1tica y OpenTelemetry SDK para identificar segmentos de c\u00f3digo que son importantes para instrumentar manualmente. Este enfoque permite una cobertura completa de toda la soluci\u00f3n. Collector El collector es un proceso separado que est\u00e1 dise\u00f1ado para ser un \"sumidero\" para los datos de telemetr\u00eda emitidos por muchos procesos, que luego pueden exportar esos datos a los sistemas de back-end. El collector tiene dos estrategias de implementaci\u00f3n diferentes: se ejecuta como un agente junto con un servicio o como una aplicaci\u00f3n remota. En general, se recomienda usar ambos: el agente se implementar\u00eda con su servicio y se ejecutar\u00eda como un proceso separado o en un sidecar; mientras tanto, el recopilador se implementar\u00eda por separado, como su propia aplicaci\u00f3n ejecut\u00e1ndose en un contenedor o m\u00e1quina virtual. Cada agente enviar\u00eda datos de telemetr\u00eda al recopilador, que luego podr\u00eda exportarlos a una variedad de sistemas de back-end como Lightstep, Jaeger o Prometheus. Bibliotecas de instrumentaci\u00f3n Una biblioteca que permite la observabilidad de otra biblioteca se denomina biblioteca de instrumentaci\u00f3n. Las bibliotecas de OpenTelemetry son espec\u00edficas del lenguaje, actualmente hay un buen soporte para Java, Python, Javascript, dotnet y golang. El soporte para la instrumentaci\u00f3n autom\u00e1tica est\u00e1 disponible para algunas bibliotecas que hacen que el uso de OpenTelemetry sea f\u00e1cil y trivial. En caso de que la instrumentaci\u00f3n autom\u00e1tica no est\u00e9 disponible, la instrumentaci\u00f3n manual se puede configurar mediante el SDK de OpenTelemetry. Integraci\u00f3n de OpenTelemetry OpenTelemetry se puede utilizar para recopilar, procesar y exportar datos a m\u00faltiples backends. Algunas integraciones populares compatibles con OpenTelemetry son: Zipkin Prometheus Jaeger New Relic Azure Monitor AWS X-Ray Datadog Kafka Lightstep Splunk GCP Monitor Por qu\u00e9 usar OpenTelemetry La raz\u00f3n principal es que ofrece un est\u00e1ndar de c\u00f3digo abierto para implementar telemetr\u00eda distribuida (propagaci\u00f3n de contexto) en sistemas heterog\u00e9neos. Evitar cualquier bloqueo de propiedad y lograr la neutralidad independiente del proveedor permite patrones m\u00e1ximos de portabilidad y extensibilidad. Adem\u00e1s, OpenTelemetry se rige por especificaciones y est\u00e1 respaldado por grandes actores en el panorama de la observabilidad como Microsoft, Splunk, AppDynamics, etc. Es probable que OpenTelemetry se convierta en un est\u00e1ndar de facto. Estado actual del proyecto OpenTelemetry OpenTelemetry es un proyecto que surgi\u00f3 de la fusi\u00f3n de OpenCensus y OpenTracing en 2019. Aunque OpenCensus y OpenTracing est\u00e1n congelados y no se est\u00e1n desarrollando nuevas funciones para ellos, OpenTelemetry tiene compatibilidad con versiones anteriores de OpenCensus y OpenTracing. Algunas funciones de OpenTelemetry todav\u00eda est\u00e1n en versi\u00f3n beta, la compatibilidad de funciones para diferentes lenguajes se rastrea aqu\u00ed: Feature Status of OpenTelemetry . El estado del proyecto OpenTelemetry se puede rastrear aqu\u00ed . Opciones de integraci\u00f3n con Azure Monitor Hay dos enfoques posibles al integrar una aplicaci\u00f3n instrumentada de OpenTelemetry con Azure Monitor como un exportador de OpenTemetry. Uso de la biblioteca de exportaci\u00f3n de OpenTelemetry de Azure Monitor Este escenario usa el SDK de OpenTelemetry como la biblioteca de instrumentaci\u00f3n principal. B\u00e1sicamente, esto significa que instrumentar\u00e1 su aplicaci\u00f3n con las bibliotecas de OpenTelemetry, pero adem\u00e1s usar\u00e1 Azure Monitor OpenTelemetry Exporter y luego lo agregar\u00e1 como un exportador adicional con OpenTelemetry SDK. Uso del archivo Jar del agente de Application Insights Al configurar esta opci\u00f3n, el archivo del Agente de Applications Insights se agrega al ejecutar la aplicaci\u00f3n. El archivo de configuraci\u00f3n applicationinsights.json tambi\u00e9n debe agregarse como parte de los artefactos de aplicaciones. Preste mucha atenci\u00f3n a la secci\u00f3n de vista previa, donde la propiedad \"openTelemetryApiSupport\": true , se establece en true, lo que permite al agente interceptar la telemetr\u00eda de OpenTelemetry creada en el c\u00f3digo de la aplicaci\u00f3n y enviarla a Azure Monitor. La principal diferencia entre ejecutar el agente de OpenTelemetry y el agente de Application Insights se demuestra en la cantidad de trazas que se registran en Azure Monitor. Cuando se ejecuta en modo solo OpenTelemetry, se env\u00edan solo las trazas manuales. Por otro lado, cuando se ejecuta utilizando el modo de agente de Application Insights, es fundamental resaltar que no se registra nada en Jaeger (ni en ning\u00fan otro exportador de OpenTelemetry). Todas las trazas se enviar\u00e1n exclusivamente a Azure Monitor. Resumen No existe un enfoque de \"talla \u00fanica\" al implementar OpenTelemetry con Azure Monitor como back-end. En el momento de escribir este art\u00edculo, si desea tener la flexibilidad de tener diferentes back-ends de OpenTelemetry, definitivamente debe optar por OpenTelemetry Agent, aunque sacrificar\u00eda todo el flujo de tracing autom\u00e1tico a Azure Monitor. Por otro lado, si desea obtener lo mejor de Azure Monitor y a\u00fan desea instrumentar su c\u00f3digo con OpenTelemetry SDK, debe usar Application Insights Agent e instrumentar manualmente su c\u00f3digo con OpenTelemetry SDK para obtener lo mejor de ambos mundos. De cualquier manera, instrumentar su c\u00f3digo con OpenTelemetry parece el enfoque correcto ya que el ecosistema solo se har\u00e1 m\u00e1s grande, mejor y m\u00e1s robusto. Referencias Sitio oficial OpenTelemetry Primeros pasos con dotnet y OpenTelemetry Uso de OpenTelemetry Collector OpenTelemetry Java SDK Agente de instrumentaci\u00f3n OpenTelemetry para Java Agente Java de Application Insights Biblioteca cliente de Azure Monitor OpenTelemetry Exporter para Java Biblioteca de complementos de Azure OpenTelemetry Tracing para Java Configuraci\u00f3n de OpenTelemetry del agente de Application Insights","title":"Open Telemetry"},{"location":"observabilidad/herramientas/OpenTelemetry/#open-telemetry","text":"OpenTelemetry es un est\u00e1ndar de observabilidad de c\u00f3digo abierto que define c\u00f3mo generar, recopilar y describir la telemetr\u00eda en sistemas distribuidos. OpenTelemetry tambi\u00e9n proporciona una distribuci\u00f3n de punto \u00fanico de un conjunto de API, SDK y bibliotecas de instrumentaci\u00f3n que implementa el est\u00e1ndar de c\u00f3digo abierto, que puede recopilar, procesar y orquestar datos de telemetr\u00eda (se\u00f1ales) como trazas, m\u00e9tricas y logs. Admite m\u00faltiples lenguajes populares. Un punto importante a tener en cuenta es que OpenTelemetry no tiene su propio backend; toda la telemetr\u00eda recopilada por OpenTelemetry Collector debe enviarse a un backend como Prometheus, Jaeger, Zipkin, Azure Monitor, etc. Los dos problemas principales que resuelve OpenTelemetry son: primero, la neutralidad del proveedor para las APIs de tracing, monitoreo y logging y, en segundo lugar, la implementaci\u00f3n de propagaci\u00f3n de contexto multiplataforma lista para usar para el seguimiento distribuido de extremo a extremo sobre componentes heterog\u00e9neos.","title":"Open Telemetry"},{"location":"observabilidad/herramientas/OpenTelemetry/#conceptos-basicos-de-open-telemetry","text":"","title":"Conceptos b\u00e1sicos de Open Telemetry"},{"location":"observabilidad/herramientas/OpenTelemetry/#patrones-de-implementacion-de-open-telemetry","text":"Comprender los patrones de implementaci\u00f3n b\u00e1sicos lo ayudar\u00e1 a saber qu\u00e9 enfoque se adapta mejor al escenario que est\u00e1 tratando de resolver. Hay tres patrones principales: Telemetr\u00eda autom\u00e1tica: la compatibilidad con la instrumentaci\u00f3n autom\u00e1tica est\u00e1 disponible para algunos lenguajes. Para aquellos disponibles, la instrumentaci\u00f3n automatizada de OpenTelemetry se implementa mediante la ejecuci\u00f3n de OpenTelemetry Agent. El agente se implementar\u00eda con su servicio y se ejecutar\u00eda como un proceso separado o en un sidecar. El agente lee un conjunto de variables de entorno predefinidas que se utilizan para configurar su comportamiento y varias configuraciones de exportador/recopilador. El agente interceptar\u00e1 todas las interacciones y dependencias y enviar\u00e1 autom\u00e1ticamente la telemetr\u00eda a los exportadores configurados. Rastreo manual: esto se debe hacer codificando con el SDK de OpenTelemetry, administrando los objetos tracer para obtener intervalos y formando \u00e1mbitos de OpenTelemetry instrumentados para identificar los segmentos de c\u00f3digo que se rastrear\u00e1n manualmente. Enfoque h\u00edbrido: la mayor\u00eda de los escenarios listos para producci\u00f3n requerir\u00e1n una combinaci\u00f3n de ambas t\u00e9cnicas, utilizando OpenTelemetry Agent para recopilar telemetr\u00eda autom\u00e1tica y OpenTelemetry SDK para identificar segmentos de c\u00f3digo que son importantes para instrumentar manualmente. Este enfoque permite una cobertura completa de toda la soluci\u00f3n.","title":"Patrones de implementaci\u00f3n de Open Telemetry"},{"location":"observabilidad/herramientas/OpenTelemetry/#collector","text":"El collector es un proceso separado que est\u00e1 dise\u00f1ado para ser un \"sumidero\" para los datos de telemetr\u00eda emitidos por muchos procesos, que luego pueden exportar esos datos a los sistemas de back-end. El collector tiene dos estrategias de implementaci\u00f3n diferentes: se ejecuta como un agente junto con un servicio o como una aplicaci\u00f3n remota. En general, se recomienda usar ambos: el agente se implementar\u00eda con su servicio y se ejecutar\u00eda como un proceso separado o en un sidecar; mientras tanto, el recopilador se implementar\u00eda por separado, como su propia aplicaci\u00f3n ejecut\u00e1ndose en un contenedor o m\u00e1quina virtual. Cada agente enviar\u00eda datos de telemetr\u00eda al recopilador, que luego podr\u00eda exportarlos a una variedad de sistemas de back-end como Lightstep, Jaeger o Prometheus.","title":"Collector"},{"location":"observabilidad/herramientas/OpenTelemetry/#bibliotecas-de-instrumentacion","text":"Una biblioteca que permite la observabilidad de otra biblioteca se denomina biblioteca de instrumentaci\u00f3n. Las bibliotecas de OpenTelemetry son espec\u00edficas del lenguaje, actualmente hay un buen soporte para Java, Python, Javascript, dotnet y golang. El soporte para la instrumentaci\u00f3n autom\u00e1tica est\u00e1 disponible para algunas bibliotecas que hacen que el uso de OpenTelemetry sea f\u00e1cil y trivial. En caso de que la instrumentaci\u00f3n autom\u00e1tica no est\u00e9 disponible, la instrumentaci\u00f3n manual se puede configurar mediante el SDK de OpenTelemetry.","title":"Bibliotecas de instrumentaci\u00f3n"},{"location":"observabilidad/herramientas/OpenTelemetry/#integracion-de-opentelemetry","text":"OpenTelemetry se puede utilizar para recopilar, procesar y exportar datos a m\u00faltiples backends. Algunas integraciones populares compatibles con OpenTelemetry son: Zipkin Prometheus Jaeger New Relic Azure Monitor AWS X-Ray Datadog Kafka Lightstep Splunk GCP Monitor","title":"Integraci\u00f3n de OpenTelemetry"},{"location":"observabilidad/herramientas/OpenTelemetry/#por-que-usar-opentelemetry","text":"La raz\u00f3n principal es que ofrece un est\u00e1ndar de c\u00f3digo abierto para implementar telemetr\u00eda distribuida (propagaci\u00f3n de contexto) en sistemas heterog\u00e9neos. Evitar cualquier bloqueo de propiedad y lograr la neutralidad independiente del proveedor permite patrones m\u00e1ximos de portabilidad y extensibilidad. Adem\u00e1s, OpenTelemetry se rige por especificaciones y est\u00e1 respaldado por grandes actores en el panorama de la observabilidad como Microsoft, Splunk, AppDynamics, etc. Es probable que OpenTelemetry se convierta en un est\u00e1ndar de facto.","title":"Por qu\u00e9 usar OpenTelemetry"},{"location":"observabilidad/herramientas/OpenTelemetry/#estado-actual-del-proyecto-opentelemetry","text":"OpenTelemetry es un proyecto que surgi\u00f3 de la fusi\u00f3n de OpenCensus y OpenTracing en 2019. Aunque OpenCensus y OpenTracing est\u00e1n congelados y no se est\u00e1n desarrollando nuevas funciones para ellos, OpenTelemetry tiene compatibilidad con versiones anteriores de OpenCensus y OpenTracing. Algunas funciones de OpenTelemetry todav\u00eda est\u00e1n en versi\u00f3n beta, la compatibilidad de funciones para diferentes lenguajes se rastrea aqu\u00ed: Feature Status of OpenTelemetry . El estado del proyecto OpenTelemetry se puede rastrear aqu\u00ed .","title":"Estado actual del proyecto OpenTelemetry"},{"location":"observabilidad/herramientas/OpenTelemetry/#opciones-de-integracion-con-azure-monitor","text":"Hay dos enfoques posibles al integrar una aplicaci\u00f3n instrumentada de OpenTelemetry con Azure Monitor como un exportador de OpenTemetry.","title":"Opciones de integraci\u00f3n con Azure Monitor"},{"location":"observabilidad/herramientas/OpenTelemetry/#uso-de-la-biblioteca-de-exportacion-de-opentelemetry-de-azure-monitor","text":"Este escenario usa el SDK de OpenTelemetry como la biblioteca de instrumentaci\u00f3n principal. B\u00e1sicamente, esto significa que instrumentar\u00e1 su aplicaci\u00f3n con las bibliotecas de OpenTelemetry, pero adem\u00e1s usar\u00e1 Azure Monitor OpenTelemetry Exporter y luego lo agregar\u00e1 como un exportador adicional con OpenTelemetry SDK.","title":"Uso de la biblioteca de exportaci\u00f3n de OpenTelemetry de Azure Monitor"},{"location":"observabilidad/herramientas/OpenTelemetry/#uso-del-archivo-jar-del-agente-de-application-insights","text":"Al configurar esta opci\u00f3n, el archivo del Agente de Applications Insights se agrega al ejecutar la aplicaci\u00f3n. El archivo de configuraci\u00f3n applicationinsights.json tambi\u00e9n debe agregarse como parte de los artefactos de aplicaciones. Preste mucha atenci\u00f3n a la secci\u00f3n de vista previa, donde la propiedad \"openTelemetryApiSupport\": true , se establece en true, lo que permite al agente interceptar la telemetr\u00eda de OpenTelemetry creada en el c\u00f3digo de la aplicaci\u00f3n y enviarla a Azure Monitor. La principal diferencia entre ejecutar el agente de OpenTelemetry y el agente de Application Insights se demuestra en la cantidad de trazas que se registran en Azure Monitor. Cuando se ejecuta en modo solo OpenTelemetry, se env\u00edan solo las trazas manuales. Por otro lado, cuando se ejecuta utilizando el modo de agente de Application Insights, es fundamental resaltar que no se registra nada en Jaeger (ni en ning\u00fan otro exportador de OpenTelemetry). Todas las trazas se enviar\u00e1n exclusivamente a Azure Monitor.","title":"Uso del archivo Jar del agente de Application Insights"},{"location":"observabilidad/herramientas/OpenTelemetry/#resumen","text":"No existe un enfoque de \"talla \u00fanica\" al implementar OpenTelemetry con Azure Monitor como back-end. En el momento de escribir este art\u00edculo, si desea tener la flexibilidad de tener diferentes back-ends de OpenTelemetry, definitivamente debe optar por OpenTelemetry Agent, aunque sacrificar\u00eda todo el flujo de tracing autom\u00e1tico a Azure Monitor. Por otro lado, si desea obtener lo mejor de Azure Monitor y a\u00fan desea instrumentar su c\u00f3digo con OpenTelemetry SDK, debe usar Application Insights Agent e instrumentar manualmente su c\u00f3digo con OpenTelemetry SDK para obtener lo mejor de ambos mundos. De cualquier manera, instrumentar su c\u00f3digo con OpenTelemetry parece el enfoque correcto ya que el ecosistema solo se har\u00e1 m\u00e1s grande, mejor y m\u00e1s robusto.","title":"Resumen"},{"location":"observabilidad/herramientas/OpenTelemetry/#referencias","text":"Sitio oficial OpenTelemetry Primeros pasos con dotnet y OpenTelemetry Uso de OpenTelemetry Collector OpenTelemetry Java SDK Agente de instrumentaci\u00f3n OpenTelemetry para Java Agente Java de Application Insights Biblioteca cliente de Azure Monitor OpenTelemetry Exporter para Java Biblioteca de complementos de Azure OpenTelemetry Tracing para Java Configuraci\u00f3n de OpenTelemetry del agente de Application Insights","title":"Referencias"},{"location":"observabilidad/herramientas/Prometheus/","text":"Prometheus Visi\u00f3n general Es un conjunto de herramientas de monitoreo y alerta de c\u00f3digo abierto basado en datos de m\u00e9tricas de series temporales. Se ha convertido en una soluci\u00f3n de m\u00e9trica est\u00e1ndar de facto en el mundo nativo de la nube y se usa ampliamente con Kubernetes. El n\u00facleo de Prometheus es un servidor que extrae y almacena m\u00e9tricas. Hay otras numerosas caracter\u00edsticas y componentes opcionales, como un administrador de alertas y bibliotecas de clientes para lenguajes de programaci\u00f3n para ampliar las funcionalidades de Prometheus m\u00e1s all\u00e1 de lo b\u00e1sico. \u00bfPor qu\u00e9 Prometheus? Prometheus es una base de datos de series de tiempo y permite rastrear, monitorear y agregar eventos o mediciones a lo largo del tiempo. Prometheus es una herramienta basada en extracci\u00f3n. Tambi\u00e9n es compatible con el modelo push para impulsar m\u00e9tricas. La visualizaci\u00f3n de la serie temporal se puede realizar directamente a trav\u00e9s de su interfaz de usuario web. Prometheus proporciona un potente lenguaje de consulta funcional llamado PromQL (Prometheus Query Language) que permite al usuario agregar datos de series temporales en tiempo real. Integraci\u00f3n con otras herramientas Las bibliotecas de cliente de Prometheus le permiten agregar instrumentaci\u00f3n a su c\u00f3digo y exponer m\u00e9tricas internas a trav\u00e9s de un endpoint HTTP. Las bibliotecas de cliente oficiales de Prometheus actualmente son Go, Java o Scala, Python y Ruby. Las bibliotecas de terceros no oficiales incluyen: .NET/C#, Node.js y C++. El formato de m\u00e9tricas de Prometheus es compatible con una amplia gama de herramientas y servicios, que incluyen: Azure Monitor Stackdriver Datadog CloudWatch New Relic Flagger Grafana GitLab etc... Existen numerosos exportadores que se utilizan para exportar m\u00e9tricas existentes desde bases de datos, hardware, herramientas de CI/CD, sistemas de mensajer\u00eda, API y otros sistemas de monitoreo de terceros. Adem\u00e1s de las bibliotecas de clientes y los exportadores, existe una cantidad importante de puntos de integraci\u00f3n para el descubrimiento de servicios, el almacenamiento remoto, las alertas y la gesti\u00f3n. Referencias Documentos de Prometheus Mejores pr\u00e1cticas de Prometheus Grafana con Prometheus","title":"Prometheus"},{"location":"observabilidad/herramientas/Prometheus/#prometheus","text":"","title":"Prometheus"},{"location":"observabilidad/herramientas/Prometheus/#vision-general","text":"Es un conjunto de herramientas de monitoreo y alerta de c\u00f3digo abierto basado en datos de m\u00e9tricas de series temporales. Se ha convertido en una soluci\u00f3n de m\u00e9trica est\u00e1ndar de facto en el mundo nativo de la nube y se usa ampliamente con Kubernetes. El n\u00facleo de Prometheus es un servidor que extrae y almacena m\u00e9tricas. Hay otras numerosas caracter\u00edsticas y componentes opcionales, como un administrador de alertas y bibliotecas de clientes para lenguajes de programaci\u00f3n para ampliar las funcionalidades de Prometheus m\u00e1s all\u00e1 de lo b\u00e1sico.","title":"Visi\u00f3n general"},{"location":"observabilidad/herramientas/Prometheus/#por-que-prometheus","text":"Prometheus es una base de datos de series de tiempo y permite rastrear, monitorear y agregar eventos o mediciones a lo largo del tiempo. Prometheus es una herramienta basada en extracci\u00f3n. Tambi\u00e9n es compatible con el modelo push para impulsar m\u00e9tricas. La visualizaci\u00f3n de la serie temporal se puede realizar directamente a trav\u00e9s de su interfaz de usuario web. Prometheus proporciona un potente lenguaje de consulta funcional llamado PromQL (Prometheus Query Language) que permite al usuario agregar datos de series temporales en tiempo real.","title":"\u00bfPor qu\u00e9 Prometheus?"},{"location":"observabilidad/herramientas/Prometheus/#integracion-con-otras-herramientas","text":"Las bibliotecas de cliente de Prometheus le permiten agregar instrumentaci\u00f3n a su c\u00f3digo y exponer m\u00e9tricas internas a trav\u00e9s de un endpoint HTTP. Las bibliotecas de cliente oficiales de Prometheus actualmente son Go, Java o Scala, Python y Ruby. Las bibliotecas de terceros no oficiales incluyen: .NET/C#, Node.js y C++. El formato de m\u00e9tricas de Prometheus es compatible con una amplia gama de herramientas y servicios, que incluyen: Azure Monitor Stackdriver Datadog CloudWatch New Relic Flagger Grafana GitLab etc... Existen numerosos exportadores que se utilizan para exportar m\u00e9tricas existentes desde bases de datos, hardware, herramientas de CI/CD, sistemas de mensajer\u00eda, API y otros sistemas de monitoreo de terceros. Adem\u00e1s de las bibliotecas de clientes y los exportadores, existe una cantidad importante de puntos de integraci\u00f3n para el descubrimiento de servicios, el almacenamiento remoto, las alertas y la gesti\u00f3n.","title":"Integraci\u00f3n con otras herramientas"},{"location":"observabilidad/herramientas/Prometheus/#referencias","text":"Documentos de Prometheus Mejores pr\u00e1cticas de Prometheus Grafana con Prometheus","title":"Referencias"},{"location":"observabilidad/herramientas/loki/","text":"Loki Loki es un sistema de agregaci\u00f3n de registros multiusuario, de alta disponibilidad y escalable horizontalmente, creado por Grafana Labs inspirado en los aprendizajes de Prometheus. Ambas herramientas siguen la misma arquitectura, que es un agente que recopila m\u00e9tricas en cada uno de los componentes del sistema de software, un servidor que almacena los registros y tambi\u00e9n el tablero de Grafana, que accede al servidor loki para construir sus visualizaciones y consultas. Loki tiene tres componentes principales: Promtail Es la parte agente de Loki. Se puede usar para tomar registros de varios lugares, como var/log/ por ejemplo. La configuraci\u00f3n de Promtail es un archivo yaml llamado config-promtail.yml . En este archivo, se describen todas las rutas y fuentes de registro que se agregar\u00e1n en Loki Server. Loki Server Es responsable de recibir y almacenar todos los registros recibidos de todos los diferentes sistemas. Grafana Dashboards Son responsables de crear las visualizaciones y realizar consultas. \u00bfPor qu\u00e9 usar Loki? La raz\u00f3n principal para usar Loki en lugar de otras herramientas de agregaci\u00f3n de registros es que Loki optimiza el almacenamiento necesario. Lo hace siguiendo el mismo patr\u00f3n que Prometheus, que indexa las etiquetas y crea fragmentos del propio registro, utilizando menos espacio que simplemente almacenando los registros sin procesar. Referencias Sitio oficial de Loki Insertar logs en Loki Agregar fuente de Loki a Grafana Mejores pr\u00e1cticas de Loki","title":"Loki"},{"location":"observabilidad/herramientas/loki/#loki","text":"Loki es un sistema de agregaci\u00f3n de registros multiusuario, de alta disponibilidad y escalable horizontalmente, creado por Grafana Labs inspirado en los aprendizajes de Prometheus. Ambas herramientas siguen la misma arquitectura, que es un agente que recopila m\u00e9tricas en cada uno de los componentes del sistema de software, un servidor que almacena los registros y tambi\u00e9n el tablero de Grafana, que accede al servidor loki para construir sus visualizaciones y consultas. Loki tiene tres componentes principales:","title":"Loki"},{"location":"observabilidad/herramientas/loki/#promtail","text":"Es la parte agente de Loki. Se puede usar para tomar registros de varios lugares, como var/log/ por ejemplo. La configuraci\u00f3n de Promtail es un archivo yaml llamado config-promtail.yml . En este archivo, se describen todas las rutas y fuentes de registro que se agregar\u00e1n en Loki Server.","title":"Promtail"},{"location":"observabilidad/herramientas/loki/#loki-server","text":"Es responsable de recibir y almacenar todos los registros recibidos de todos los diferentes sistemas.","title":"Loki Server"},{"location":"observabilidad/herramientas/loki/#grafana-dashboards","text":"Son responsables de crear las visualizaciones y realizar consultas.","title":"Grafana Dashboards"},{"location":"observabilidad/herramientas/loki/#por-que-usar-loki","text":"La raz\u00f3n principal para usar Loki en lugar de otras herramientas de agregaci\u00f3n de registros es que Loki optimiza el almacenamiento necesario. Lo hace siguiendo el mismo patr\u00f3n que Prometheus, que indexa las etiquetas y crea fragmentos del propio registro, utilizando menos espacio que simplemente almacenando los registros sin procesar.","title":"\u00bfPor qu\u00e9 usar Loki?"},{"location":"observabilidad/herramientas/loki/#referencias","text":"Sitio oficial de Loki Insertar logs en Loki Agregar fuente de Loki a Grafana Mejores pr\u00e1cticas de Loki","title":"Referencias"},{"location":"observabilidad/pilares/dashboard/","text":"Dashboard Visi\u00f3n general El dashboard es una forma de visualizaci\u00f3n que proporciona de un vistazo los indicadores clave de rendimiento (KPI) del sistema observable. Conectan m\u00faltiples fuentes de datos. El dashboard se puede utilizar para: Mostrar tendencias Identificar patrones Medir la eficiencia f\u00e1cilmente Identificar datos at\u00edpicos y correlaciones Ver el estado de salud o el rendimiento del sistema Dar una perspectiva del KPI que es importante para un negocio/proceso Mejores pr\u00e1cticas Las preguntas comunes que debe hacerse al crear un dashboard ser\u00edan: \u00bfD\u00f3nde pas\u00f3 la mayor parte de su tiempo el usuario? \u00bfQu\u00e9 busca el usuario? \u00bfC\u00f3mo puedo ayudar mejor a mi equipo con alertas y soluci\u00f3n de problemas? \u00bfEstuvo el sistema en buen estado durante el \u00faltimo d\u00eda/semana/mes/trimestre? Estos son los principios que se deben tener en cuenta al crear dashboards: Separe un dashboard en varias secciones para simplificar. Agregar salto de p\u00e1gina o ancla (#secci\u00f3n) tambi\u00e9n es una ventaja, si corresponde. Agregue gr\u00e1ficos m\u00faltiples y simples. Cree gr\u00e1ficos simples, tenga m\u00e1s de ellos en lugar de un gr\u00e1fico complicado todo en uno. Identifique objetivos o medici\u00f3n de KPI. Haga preguntas que puedan ayudar a alcanzar el objetivo o KPI definido. Valide las preguntas. Esto se hace a menudo con los stakeholders, patrocinadores, l\u00edderes o gerentes de proyecto. Observe el dashboard que se construye. \u00bfReflejan los datos lo que las partes interesadas se propusieron responder? Recuerde siempre que este proceso lleva tiempo. Construir un dashboard es f\u00e1cil, construir un dashboard observable para mostrar un patr\u00f3n es dif\u00edcil. Herramientas recomendadas Azure Monitor Workbooks : Azure Workbooks, compatible con Markdown, est\u00e1 estrechamente integrado con los servicios de Azure, lo que lo hace altamente personalizable sin necesidad de herramientas adicionales. Creaci\u00f3n y uso compartido de paneles de datos de Log Analytics : dashboard que se puede crear mediante consultas de log en los datos de Log Analytics. Creaci\u00f3n de paneles de indicadores clave de rendimiento (KPI) personalizados con Azure Application Insights : los dashboard tambi\u00e9n se pueden crear con Application Insights. Creaci\u00f3n de un panel de Power BI desde un informe : Power Bi es una de las herramientas m\u00e1s sencillas para crear dashboards a partir de fuentes de datos y reportes. Grafana : Grafana es una popular herramienta de c\u00f3digo abierto para dashboard y visualizaci\u00f3n. Azure Monitor como origen de datos de Grafana : proporciona una integraci\u00f3n paso a paso de Azure Monitor con Grafana. Breve comparaci\u00f3n de varias herramientas . Ejemplos y recetas de dashboard Azure Workbooks An\u00e1lisis de rendimiento: una medida de c\u00f3mo funciona el sistema. Plantilla disponible en la galer\u00eda. An\u00e1lisis de fallas: un informe sobre fallas del sistema con detalles. Plantilla disponible en la galer\u00eda. \u00cdndice de rendimiento de la aplicaci\u00f3n (Appdex): esta es una forma de medir la satisfacci\u00f3n del usuario. Clasifica el rendimiento en tres zonas en funci\u00f3n de un umbral de rendimiento de referencia T. La plantilla para Appdex tambi\u00e9n est\u00e1 disponible en la galer\u00eda de Azure Workbooks. Application Insights An\u00e1lisis de retenci\u00f3n de usuarios para aplicaciones web con Application Insights . An\u00e1lisis de patrones de navegaci\u00f3n del usuario mediante flujos de usuarios de Application Insights . Use Azure Application Insights para entender la forma en que los clientes utilizan su aplicaci\u00f3n . Grafana con Azure Monitor como fuente de datos Azure Kubernetes Service - M\u00e9tricas de cl\u00faster y espacio de nombres : M\u00e9tricas de Container Insights para cl\u00fasteres de Kubernetes. Utilizaci\u00f3n del cl\u00faster, utilizaci\u00f3n del espacio de nombres, CPU y memoria del nodo, uso del disco del nodo y E/S del disco, red del nodo y m\u00e9tricas de operaci\u00f3n de kubelet docker. Azure Kubernetes Service - Nivel de contenedor y m\u00e9tricas de pod : contiene el nivel de contenedor y las m\u00e9tricas de pod, como CPU y memoria, que faltan en el dashboard anterior. Resumen Para crear un dashboard observable, el objetivo es hacer uso de las m\u00e9tricas, los logs y las trazas recopiladss para dar una idea de c\u00f3mo funciona el sistema, c\u00f3mo se comporta el usuario e identificar patrones. Hay muchas herramientas y plantillas. Cualquiera que sea la elecci\u00f3n, un buen tablero siempre es un tablero que puede ayudarlo a responder preguntas sobre el sistema y el usuario, realizar un seguimiento del KPI y el objetivo y, al mismo tiempo, permitir que se tomen decisiones comerciales informadas.","title":"Dashboard"},{"location":"observabilidad/pilares/dashboard/#dashboard","text":"","title":"Dashboard"},{"location":"observabilidad/pilares/dashboard/#vision-general","text":"El dashboard es una forma de visualizaci\u00f3n que proporciona de un vistazo los indicadores clave de rendimiento (KPI) del sistema observable. Conectan m\u00faltiples fuentes de datos. El dashboard se puede utilizar para: Mostrar tendencias Identificar patrones Medir la eficiencia f\u00e1cilmente Identificar datos at\u00edpicos y correlaciones Ver el estado de salud o el rendimiento del sistema Dar una perspectiva del KPI que es importante para un negocio/proceso","title":"Visi\u00f3n general"},{"location":"observabilidad/pilares/dashboard/#mejores-practicas","text":"Las preguntas comunes que debe hacerse al crear un dashboard ser\u00edan: \u00bfD\u00f3nde pas\u00f3 la mayor parte de su tiempo el usuario? \u00bfQu\u00e9 busca el usuario? \u00bfC\u00f3mo puedo ayudar mejor a mi equipo con alertas y soluci\u00f3n de problemas? \u00bfEstuvo el sistema en buen estado durante el \u00faltimo d\u00eda/semana/mes/trimestre? Estos son los principios que se deben tener en cuenta al crear dashboards: Separe un dashboard en varias secciones para simplificar. Agregar salto de p\u00e1gina o ancla (#secci\u00f3n) tambi\u00e9n es una ventaja, si corresponde. Agregue gr\u00e1ficos m\u00faltiples y simples. Cree gr\u00e1ficos simples, tenga m\u00e1s de ellos en lugar de un gr\u00e1fico complicado todo en uno. Identifique objetivos o medici\u00f3n de KPI. Haga preguntas que puedan ayudar a alcanzar el objetivo o KPI definido. Valide las preguntas. Esto se hace a menudo con los stakeholders, patrocinadores, l\u00edderes o gerentes de proyecto. Observe el dashboard que se construye. \u00bfReflejan los datos lo que las partes interesadas se propusieron responder? Recuerde siempre que este proceso lleva tiempo. Construir un dashboard es f\u00e1cil, construir un dashboard observable para mostrar un patr\u00f3n es dif\u00edcil.","title":"Mejores pr\u00e1cticas"},{"location":"observabilidad/pilares/dashboard/#herramientas-recomendadas","text":"Azure Monitor Workbooks : Azure Workbooks, compatible con Markdown, est\u00e1 estrechamente integrado con los servicios de Azure, lo que lo hace altamente personalizable sin necesidad de herramientas adicionales. Creaci\u00f3n y uso compartido de paneles de datos de Log Analytics : dashboard que se puede crear mediante consultas de log en los datos de Log Analytics. Creaci\u00f3n de paneles de indicadores clave de rendimiento (KPI) personalizados con Azure Application Insights : los dashboard tambi\u00e9n se pueden crear con Application Insights. Creaci\u00f3n de un panel de Power BI desde un informe : Power Bi es una de las herramientas m\u00e1s sencillas para crear dashboards a partir de fuentes de datos y reportes. Grafana : Grafana es una popular herramienta de c\u00f3digo abierto para dashboard y visualizaci\u00f3n. Azure Monitor como origen de datos de Grafana : proporciona una integraci\u00f3n paso a paso de Azure Monitor con Grafana. Breve comparaci\u00f3n de varias herramientas .","title":"Herramientas recomendadas"},{"location":"observabilidad/pilares/dashboard/#ejemplos-y-recetas-de-dashboard","text":"","title":"Ejemplos y recetas de dashboard"},{"location":"observabilidad/pilares/dashboard/#azure-workbooks","text":"An\u00e1lisis de rendimiento: una medida de c\u00f3mo funciona el sistema. Plantilla disponible en la galer\u00eda. An\u00e1lisis de fallas: un informe sobre fallas del sistema con detalles. Plantilla disponible en la galer\u00eda. \u00cdndice de rendimiento de la aplicaci\u00f3n (Appdex): esta es una forma de medir la satisfacci\u00f3n del usuario. Clasifica el rendimiento en tres zonas en funci\u00f3n de un umbral de rendimiento de referencia T. La plantilla para Appdex tambi\u00e9n est\u00e1 disponible en la galer\u00eda de Azure Workbooks.","title":"Azure Workbooks"},{"location":"observabilidad/pilares/dashboard/#application-insights","text":"An\u00e1lisis de retenci\u00f3n de usuarios para aplicaciones web con Application Insights . An\u00e1lisis de patrones de navegaci\u00f3n del usuario mediante flujos de usuarios de Application Insights . Use Azure Application Insights para entender la forma en que los clientes utilizan su aplicaci\u00f3n .","title":"Application Insights"},{"location":"observabilidad/pilares/dashboard/#grafana-con-azure-monitor-como-fuente-de-datos","text":"Azure Kubernetes Service - M\u00e9tricas de cl\u00faster y espacio de nombres : M\u00e9tricas de Container Insights para cl\u00fasteres de Kubernetes. Utilizaci\u00f3n del cl\u00faster, utilizaci\u00f3n del espacio de nombres, CPU y memoria del nodo, uso del disco del nodo y E/S del disco, red del nodo y m\u00e9tricas de operaci\u00f3n de kubelet docker. Azure Kubernetes Service - Nivel de contenedor y m\u00e9tricas de pod : contiene el nivel de contenedor y las m\u00e9tricas de pod, como CPU y memoria, que faltan en el dashboard anterior.","title":"Grafana con Azure Monitor como fuente de datos"},{"location":"observabilidad/pilares/dashboard/#resumen","text":"Para crear un dashboard observable, el objetivo es hacer uso de las m\u00e9tricas, los logs y las trazas recopiladss para dar una idea de c\u00f3mo funciona el sistema, c\u00f3mo se comporta el usuario e identificar patrones. Hay muchas herramientas y plantillas. Cualquiera que sea la elecci\u00f3n, un buen tablero siempre es un tablero que puede ayudarlo a responder preguntas sobre el sistema y el usuario, realizar un seguimiento del KPI y el objetivo y, al mismo tiempo, permitir que se tomen decisiones comerciales informadas.","title":"Resumen"},{"location":"observabilidad/pilares/logging/","text":"Logging Visi\u00f3n general Los logs son eventos discretos con el objetivo de ayudar a los ingenieros a identificar las \u00e1reas problem\u00e1ticas durante las fallas. M\u00e9todos de recolecci\u00f3n Dos de las t\u00e9cnicas est\u00e1ndar son un enfoque de escritura directa o basado en agentes. Los eventos de log escritos directamente se manejan en el proceso del componente en particular, generalmente utilizando una biblioteca provista. Azure Monitor tiene capacidades de env\u00edo directo, pero no se recomienda para un uso serio o de producci\u00f3n. Este enfoque tiene algunas ventajas: No hay un proceso externo para configurar o monitorear Sin administraci\u00f3n de archivos de log para evitar problemas de falta de espacio en disco. Desventajas potenciales de este enfoque: Uso de memoria potencialmente mayor si la biblioteca en particular est\u00e1 usando un b\u00fafer respaldado por memoria. En el caso de una interrupci\u00f3n prolongada del servicio, los datos de log pueden perderse o truncarse debido a las limitaciones del b\u00fafer. El logeo de procesos de m\u00faltiples componentes administrar\u00e1 y emitir\u00e1 logs individualmente, lo que puede ser m\u00e1s complejo de administrar. La recopilaci\u00f3n de logs basada en agentes se basa en un proceso externo que se ejecuta en la m\u00e1quina host, y el componente en particular emite datos de log est\u00e1ndar o archivo. Escribir datos de log en stdout es la pr\u00e1ctica preferida cuando se ejecutan aplicaciones dentro de un entorno de contenedor como Kubernetes. El runtime del contenedor redirige la salida a los archivos, que luego puede procesar un agente. Azure Monitor , Grafana Loki , Logstash y Fluent Bit son ejemplos de agentes de env\u00edo de logs. Hay varias ventajas cuando se utiliza un agente para recopilar y enviar archivos de log: Configuraci\u00f3n centralizada. Recopilaci\u00f3n de m\u00faltiples fuentes de datos con un solo proceso. Preprocesamiento local y filtrado de datos de log antes de enviarlos a un servicio central. Utilizar el espacio en disco como un b\u00fafer de datos durante una interrupci\u00f3n del servicio. Este enfoque no est\u00e1 exento de desventajas: Se requieren recursos exclusivos de CPU y memoria para el procesamiento de datos de log. Espacio de disco persistente para almacenamiento en b\u00fafer. Mejores pr\u00e1cticas Preste atenci\u00f3n a los niveles de log. Registrar demasiado aumentar\u00e1 los costos y disminuir\u00e1 el rendimiento de la aplicaci\u00f3n. Aseg\u00farese de que la configuraci\u00f3n de log se pueda modificar sin cambios de c\u00f3digo. Si est\u00e1 disponible, aproveche los niveles de log por categor\u00eda que permiten una configuraci\u00f3n de log granular. Verifique los niveles de log antes de iniciar sesi\u00f3n, evitando as\u00ed asignaciones y costos de manipulaci\u00f3n de cadenas. Aseg\u00farese de que las versiones de servicio est\u00e9n incluidas en los logs para poder identificar versiones problem\u00e1ticas. Loguee una excepci\u00f3n generada solo una vez. En sus controladores, solo detecte las excepciones esperadas que pueda manejar correctamente. Ajuste los niveles de log en producci\u00f3n. Durante una nueva versi\u00f3n, la verbosidad se puede aumentar para facilitar la identificaci\u00f3n de errores. Si utiliza muestreo, implem\u00e9ntelo en el nivel de servicio en lugar de definirlo en el sistema de log. De esta manera tenemos control sobre lo que se registra. Incluya solo fallas de controles de estado y solicitudes no del negocio. Aseg\u00farese de que un mal funcionamiento del sistema no provoque el almacenamiento de logs repetitivos. No reinvente la rueda, utilice las herramientas existentes para recopilar y analizar los datos. Aseg\u00farese de que se sigan las pol\u00edticas y restricciones de informaci\u00f3n de identificaci\u00f3n personal. Aseg\u00farese de que se capturen y registren los errores y las excepciones en los servicios dependientes. Si hay suficientes datos de log, \u00bfes necesario instrumentar m\u00e9tricas? Logs vs M\u00e9tricas vs Trazas cubre una gu\u00eda de alto nivel sobre cu\u00e1ndo utilizar datos m\u00e9tricos y cu\u00e1ndo usar datos de log. Ambos tienen un papel valioso que desempe\u00f1ar en la creaci\u00f3n de sistemas observables. \u00bfTiene problemas para identificar qu\u00e9 loguear? Al inicio de la aplicaci\u00f3n: Errores irrecuperables desde el inicio. Advertencias si la aplicaci\u00f3n a\u00fan se puede ejecutar, pero no como se esperaba. Informaci\u00f3n sobre el estado del servicio al inicio (n\u00famero de compilaci\u00f3n, configuraciones cargadas, etc.) Por solicitud entrante: Informaci\u00f3n b\u00e1sica para cada solicitud entrante: la URL, cualquier dimensi\u00f3n de usuario/inquilino/solicitud, c\u00f3digo de respuesta devuelto, latencia, tama\u00f1o de carga \u00fatil, recuentos de logs, etc. Advertencia por cualquier excepci\u00f3n inesperada, detectada solo en el controlador/interceptor superior y logeada con o junto a la informaci\u00f3n de solicitud, con seguimiento de pila. Por solicitud saliente: Informaci\u00f3n b\u00e1sica para cada solicitud saliente: la URL, cualquier dimensi\u00f3n de usuario/inquilino/solicitud, c\u00f3digo de respuesta devuelto, latencia, tama\u00f1os de carga \u00fatil, recuentos de logs devueltos, etc. Herramientas recomendadas Azure Monitor : incluye m\u00e9tricas del sistema, an\u00e1lisis de logs y m\u00e1s. Grafana Loki : una plataforma de agregaci\u00f3n de logs de c\u00f3digo abierto, basada en los aprendizajes de la comunidad de Prometheus para la recopilaci\u00f3n y el almacenamiento altamente eficientes de datos de log a escala. The Elastic Stack : una pila tecnol\u00f3gica de an\u00e1lisis de logs de c\u00f3digo abierto que utiliza Logstash, Beats, Elastic Search y Kibana. Grafana : herramienta de visualizaci\u00f3n y dashboard de c\u00f3digo abierto. Admite or\u00edgenes de datos de log, m\u00e9tricas y seguimiento distribuido.","title":"Logging"},{"location":"observabilidad/pilares/logging/#logging","text":"","title":"Logging"},{"location":"observabilidad/pilares/logging/#vision-general","text":"Los logs son eventos discretos con el objetivo de ayudar a los ingenieros a identificar las \u00e1reas problem\u00e1ticas durante las fallas.","title":"Visi\u00f3n general"},{"location":"observabilidad/pilares/logging/#metodos-de-recoleccion","text":"Dos de las t\u00e9cnicas est\u00e1ndar son un enfoque de escritura directa o basado en agentes. Los eventos de log escritos directamente se manejan en el proceso del componente en particular, generalmente utilizando una biblioteca provista. Azure Monitor tiene capacidades de env\u00edo directo, pero no se recomienda para un uso serio o de producci\u00f3n. Este enfoque tiene algunas ventajas: No hay un proceso externo para configurar o monitorear Sin administraci\u00f3n de archivos de log para evitar problemas de falta de espacio en disco. Desventajas potenciales de este enfoque: Uso de memoria potencialmente mayor si la biblioteca en particular est\u00e1 usando un b\u00fafer respaldado por memoria. En el caso de una interrupci\u00f3n prolongada del servicio, los datos de log pueden perderse o truncarse debido a las limitaciones del b\u00fafer. El logeo de procesos de m\u00faltiples componentes administrar\u00e1 y emitir\u00e1 logs individualmente, lo que puede ser m\u00e1s complejo de administrar. La recopilaci\u00f3n de logs basada en agentes se basa en un proceso externo que se ejecuta en la m\u00e1quina host, y el componente en particular emite datos de log est\u00e1ndar o archivo. Escribir datos de log en stdout es la pr\u00e1ctica preferida cuando se ejecutan aplicaciones dentro de un entorno de contenedor como Kubernetes. El runtime del contenedor redirige la salida a los archivos, que luego puede procesar un agente. Azure Monitor , Grafana Loki , Logstash y Fluent Bit son ejemplos de agentes de env\u00edo de logs. Hay varias ventajas cuando se utiliza un agente para recopilar y enviar archivos de log: Configuraci\u00f3n centralizada. Recopilaci\u00f3n de m\u00faltiples fuentes de datos con un solo proceso. Preprocesamiento local y filtrado de datos de log antes de enviarlos a un servicio central. Utilizar el espacio en disco como un b\u00fafer de datos durante una interrupci\u00f3n del servicio. Este enfoque no est\u00e1 exento de desventajas: Se requieren recursos exclusivos de CPU y memoria para el procesamiento de datos de log. Espacio de disco persistente para almacenamiento en b\u00fafer.","title":"M\u00e9todos de recolecci\u00f3n"},{"location":"observabilidad/pilares/logging/#mejores-practicas","text":"Preste atenci\u00f3n a los niveles de log. Registrar demasiado aumentar\u00e1 los costos y disminuir\u00e1 el rendimiento de la aplicaci\u00f3n. Aseg\u00farese de que la configuraci\u00f3n de log se pueda modificar sin cambios de c\u00f3digo. Si est\u00e1 disponible, aproveche los niveles de log por categor\u00eda que permiten una configuraci\u00f3n de log granular. Verifique los niveles de log antes de iniciar sesi\u00f3n, evitando as\u00ed asignaciones y costos de manipulaci\u00f3n de cadenas. Aseg\u00farese de que las versiones de servicio est\u00e9n incluidas en los logs para poder identificar versiones problem\u00e1ticas. Loguee una excepci\u00f3n generada solo una vez. En sus controladores, solo detecte las excepciones esperadas que pueda manejar correctamente. Ajuste los niveles de log en producci\u00f3n. Durante una nueva versi\u00f3n, la verbosidad se puede aumentar para facilitar la identificaci\u00f3n de errores. Si utiliza muestreo, implem\u00e9ntelo en el nivel de servicio en lugar de definirlo en el sistema de log. De esta manera tenemos control sobre lo que se registra. Incluya solo fallas de controles de estado y solicitudes no del negocio. Aseg\u00farese de que un mal funcionamiento del sistema no provoque el almacenamiento de logs repetitivos. No reinvente la rueda, utilice las herramientas existentes para recopilar y analizar los datos. Aseg\u00farese de que se sigan las pol\u00edticas y restricciones de informaci\u00f3n de identificaci\u00f3n personal. Aseg\u00farese de que se capturen y registren los errores y las excepciones en los servicios dependientes.","title":"Mejores pr\u00e1cticas"},{"location":"observabilidad/pilares/logging/#si-hay-suficientes-datos-de-log-es-necesario-instrumentar-metricas","text":"Logs vs M\u00e9tricas vs Trazas cubre una gu\u00eda de alto nivel sobre cu\u00e1ndo utilizar datos m\u00e9tricos y cu\u00e1ndo usar datos de log. Ambos tienen un papel valioso que desempe\u00f1ar en la creaci\u00f3n de sistemas observables.","title":"Si hay suficientes datos de log, \u00bfes necesario instrumentar m\u00e9tricas?"},{"location":"observabilidad/pilares/logging/#tiene-problemas-para-identificar-que-loguear","text":"Al inicio de la aplicaci\u00f3n: Errores irrecuperables desde el inicio. Advertencias si la aplicaci\u00f3n a\u00fan se puede ejecutar, pero no como se esperaba. Informaci\u00f3n sobre el estado del servicio al inicio (n\u00famero de compilaci\u00f3n, configuraciones cargadas, etc.) Por solicitud entrante: Informaci\u00f3n b\u00e1sica para cada solicitud entrante: la URL, cualquier dimensi\u00f3n de usuario/inquilino/solicitud, c\u00f3digo de respuesta devuelto, latencia, tama\u00f1o de carga \u00fatil, recuentos de logs, etc. Advertencia por cualquier excepci\u00f3n inesperada, detectada solo en el controlador/interceptor superior y logeada con o junto a la informaci\u00f3n de solicitud, con seguimiento de pila. Por solicitud saliente: Informaci\u00f3n b\u00e1sica para cada solicitud saliente: la URL, cualquier dimensi\u00f3n de usuario/inquilino/solicitud, c\u00f3digo de respuesta devuelto, latencia, tama\u00f1os de carga \u00fatil, recuentos de logs devueltos, etc.","title":"\u00bfTiene problemas para identificar qu\u00e9 loguear?"},{"location":"observabilidad/pilares/logging/#herramientas-recomendadas","text":"Azure Monitor : incluye m\u00e9tricas del sistema, an\u00e1lisis de logs y m\u00e1s. Grafana Loki : una plataforma de agregaci\u00f3n de logs de c\u00f3digo abierto, basada en los aprendizajes de la comunidad de Prometheus para la recopilaci\u00f3n y el almacenamiento altamente eficientes de datos de log a escala. The Elastic Stack : una pila tecnol\u00f3gica de an\u00e1lisis de logs de c\u00f3digo abierto que utiliza Logstash, Beats, Elastic Search y Kibana. Grafana : herramienta de visualizaci\u00f3n y dashboard de c\u00f3digo abierto. Admite or\u00edgenes de datos de log, m\u00e9tricas y seguimiento distribuido.","title":"Herramientas recomendadas"},{"location":"observabilidad/pilares/metrics/","text":"M\u00e9tricas Visi\u00f3n general Las m\u00e9tricas proporcionan un flujo de datos casi en tiempo real, informando a los operadores y partes interesadas sobre las funciones que est\u00e1 realizando el sistema, as\u00ed como sobre su estado. A diferencia del logeo y el traceo, los datos m\u00e9tricos tienden a ser m\u00e1s eficientes para transmitir y almacenar. M\u00e9todos de recolecci\u00f3n Los enfoques de recopilaci\u00f3n de m\u00e9tricas se dividen en dos categor\u00edas: m\u00e9tricas push y m\u00e9tricas pull. M\u00e9tricas push significa que el componente de origen env\u00eda los datos a un servicio o agente remoto. Azure Monitor y statsd son ejemplos de m\u00e9tricas push. Algunos puntos fuertes de las m\u00e9tricas push incluyen: Solo requiere la salida de red al destino remoto. El componente de origen controla la frecuencia de medici\u00f3n. Configuraci\u00f3n simplificada ya que el componente solo necesita saber el destino de donde enviar los datos. Algunas desventajas con este enfoque: A escala, es mucho m\u00e1s dif\u00edcil controlar las velocidades de transmisi\u00f3n de datos, lo que puede provocar la limitaci\u00f3n del servicio o p\u00e9rdida de los valores. Es dif\u00edcil determinar si cada componente est\u00e1 en buen estado y enviando datos. En el caso de las m\u00e9tricas pull, cada componente de origen publica un endpoint para que el agente de m\u00e9tricas se conecte y recopile las mediciones. Prometheus y su ecosistema de herramientas son un ejemplo de m\u00e9tricas de estilo pull. Los beneficios experimentados al usar una configuraci\u00f3n de m\u00e9tricas pull pueden implicar: Configuraci\u00f3n \u00fanica para determinar qu\u00e9 se mide y la frecuencia de medici\u00f3n para el entorno local. Cada objetivo de medici\u00f3n tiene una metam\u00e9trica relacionada con si la recopilaci\u00f3n es exitosa o no, que se puede usar como un control de salud general. Compatibilidad con el enrutamiento, el filtrado y el procesamiento de m\u00e9tricas antes de enviarlas a un almac\u00e9n de m\u00e9tricas central global. Los elementos de preocupaci\u00f3n para algunos pueden incluir: La configuraci\u00f3n y gesti\u00f3n de fuentes de datos puede dar lugar a una configuraci\u00f3n compleja. La configuraci\u00f3n de la red puede agregar m\u00e1s complejidad si es necesario administrar los firewalls y otras ACL para permitir la conectividad. Mejores pr\u00e1cticas \u00bfCu\u00e1ndo debo usar m\u00e9tricas en lugar de logs? Logs vs M\u00e9tricas vs Trazas cubre una gu\u00eda de alto nivel sobre cu\u00e1ndo utilizar datos m\u00e9tricos y cu\u00e1ndo usar datos de log. Ambos tienen un papel valioso que desempe\u00f1ar en la creaci\u00f3n de sistemas observables. \u00bfQu\u00e9 se debe medir? Mediciones cr\u00edticas del sistema que se relacionan con el estado de la aplicaci\u00f3n/m\u00e1quina, suelen ser excelentes candidatos para alertas. Trabaje con sus colegas de ingenier\u00eda y desarrollo para identificar las m\u00e9tricas, pero pueden incluir: Utilizaci\u00f3n de CPU y memoria. Tasa de request. Longitud de la cola. Recuento de excepciones inesperado. M\u00e9tricas de servicio dependientes. Medidas importantes relacionadas con el negocio, que impulsan la presentaci\u00f3n de informes a las partes interesadas. Consulte con las diversas partes interesadas del componente, pero algunos ejemplos pueden incluir: Trabajos realizados. Duraci\u00f3n de la sesi\u00f3n de usuario. Visitas al sitio. Etiquetas de dimensi\u00f3n Los sistemas m\u00e9tricos modernos suelen definir una \u00fanica m\u00e9trica de serie temporal como la combinaci\u00f3n del nombre de la m\u00e9trica y su diccionario de etiquetas de dimensi\u00f3n. Las etiquetas son una forma excelente de distinguir una instancia de una m\u00e9trica de otra y, al mismo tiempo, permitir que se realicen agregaciones y otras operaciones en el conjunto para el an\u00e1lisis. Algunas etiquetas comunes utilizadas en las m\u00e9tricas pueden incluir: Nombre del contenedor Nombre de host Versi\u00f3n de c\u00f3digo Nombre del cl\u00faster de Kubernetes Regi\u00f3n de Azure Herramientas recomendadas Azure Monitor : servicio que incluye m\u00e9tricas del sistema, an\u00e1lisis de log y m\u00e1s. Prometheus : una aplicaci\u00f3n de monitoreo y alerta en tiempo real. Su formato de exposici\u00f3n para exponer series temporales es la base del formato est\u00e1ndar de OpenMetrics. Thanos : configuraci\u00f3n de Prometheus de c\u00f3digo abierto y alta disponibilidad con capacidades de almacenamiento a largo plazo. Cortex : Prometheus a largo plazo, escalable horizontalmente, de alta disponibilidad y multiusuario. Grafana : herramienta de visualizaci\u00f3n y panel de control de c\u00f3digo abierto. Admite or\u00edgenes de datos de logs, m\u00e9tricas y trazas distribuidas.","title":"M\u00e9tricas"},{"location":"observabilidad/pilares/metrics/#metricas","text":"","title":"M\u00e9tricas"},{"location":"observabilidad/pilares/metrics/#vision-general","text":"Las m\u00e9tricas proporcionan un flujo de datos casi en tiempo real, informando a los operadores y partes interesadas sobre las funciones que est\u00e1 realizando el sistema, as\u00ed como sobre su estado. A diferencia del logeo y el traceo, los datos m\u00e9tricos tienden a ser m\u00e1s eficientes para transmitir y almacenar.","title":"Visi\u00f3n general"},{"location":"observabilidad/pilares/metrics/#metodos-de-recoleccion","text":"Los enfoques de recopilaci\u00f3n de m\u00e9tricas se dividen en dos categor\u00edas: m\u00e9tricas push y m\u00e9tricas pull. M\u00e9tricas push significa que el componente de origen env\u00eda los datos a un servicio o agente remoto. Azure Monitor y statsd son ejemplos de m\u00e9tricas push. Algunos puntos fuertes de las m\u00e9tricas push incluyen: Solo requiere la salida de red al destino remoto. El componente de origen controla la frecuencia de medici\u00f3n. Configuraci\u00f3n simplificada ya que el componente solo necesita saber el destino de donde enviar los datos. Algunas desventajas con este enfoque: A escala, es mucho m\u00e1s dif\u00edcil controlar las velocidades de transmisi\u00f3n de datos, lo que puede provocar la limitaci\u00f3n del servicio o p\u00e9rdida de los valores. Es dif\u00edcil determinar si cada componente est\u00e1 en buen estado y enviando datos. En el caso de las m\u00e9tricas pull, cada componente de origen publica un endpoint para que el agente de m\u00e9tricas se conecte y recopile las mediciones. Prometheus y su ecosistema de herramientas son un ejemplo de m\u00e9tricas de estilo pull. Los beneficios experimentados al usar una configuraci\u00f3n de m\u00e9tricas pull pueden implicar: Configuraci\u00f3n \u00fanica para determinar qu\u00e9 se mide y la frecuencia de medici\u00f3n para el entorno local. Cada objetivo de medici\u00f3n tiene una metam\u00e9trica relacionada con si la recopilaci\u00f3n es exitosa o no, que se puede usar como un control de salud general. Compatibilidad con el enrutamiento, el filtrado y el procesamiento de m\u00e9tricas antes de enviarlas a un almac\u00e9n de m\u00e9tricas central global. Los elementos de preocupaci\u00f3n para algunos pueden incluir: La configuraci\u00f3n y gesti\u00f3n de fuentes de datos puede dar lugar a una configuraci\u00f3n compleja. La configuraci\u00f3n de la red puede agregar m\u00e1s complejidad si es necesario administrar los firewalls y otras ACL para permitir la conectividad.","title":"M\u00e9todos de recolecci\u00f3n"},{"location":"observabilidad/pilares/metrics/#mejores-practicas","text":"","title":"Mejores pr\u00e1cticas"},{"location":"observabilidad/pilares/metrics/#cuando-debo-usar-metricas-en-lugar-de-logs","text":"Logs vs M\u00e9tricas vs Trazas cubre una gu\u00eda de alto nivel sobre cu\u00e1ndo utilizar datos m\u00e9tricos y cu\u00e1ndo usar datos de log. Ambos tienen un papel valioso que desempe\u00f1ar en la creaci\u00f3n de sistemas observables.","title":"\u00bfCu\u00e1ndo debo usar m\u00e9tricas en lugar de logs?"},{"location":"observabilidad/pilares/metrics/#que-se-debe-medir","text":"Mediciones cr\u00edticas del sistema que se relacionan con el estado de la aplicaci\u00f3n/m\u00e1quina, suelen ser excelentes candidatos para alertas. Trabaje con sus colegas de ingenier\u00eda y desarrollo para identificar las m\u00e9tricas, pero pueden incluir: Utilizaci\u00f3n de CPU y memoria. Tasa de request. Longitud de la cola. Recuento de excepciones inesperado. M\u00e9tricas de servicio dependientes. Medidas importantes relacionadas con el negocio, que impulsan la presentaci\u00f3n de informes a las partes interesadas. Consulte con las diversas partes interesadas del componente, pero algunos ejemplos pueden incluir: Trabajos realizados. Duraci\u00f3n de la sesi\u00f3n de usuario. Visitas al sitio.","title":"\u00bfQu\u00e9 se debe medir?"},{"location":"observabilidad/pilares/metrics/#etiquetas-de-dimension","text":"Los sistemas m\u00e9tricos modernos suelen definir una \u00fanica m\u00e9trica de serie temporal como la combinaci\u00f3n del nombre de la m\u00e9trica y su diccionario de etiquetas de dimensi\u00f3n. Las etiquetas son una forma excelente de distinguir una instancia de una m\u00e9trica de otra y, al mismo tiempo, permitir que se realicen agregaciones y otras operaciones en el conjunto para el an\u00e1lisis. Algunas etiquetas comunes utilizadas en las m\u00e9tricas pueden incluir: Nombre del contenedor Nombre de host Versi\u00f3n de c\u00f3digo Nombre del cl\u00faster de Kubernetes Regi\u00f3n de Azure","title":"Etiquetas de dimensi\u00f3n"},{"location":"observabilidad/pilares/metrics/#herramientas-recomendadas","text":"Azure Monitor : servicio que incluye m\u00e9tricas del sistema, an\u00e1lisis de log y m\u00e1s. Prometheus : una aplicaci\u00f3n de monitoreo y alerta en tiempo real. Su formato de exposici\u00f3n para exponer series temporales es la base del formato est\u00e1ndar de OpenMetrics. Thanos : configuraci\u00f3n de Prometheus de c\u00f3digo abierto y alta disponibilidad con capacidades de almacenamiento a largo plazo. Cortex : Prometheus a largo plazo, escalable horizontalmente, de alta disponibilidad y multiusuario. Grafana : herramienta de visualizaci\u00f3n y panel de control de c\u00f3digo abierto. Admite or\u00edgenes de datos de logs, m\u00e9tricas y trazas distribuidas.","title":"Herramientas recomendadas"},{"location":"observabilidad/pilares/tracing/","text":"Tracing Visi\u00f3n general Produce la informaci\u00f3n necesaria para observar series de operaciones correlacionadas en un sistema distribuido. Una vez recopilados, muestran la ruta, las medidas y las fallas en una transacci\u00f3n de extremo a extremo. Mejores pr\u00e1cticas Aseg\u00farese de que se rastreen al menos las transacciones clave. Incluya en cada traza la informaci\u00f3n necesaria para identificar las versiones de software. Esto es importante para correlacionar las implementaciones y la degradaci\u00f3n del sistema. Aseg\u00farese de que las dependencias est\u00e9n incluidas en la traza. Si los costos son una preocupaci\u00f3n, use el muestreo, evitando descartar errores, comportamientos inesperados e informaci\u00f3n cr\u00edtica. No reinvente la rueda, utilice las herramientas existentes para recopilar y analizar los datos. Aseg\u00farese de que se sigan las pol\u00edticas y restricciones de informaci\u00f3n de identificaci\u00f3n personal. Herramientas recomendadas Azure Monitor : incluye m\u00e9tricas del sistema, an\u00e1lisis de logs y m\u00e1s. Jaeger Tracing : traceo distribuido de extremo a extremo de c\u00f3digo abierto. Grafana : herramienta de visualizaci\u00f3n y dashboard de c\u00f3digo abierto. Admite or\u00edgenes de datos de log, m\u00e9tricas y seguimiento distribuido. Considere usar OpenTelemetry ya que implementa la propagaci\u00f3n de contexto multiplataforma de c\u00f3digo abierto para transacciones distribuidas de extremo a extremo sobre componentes heterog\u00e9neos listos para usar. Se encarga de crear y administrar autom\u00e1ticamente el objeto Trace Context entre una pila completa de microservicios implementados en diferentes pilas t\u00e9cnicas.","title":"Tracing"},{"location":"observabilidad/pilares/tracing/#tracing","text":"","title":"Tracing"},{"location":"observabilidad/pilares/tracing/#vision-general","text":"Produce la informaci\u00f3n necesaria para observar series de operaciones correlacionadas en un sistema distribuido. Una vez recopilados, muestran la ruta, las medidas y las fallas en una transacci\u00f3n de extremo a extremo.","title":"Visi\u00f3n general"},{"location":"observabilidad/pilares/tracing/#mejores-practicas","text":"Aseg\u00farese de que se rastreen al menos las transacciones clave. Incluya en cada traza la informaci\u00f3n necesaria para identificar las versiones de software. Esto es importante para correlacionar las implementaciones y la degradaci\u00f3n del sistema. Aseg\u00farese de que las dependencias est\u00e9n incluidas en la traza. Si los costos son una preocupaci\u00f3n, use el muestreo, evitando descartar errores, comportamientos inesperados e informaci\u00f3n cr\u00edtica. No reinvente la rueda, utilice las herramientas existentes para recopilar y analizar los datos. Aseg\u00farese de que se sigan las pol\u00edticas y restricciones de informaci\u00f3n de identificaci\u00f3n personal.","title":"Mejores pr\u00e1cticas"},{"location":"observabilidad/pilares/tracing/#herramientas-recomendadas","text":"Azure Monitor : incluye m\u00e9tricas del sistema, an\u00e1lisis de logs y m\u00e1s. Jaeger Tracing : traceo distribuido de extremo a extremo de c\u00f3digo abierto. Grafana : herramienta de visualizaci\u00f3n y dashboard de c\u00f3digo abierto. Admite or\u00edgenes de datos de log, m\u00e9tricas y seguimiento distribuido. Considere usar OpenTelemetry ya que implementa la propagaci\u00f3n de contexto multiplataforma de c\u00f3digo abierto para transacciones distribuidas de extremo a extremo sobre componentes heterog\u00e9neos listos para usar. Se encarga de crear y administrar autom\u00e1ticamente el objeto Trace Context entre una pila completa de microservicios implementados en diferentes pilas t\u00e9cnicas.","title":"Herramientas recomendadas"},{"location":"revisiones%20de%20codigo/","text":"Code Reviews Los desarrolladores deben realizar revisiones de c\u00f3digo entre pares en cada pull request. Metas La revisi\u00f3n del c\u00f3digo es una forma de tener una conversaci\u00f3n sobre el c\u00f3digo donde los participantes: Mejoran la calidad del c\u00f3digo identificando y eliminando los defectos antes de que puedan introducirse en el repositorio de c\u00f3digo. Aprenden y crecen haciendo que otros revisen el c\u00f3digo, nos exponemos a patrones de dise\u00f1o o lenguajes desconocidos, entre otros temas, e incluso rompemos algunos malos h\u00e1bitos. Comparten conocimiento entre los desarrolladores sobre el c\u00f3digo del proyecto. Recursos Herramientas de revisi\u00f3n de c\u00f3digo Documentaci\u00f3n de pr\u00e1cticas de ingenier\u00eda de Google: C\u00f3mo hacer una revisi\u00f3n de c\u00f3digo Los secretos mejor guardados de la revisi\u00f3n del c\u00f3digo de pares","title":"Code Reviews"},{"location":"revisiones%20de%20codigo/#code-reviews","text":"Los desarrolladores deben realizar revisiones de c\u00f3digo entre pares en cada pull request.","title":"Code Reviews"},{"location":"revisiones%20de%20codigo/#metas","text":"La revisi\u00f3n del c\u00f3digo es una forma de tener una conversaci\u00f3n sobre el c\u00f3digo donde los participantes: Mejoran la calidad del c\u00f3digo identificando y eliminando los defectos antes de que puedan introducirse en el repositorio de c\u00f3digo. Aprenden y crecen haciendo que otros revisen el c\u00f3digo, nos exponemos a patrones de dise\u00f1o o lenguajes desconocidos, entre otros temas, e incluso rompemos algunos malos h\u00e1bitos. Comparten conocimiento entre los desarrolladores sobre el c\u00f3digo del proyecto.","title":"Metas"},{"location":"revisiones%20de%20codigo/#recursos","text":"Herramientas de revisi\u00f3n de c\u00f3digo Documentaci\u00f3n de pr\u00e1cticas de ingenier\u00eda de Google: C\u00f3mo hacer una revisi\u00f3n de c\u00f3digo Los secretos mejor guardados de la revisi\u00f3n del c\u00f3digo de pares","title":"Recursos"},{"location":"revisiones%20de%20codigo/evidence-and-measures/","text":"Evidencia y Medidas Evidencia Muchos de los elementos de control de calidad del c\u00f3digo se pueden automatizar o aplicar mediante pol\u00edticas en los sistemas modernos de seguimiento de elementos de trabajo y control de versiones. La verificaci\u00f3n de las pol\u00edticas en la rama principal en Azure DevOps o GitHub, por ejemplo, puede ser evidencia suficiente de que un equipo de proyecto est\u00e1 realizando revisiones de c\u00f3digo. Las ramas principales en todos los repositorios tienen pol\u00edticas de rama. Configuraci\u00f3n de pol\u00edticas de ramas Todas las compilaciones producidas a partir de repositorios de proyectos incluyen linters apropiados, ejecutan pruebas unitarias. Cada elemento de trabajo de error debe incluir un enlace al PR que lo introdujo, una vez que se haya diagnosticado el error. Esto ayuda con el aprendizaje. Cada elemento de trabajo de error debe incluir una nota sobre c\u00f3mo el error podr\u00eda (o no) detectarse en una revisi\u00f3n de c\u00f3digo. El equipo del proyecto actualiza regularmente sus checklists de revisi\u00f3n de c\u00f3digo para reflejar los problemas comunes que han encontrado. Los l\u00edderes de desarrollo deben revisar una muestra de PRs y/o ser co-revisores con otros desarrolladores para ayudar a todos a mejorar sus habilidades como revisores de c\u00f3digo. Medidas El equipo puede recopilar m\u00e9tricas de revisiones de c\u00f3digo para medir su eficiencia. Algunas m\u00e9tricas \u00fatiles incluyen: Defect Removal Efficiency (DRE): una medida de la capacidad del equipo de desarrollo para eliminar defectos antes del release M\u00e9tricas de tiempo: Tiempo empleado en la preparaci\u00f3n de las sesiones de inspecci\u00f3n de c\u00f3digo Tiempo utilizado en las sesiones de revisi\u00f3n Lines of code (LOC) inspeccionadas por unidad de tiempo/reuni\u00f3n Es una soluci\u00f3n perfectamente razonable rastrear estas m\u00e9tricas manualmente, por ejemplo, en un Excel. Tambi\u00e9n es posible utilizar las funciones de las plataformas de gesti\u00f3n de proyectos; por ejemplo, AzDO habilita paneles para m\u00e9tricas, incluido el seguimiento de errores. Puede encontrar complementos listos para usar para varias plataformas o puede optar por implementar estas funciones usted mismo. Recursos Una gu\u00eda para las inspecciones de c\u00f3digo Eficacia de eliminaci\u00f3n de defectos","title":"Evidencia y Medidas"},{"location":"revisiones%20de%20codigo/evidence-and-measures/#evidencia-y-medidas","text":"","title":"Evidencia y Medidas"},{"location":"revisiones%20de%20codigo/evidence-and-measures/#evidencia","text":"Muchos de los elementos de control de calidad del c\u00f3digo se pueden automatizar o aplicar mediante pol\u00edticas en los sistemas modernos de seguimiento de elementos de trabajo y control de versiones. La verificaci\u00f3n de las pol\u00edticas en la rama principal en Azure DevOps o GitHub, por ejemplo, puede ser evidencia suficiente de que un equipo de proyecto est\u00e1 realizando revisiones de c\u00f3digo. Las ramas principales en todos los repositorios tienen pol\u00edticas de rama. Configuraci\u00f3n de pol\u00edticas de ramas Todas las compilaciones producidas a partir de repositorios de proyectos incluyen linters apropiados, ejecutan pruebas unitarias. Cada elemento de trabajo de error debe incluir un enlace al PR que lo introdujo, una vez que se haya diagnosticado el error. Esto ayuda con el aprendizaje. Cada elemento de trabajo de error debe incluir una nota sobre c\u00f3mo el error podr\u00eda (o no) detectarse en una revisi\u00f3n de c\u00f3digo. El equipo del proyecto actualiza regularmente sus checklists de revisi\u00f3n de c\u00f3digo para reflejar los problemas comunes que han encontrado. Los l\u00edderes de desarrollo deben revisar una muestra de PRs y/o ser co-revisores con otros desarrolladores para ayudar a todos a mejorar sus habilidades como revisores de c\u00f3digo.","title":"Evidencia"},{"location":"revisiones%20de%20codigo/evidence-and-measures/#medidas","text":"El equipo puede recopilar m\u00e9tricas de revisiones de c\u00f3digo para medir su eficiencia. Algunas m\u00e9tricas \u00fatiles incluyen: Defect Removal Efficiency (DRE): una medida de la capacidad del equipo de desarrollo para eliminar defectos antes del release M\u00e9tricas de tiempo: Tiempo empleado en la preparaci\u00f3n de las sesiones de inspecci\u00f3n de c\u00f3digo Tiempo utilizado en las sesiones de revisi\u00f3n Lines of code (LOC) inspeccionadas por unidad de tiempo/reuni\u00f3n Es una soluci\u00f3n perfectamente razonable rastrear estas m\u00e9tricas manualmente, por ejemplo, en un Excel. Tambi\u00e9n es posible utilizar las funciones de las plataformas de gesti\u00f3n de proyectos; por ejemplo, AzDO habilita paneles para m\u00e9tricas, incluido el seguimiento de errores. Puede encontrar complementos listos para usar para varias plataformas o puede optar por implementar estas funciones usted mismo.","title":"Medidas"},{"location":"revisiones%20de%20codigo/evidence-and-measures/#recursos","text":"Una gu\u00eda para las inspecciones de c\u00f3digo Eficacia de eliminaci\u00f3n de defectos","title":"Recursos"},{"location":"revisiones%20de%20codigo/tools/","text":"Herramientas de revisi\u00f3n de c\u00f3digo Personalizar Azure DevOps Tableros de tareas AzDO: personalizar tarjetas AzDO: agregar columnas en el tablero de tareas Pol\u00edticas del revisor Configuraci\u00f3n del grupo de revisores requerido en AzDO - Incluir autom\u00e1ticamente revisores de c\u00f3digo Configuraci\u00f3n de pol\u00edticas de ramas AzDO: Configurar directivas de ramas AzDO: Configuraci\u00f3n de pol\u00edticas de rama con la herramienta CLI: Crear un archivo de configuraci\u00f3n de pol\u00edticas Pol\u00edtica de recuento de aprobaciones GitHub: Configuraci\u00f3n de ramas protegidas Visual Studio Code GitHub: GitHub Pull Requests Admite el procesamiento de pull requests de GitHub dentro de VS Code. Abra el complemento desde la barra de actividad. Seleccione Asignado a m\u00ed. Seleccione un PR. En Descripci\u00f3n, puede elegir Verificar la rama y acceder al Modo de revisi\u00f3n y obtener una experiencia m\u00e1s integrada. Azure DevOps: Azure DevOps Pull Requests Admite el procesamiento de pull requests de Azure DevOps dentro de VS Code. Abra el complemento desde la barra de actividad. Seleccione Asignado a m\u00ed. Seleccione un PR. En Descripci\u00f3n, puede elegir Verificar la rama y acceder al Modo de revisi\u00f3n y obtener una experiencia m\u00e1s integrada.","title":"Herramientas de revisi\u00f3n de c\u00f3digo"},{"location":"revisiones%20de%20codigo/tools/#herramientas-de-revision-de-codigo","text":"","title":"Herramientas de revisi\u00f3n de c\u00f3digo"},{"location":"revisiones%20de%20codigo/tools/#personalizar-azure-devops","text":"","title":"Personalizar Azure DevOps"},{"location":"revisiones%20de%20codigo/tools/#tableros-de-tareas","text":"AzDO: personalizar tarjetas AzDO: agregar columnas en el tablero de tareas","title":"Tableros de tareas"},{"location":"revisiones%20de%20codigo/tools/#politicas-del-revisor","text":"Configuraci\u00f3n del grupo de revisores requerido en AzDO - Incluir autom\u00e1ticamente revisores de c\u00f3digo","title":"Pol\u00edticas del revisor"},{"location":"revisiones%20de%20codigo/tools/#configuracion-de-politicas-de-ramas","text":"AzDO: Configurar directivas de ramas AzDO: Configuraci\u00f3n de pol\u00edticas de rama con la herramienta CLI: Crear un archivo de configuraci\u00f3n de pol\u00edticas Pol\u00edtica de recuento de aprobaciones GitHub: Configuraci\u00f3n de ramas protegidas","title":"Configuraci\u00f3n de pol\u00edticas de ramas"},{"location":"revisiones%20de%20codigo/tools/#visual-studio-code","text":"","title":"Visual Studio Code"},{"location":"revisiones%20de%20codigo/tools/#github-github-pull-requests","text":"Admite el procesamiento de pull requests de GitHub dentro de VS Code. Abra el complemento desde la barra de actividad. Seleccione Asignado a m\u00ed. Seleccione un PR. En Descripci\u00f3n, puede elegir Verificar la rama y acceder al Modo de revisi\u00f3n y obtener una experiencia m\u00e1s integrada.","title":"GitHub: GitHub Pull Requests"},{"location":"revisiones%20de%20codigo/tools/#azure-devops-azure-devops-pull-requests","text":"Admite el procesamiento de pull requests de Azure DevOps dentro de VS Code. Abra el complemento desde la barra de actividad. Seleccione Asignado a m\u00ed. Seleccione un PR. En Descripci\u00f3n, puede elegir Verificar la rama y acceder al Modo de revisi\u00f3n y obtener una experiencia m\u00e1s integrada.","title":"Azure DevOps: Azure DevOps Pull Requests"},{"location":"revisiones%20de%20codigo/recetas/","text":"Gu\u00eda espec\u00edfica del lenguaje Bash C# Markdown Python Terraform YAML (Azure Pipelines)","title":"Gu\u00eda espec\u00edfica del lenguaje"},{"location":"revisiones%20de%20codigo/recetas/#guia-especifica-del-lenguaje","text":"Bash C# Markdown Python Terraform YAML (Azure Pipelines)","title":"Gu\u00eda espec\u00edfica del lenguaje"},{"location":"revisiones%20de%20codigo/recetas/azure-pipelines-yaml/","text":"YAML(Azure Pipelines) Code Reviews Gu\u00eda de estilo Referencia del esquema YAML . An\u00e1lisis de c\u00f3digo / Linting El linter YAML m\u00e1s popular es la extensi\u00f3n YAML . Esta extensi\u00f3n proporciona validaci\u00f3n YAML, esquematizaci\u00f3n de documentos, finalizaci\u00f3n autom\u00e1tica, compatibilidad con desplazamiento y funciones de formateador. VS Code Extensions Hay una extensi\u00f3n de Azure Pipelines para VS Code para agregar resaltado de sintaxis y autocompletado. Tambi\u00e9n lo ayuda a configurar la compilaci\u00f3n e implementaci\u00f3n continuas de Azure WebApps sin salir de VS Code. Descripci\u00f3n general de YAML en Azure Pipelines Cuando se activa la canalizaci\u00f3n, antes de ejecutar la canalizaci\u00f3n, hay algunas fases, como Tiempo de encolado, Tiempo de compilaci\u00f3n y Tiempo de ejecuci\u00f3n , donde las variables se interpretan por su sintaxis de expresi\u00f3n de tiempo de ejecuci\u00f3n . Cuando se activa la canalizaci\u00f3n, todos los archivos YAML anidados se expanden para ejecutarse en Azure Pipelines. Esta lista de verificaci\u00f3n contiene algunos consejos y trucos para revisar todos los archivos YAML anidados. Estos documentos pueden ser \u00fatiles al revisar archivos YAML: Documentaci\u00f3n YAML de Azure Pipelines Secuencia de ejecuci\u00f3n de canalizaci\u00f3n Conceptos clave para los nuevos Azure Pipelines Code Review Checklist Adem\u00e1s de la Checklist de Code Review (), tambi\u00e9n debe buscar estos elementos de revisi\u00f3n de c\u00f3digo espec\u00edficos de Azure Pipelines YAML: Estructura del pipeline Los pasos se entienden bien y los componentes son f\u00e1cilmente identificables. Aseg\u00farese de que haya una descripci\u00f3n adecuada displayName: para cada paso de la canalizaci\u00f3n. Los pasos o etapas de la canalizaci\u00f3n se comprueban en Azure Pipelines para comprender mejor los componentes. En caso de que tenga archivos YAML anidados complejos, la canalizaci\u00f3n en Azure Pipelines se edita para encontrar el archivo ra\u00edz desencadenante. Se visitan todas las referencias del archivo de plantilla para garantizar que un peque\u00f1o cambio no provoque cambios importantes; cambiar un archivo puede afectar a varias canalizaciones Los scripts en l\u00ednea largos en el archivo YAML se mueven a archivos de script Estructura YAML Los componentes reutilizables se dividen en plantillas YAML separadas. Las variables se separan por entorno almacenadas en plantillas o grupos de variables. Se tienen en cuenta los cambios de valor de las variables en el tiempo de encolado, el tiempo de compilaci\u00f3n y el tiempo de ejecuci\u00f3n. Se consideran los valores de sintaxis de variables utilizados con la sintaxis de macro, la sintaxis de expresi\u00f3n de plantilla y la sintaxis de expresi\u00f3n de tiempo de ejecuci\u00f3n. Las variables pueden cambiar durante la canalizaci\u00f3n, los par\u00e1metros no. Las variables/par\u00e1metros no utilizados se eliminan en la canalizaci\u00f3n. \u00bfLa canalizaci\u00f3n cumple con los criterios de condiciones de etapa/trabajo? Comprobaci\u00f3n de permisos y seguridad Los valores secretos no deben imprimirse en la canalizaci\u00f3n, issecret se usa para imprimir secretos para la depuraci\u00f3n. Si la canalizaci\u00f3n utiliza grupos de variables en la biblioteca, aseg\u00farese de que la canalizaci\u00f3n tenga acceso a los grupos de variables creados. Si la canalizaci\u00f3n tiene una tarea remota en otro repositorio/organizaci\u00f3n, \u00bftiene acceso? Si la canalizaci\u00f3n intenta acceder a un archivo seguro, \u00bftiene el permiso? Si la canalizaci\u00f3n requiere aprobaci\u00f3n para las implementaciones del entorno, \u00bfqui\u00e9n es el aprobador? \u00bfNecesita guardar secretos y administrarlos? \u00bfConsider\u00f3 usar Azure KeyVault?","title":"YAML(Azure Pipelines) Code Reviews"},{"location":"revisiones%20de%20codigo/recetas/azure-pipelines-yaml/#yamlazure-pipelines-code-reviews","text":"","title":"YAML(Azure Pipelines) Code Reviews"},{"location":"revisiones%20de%20codigo/recetas/azure-pipelines-yaml/#guia-de-estilo","text":"Referencia del esquema YAML .","title":"Gu\u00eda de estilo"},{"location":"revisiones%20de%20codigo/recetas/azure-pipelines-yaml/#analisis-de-codigo-linting","text":"El linter YAML m\u00e1s popular es la extensi\u00f3n YAML . Esta extensi\u00f3n proporciona validaci\u00f3n YAML, esquematizaci\u00f3n de documentos, finalizaci\u00f3n autom\u00e1tica, compatibilidad con desplazamiento y funciones de formateador.","title":"An\u00e1lisis de c\u00f3digo / Linting"},{"location":"revisiones%20de%20codigo/recetas/azure-pipelines-yaml/#vs-code-extensions","text":"Hay una extensi\u00f3n de Azure Pipelines para VS Code para agregar resaltado de sintaxis y autocompletado. Tambi\u00e9n lo ayuda a configurar la compilaci\u00f3n e implementaci\u00f3n continuas de Azure WebApps sin salir de VS Code.","title":"VS Code Extensions"},{"location":"revisiones%20de%20codigo/recetas/azure-pipelines-yaml/#descripcion-general-de-yaml-en-azure-pipelines","text":"Cuando se activa la canalizaci\u00f3n, antes de ejecutar la canalizaci\u00f3n, hay algunas fases, como Tiempo de encolado, Tiempo de compilaci\u00f3n y Tiempo de ejecuci\u00f3n , donde las variables se interpretan por su sintaxis de expresi\u00f3n de tiempo de ejecuci\u00f3n . Cuando se activa la canalizaci\u00f3n, todos los archivos YAML anidados se expanden para ejecutarse en Azure Pipelines. Esta lista de verificaci\u00f3n contiene algunos consejos y trucos para revisar todos los archivos YAML anidados. Estos documentos pueden ser \u00fatiles al revisar archivos YAML: Documentaci\u00f3n YAML de Azure Pipelines Secuencia de ejecuci\u00f3n de canalizaci\u00f3n Conceptos clave para los nuevos Azure Pipelines","title":"Descripci\u00f3n general de YAML en Azure Pipelines"},{"location":"revisiones%20de%20codigo/recetas/azure-pipelines-yaml/#code-review-checklist","text":"Adem\u00e1s de la Checklist de Code Review (), tambi\u00e9n debe buscar estos elementos de revisi\u00f3n de c\u00f3digo espec\u00edficos de Azure Pipelines YAML:","title":"Code Review Checklist"},{"location":"revisiones%20de%20codigo/recetas/azure-pipelines-yaml/#estructura-del-pipeline","text":"Los pasos se entienden bien y los componentes son f\u00e1cilmente identificables. Aseg\u00farese de que haya una descripci\u00f3n adecuada displayName: para cada paso de la canalizaci\u00f3n. Los pasos o etapas de la canalizaci\u00f3n se comprueban en Azure Pipelines para comprender mejor los componentes. En caso de que tenga archivos YAML anidados complejos, la canalizaci\u00f3n en Azure Pipelines se edita para encontrar el archivo ra\u00edz desencadenante. Se visitan todas las referencias del archivo de plantilla para garantizar que un peque\u00f1o cambio no provoque cambios importantes; cambiar un archivo puede afectar a varias canalizaciones Los scripts en l\u00ednea largos en el archivo YAML se mueven a archivos de script","title":"Estructura del pipeline"},{"location":"revisiones%20de%20codigo/recetas/azure-pipelines-yaml/#estructura-yaml","text":"Los componentes reutilizables se dividen en plantillas YAML separadas. Las variables se separan por entorno almacenadas en plantillas o grupos de variables. Se tienen en cuenta los cambios de valor de las variables en el tiempo de encolado, el tiempo de compilaci\u00f3n y el tiempo de ejecuci\u00f3n. Se consideran los valores de sintaxis de variables utilizados con la sintaxis de macro, la sintaxis de expresi\u00f3n de plantilla y la sintaxis de expresi\u00f3n de tiempo de ejecuci\u00f3n. Las variables pueden cambiar durante la canalizaci\u00f3n, los par\u00e1metros no. Las variables/par\u00e1metros no utilizados se eliminan en la canalizaci\u00f3n. \u00bfLa canalizaci\u00f3n cumple con los criterios de condiciones de etapa/trabajo?","title":"Estructura YAML"},{"location":"revisiones%20de%20codigo/recetas/azure-pipelines-yaml/#comprobacion-de-permisos-y-seguridad","text":"Los valores secretos no deben imprimirse en la canalizaci\u00f3n, issecret se usa para imprimir secretos para la depuraci\u00f3n. Si la canalizaci\u00f3n utiliza grupos de variables en la biblioteca, aseg\u00farese de que la canalizaci\u00f3n tenga acceso a los grupos de variables creados. Si la canalizaci\u00f3n tiene una tarea remota en otro repositorio/organizaci\u00f3n, \u00bftiene acceso? Si la canalizaci\u00f3n intenta acceder a un archivo seguro, \u00bftiene el permiso? Si la canalizaci\u00f3n requiere aprobaci\u00f3n para las implementaciones del entorno, \u00bfqui\u00e9n es el aprobador? \u00bfNecesita guardar secretos y administrarlos? \u00bfConsider\u00f3 usar Azure KeyVault?","title":"Comprobaci\u00f3n de permisos y seguridad"},{"location":"revisiones%20de%20codigo/recetas/bash/","text":"Bash Code Reviews Gu\u00eda de estilo Google's Bash Style Guide An\u00e1lisis de c\u00f3digo / Linting Los proyectos deben verificar el c\u00f3digo bash con shellcheck como parte del proceso de CI. Adem\u00e1s de linting, shfmt se puede usar para formatear autom\u00e1ticamente scripts de shell. Configuraci\u00f3n del proyecto vscode-shellcheck La extensi\u00f3n Shellcheck debe usarse en VS Code, proporciona capacidades de an\u00e1lisis de c\u00f3digo est\u00e1tico y problemas de linting de reparaci\u00f3n autom\u00e1tica. Formateo autom\u00e1tico de c\u00f3digo shell-format La extensi\u00f3n shell-format formatea autom\u00e1ticamente sus scripts bash, archivos docker y varios archivos de configuraci\u00f3n. Depende de shfmt, que puede hacer cumplir las verificaciones de la gu\u00eda de estilo de Google para bash. Validaci\u00f3n de compilaci\u00f3n Para automatizar este proceso en Azure DevOps, puede agregar el siguiente fragmento de c\u00f3digo a su archivo azure-pipelines.yaml. Esto borrar\u00e1 cualquier script en la carpeta ./scripts/. - bash : | echo \"This checks for formatting and common bash errors. See wiki for error details and ignore options: https://github.com/koalaman/shellcheck/wiki/SC1000\" export scversion=\"stable\" wget -qO- \"https://github.com/koalaman/shellcheck/releases/download/${scversion?}/shellcheck-${scversion?}.linux.x86_64.tar.xz\" | tar -xJv sudo mv \"shellcheck-${scversion}/shellcheck\" /usr/bin/ rm -r \"shellcheck-${scversion}\" shellcheck ./scripts/*.sh displayName : \"Validate Scripts: Shellcheck\" Adem\u00e1s, sus scripts de shell se pueden formatear en su canalizaci\u00f3n de compilaci\u00f3n usando la herramienta shfmt. Para integrar shfmt en su canal de compilaci\u00f3n, haga lo siguiente: - bash : | echo \"This step does auto formatting of shell scripts\" shfmt -l -w ./scripts/*.sh displayName : \"Format Scripts: shfmt\" Las pruebas unitarias que usan shunit2 tambi\u00e9n se pueden agregar a la canalizaci\u00f3n de compilaci\u00f3n, usando el siguiente bloque: - bash : | echo \"This step unit tests shell scripts by using shunit2\" ./shunit2 displayName : \"Format Scripts: shfmt\" Pre-Commit Hooks Todos los desarrolladores deben ejecutar shellcheck y shfmt como pre-commit hooks. Paso 1 Ejecute pip install pre-commit . Alternativamente, puede ejecutar brew install pre-commit si est\u00e1 utilizando homebrew. Paso 2 Agregue el archivo .pre-commit-config.yaml a la ra\u00edz del proyecto go. Ejecute shfmt en el pre-commit agreg\u00e1ndolo al archivo .pre-commit-config.yaml como se muestra a continuaci\u00f3n. - repo : git://github.com/pecigonzalo/pre-commit-fmt sha : master hooks : - id : shell-fmt args : - --indent=4 - repo : https://github.com/shellcheck-py/shellcheck-py rev : v0.7.1.1 hooks : - id : shellcheck Paso 3 Ejecute $ pre-commit install para configurar los scripts de git hook Dependencias Los scripts Bash se utilizan a menudo para \"unir\" otros sistemas y herramientas. Como tal, los scripts de Bash a menudo pueden tener dependencias numerosas y/o complicadas. Considere el uso de contenedores Docker para asegurarse de que los scripts se ejecuten en un entorno port\u00e1til y reproducible que contenga todas las dependencias correctas. Para asegurarse de que los scripts dockerizados sean f\u00e1ciles de ejecutar, considere hacer que el uso de Docker sea transparente para la persona que llama al script envolviendo el script en un 'bootstrap' que verifica si el script se est\u00e1 ejecutando en Docker y se vuelve a ejecutar en Docker si no es as\u00ed. Esto proporciona lo mejor de ambos mundos: ejecuci\u00f3n sencilla de scripts y entornos coherentes. if [[ \"${DOCKER}\" != \"true\" ]]; then docker build -t my_script -f my_script.Dockerfile . > /dev/null docker run -e DOCKER=true my_script \"$@\" exit $? fi # ... implementation of my_script here can assume that all of its dependencies exist since it's always running in Docker ... Code Review Checklist Adem\u00e1s de la Checklist de Code Review (), tambi\u00e9n debe buscar estos elementos de revisi\u00f3n de c\u00f3digo espec\u00edficos de bash: \u00bfEste c\u00f3digo utiliza opciones de shell integradas como set -o, set -e, set -u para el control de ejecuci\u00f3n de scripts de shell? \u00bfEl c\u00f3digo est\u00e1 modularizado? Los scripts de shell se pueden modularizar como m\u00f3dulos de python. Las partes de los scripts bash deben obtenerse en proyectos bash complejos. \u00bfTodas las excepciones se manejan correctamente? Las excepciones deben manejarse correctamente utilizando c\u00f3digos de salida o se\u00f1ales de captura. \u00bfPasa el c\u00f3digo todas las verificaciones linting seg\u00fan shellcheck y las pruebas unitarias seg\u00fan shunit2? \u00bfEl c\u00f3digo usa rutas relativas o rutas absolutas? Deben evitarse las rutas relativas, ya que son propensas a los ataques del entorno. Si se necesita una ruta relativa, verifique que la variable PATH est\u00e9 configurada. \u00bfEl c\u00f3digo toma credenciales como entrada del usuario? \u00bfLas credenciales est\u00e1n enmascaradas o encriptadas en el script?","title":"Bash Code Reviews"},{"location":"revisiones%20de%20codigo/recetas/bash/#bash-code-reviews","text":"","title":"Bash Code Reviews"},{"location":"revisiones%20de%20codigo/recetas/bash/#guia-de-estilo","text":"Google's Bash Style Guide","title":"Gu\u00eda de estilo"},{"location":"revisiones%20de%20codigo/recetas/bash/#analisis-de-codigo-linting","text":"Los proyectos deben verificar el c\u00f3digo bash con shellcheck como parte del proceso de CI. Adem\u00e1s de linting, shfmt se puede usar para formatear autom\u00e1ticamente scripts de shell.","title":"An\u00e1lisis de c\u00f3digo / Linting"},{"location":"revisiones%20de%20codigo/recetas/bash/#configuracion-del-proyecto","text":"","title":"Configuraci\u00f3n del proyecto"},{"location":"revisiones%20de%20codigo/recetas/bash/#vscode-shellcheck","text":"La extensi\u00f3n Shellcheck debe usarse en VS Code, proporciona capacidades de an\u00e1lisis de c\u00f3digo est\u00e1tico y problemas de linting de reparaci\u00f3n autom\u00e1tica.","title":"vscode-shellcheck"},{"location":"revisiones%20de%20codigo/recetas/bash/#formateo-automatico-de-codigo","text":"","title":"Formateo autom\u00e1tico de c\u00f3digo"},{"location":"revisiones%20de%20codigo/recetas/bash/#shell-format","text":"La extensi\u00f3n shell-format formatea autom\u00e1ticamente sus scripts bash, archivos docker y varios archivos de configuraci\u00f3n. Depende de shfmt, que puede hacer cumplir las verificaciones de la gu\u00eda de estilo de Google para bash.","title":"shell-format"},{"location":"revisiones%20de%20codigo/recetas/bash/#validacion-de-compilacion","text":"Para automatizar este proceso en Azure DevOps, puede agregar el siguiente fragmento de c\u00f3digo a su archivo azure-pipelines.yaml. Esto borrar\u00e1 cualquier script en la carpeta ./scripts/. - bash : | echo \"This checks for formatting and common bash errors. See wiki for error details and ignore options: https://github.com/koalaman/shellcheck/wiki/SC1000\" export scversion=\"stable\" wget -qO- \"https://github.com/koalaman/shellcheck/releases/download/${scversion?}/shellcheck-${scversion?}.linux.x86_64.tar.xz\" | tar -xJv sudo mv \"shellcheck-${scversion}/shellcheck\" /usr/bin/ rm -r \"shellcheck-${scversion}\" shellcheck ./scripts/*.sh displayName : \"Validate Scripts: Shellcheck\" Adem\u00e1s, sus scripts de shell se pueden formatear en su canalizaci\u00f3n de compilaci\u00f3n usando la herramienta shfmt. Para integrar shfmt en su canal de compilaci\u00f3n, haga lo siguiente: - bash : | echo \"This step does auto formatting of shell scripts\" shfmt -l -w ./scripts/*.sh displayName : \"Format Scripts: shfmt\" Las pruebas unitarias que usan shunit2 tambi\u00e9n se pueden agregar a la canalizaci\u00f3n de compilaci\u00f3n, usando el siguiente bloque: - bash : | echo \"This step unit tests shell scripts by using shunit2\" ./shunit2 displayName : \"Format Scripts: shfmt\"","title":"Validaci\u00f3n de compilaci\u00f3n"},{"location":"revisiones%20de%20codigo/recetas/bash/#pre-commit-hooks","text":"Todos los desarrolladores deben ejecutar shellcheck y shfmt como pre-commit hooks. Paso 1 Ejecute pip install pre-commit . Alternativamente, puede ejecutar brew install pre-commit si est\u00e1 utilizando homebrew. Paso 2 Agregue el archivo .pre-commit-config.yaml a la ra\u00edz del proyecto go. Ejecute shfmt en el pre-commit agreg\u00e1ndolo al archivo .pre-commit-config.yaml como se muestra a continuaci\u00f3n. - repo : git://github.com/pecigonzalo/pre-commit-fmt sha : master hooks : - id : shell-fmt args : - --indent=4 - repo : https://github.com/shellcheck-py/shellcheck-py rev : v0.7.1.1 hooks : - id : shellcheck Paso 3 Ejecute $ pre-commit install para configurar los scripts de git hook","title":"Pre-Commit Hooks"},{"location":"revisiones%20de%20codigo/recetas/bash/#dependencias","text":"Los scripts Bash se utilizan a menudo para \"unir\" otros sistemas y herramientas. Como tal, los scripts de Bash a menudo pueden tener dependencias numerosas y/o complicadas. Considere el uso de contenedores Docker para asegurarse de que los scripts se ejecuten en un entorno port\u00e1til y reproducible que contenga todas las dependencias correctas. Para asegurarse de que los scripts dockerizados sean f\u00e1ciles de ejecutar, considere hacer que el uso de Docker sea transparente para la persona que llama al script envolviendo el script en un 'bootstrap' que verifica si el script se est\u00e1 ejecutando en Docker y se vuelve a ejecutar en Docker si no es as\u00ed. Esto proporciona lo mejor de ambos mundos: ejecuci\u00f3n sencilla de scripts y entornos coherentes. if [[ \"${DOCKER}\" != \"true\" ]]; then docker build -t my_script -f my_script.Dockerfile . > /dev/null docker run -e DOCKER=true my_script \"$@\" exit $? fi # ... implementation of my_script here can assume that all of its dependencies exist since it's always running in Docker ...","title":"Dependencias"},{"location":"revisiones%20de%20codigo/recetas/bash/#code-review-checklist","text":"Adem\u00e1s de la Checklist de Code Review (), tambi\u00e9n debe buscar estos elementos de revisi\u00f3n de c\u00f3digo espec\u00edficos de bash: \u00bfEste c\u00f3digo utiliza opciones de shell integradas como set -o, set -e, set -u para el control de ejecuci\u00f3n de scripts de shell? \u00bfEl c\u00f3digo est\u00e1 modularizado? Los scripts de shell se pueden modularizar como m\u00f3dulos de python. Las partes de los scripts bash deben obtenerse en proyectos bash complejos. \u00bfTodas las excepciones se manejan correctamente? Las excepciones deben manejarse correctamente utilizando c\u00f3digos de salida o se\u00f1ales de captura. \u00bfPasa el c\u00f3digo todas las verificaciones linting seg\u00fan shellcheck y las pruebas unitarias seg\u00fan shunit2? \u00bfEl c\u00f3digo usa rutas relativas o rutas absolutas? Deben evitarse las rutas relativas, ya que son propensas a los ataques del entorno. Si se necesita una ruta relativa, verifique que la variable PATH est\u00e9 configurada. \u00bfEl c\u00f3digo toma credenciales como entrada del usuario? \u00bfLas credenciales est\u00e1n enmascaradas o encriptadas en el script?","title":"Code Review Checklist"},{"location":"revisiones%20de%20codigo/recetas/csharp/","text":"","title":"Csharp"},{"location":"revisiones%20de%20codigo/recetas/markdown/","text":"Markdown Code Reviews Gu\u00eda de estilo La documentaci\u00f3n se trata como cualquier otro c\u00f3digo fuente y se deben seguir las mismas reglas y listas de verificaci\u00f3n. La documentaci\u00f3n debe usar una buena sintaxis de Markdown para garantizar que se analice correctamente y seguir las pautas de un buen estilo de escritura para garantizar que el documento sea f\u00e1cil de leer y comprender. Markdown Markdown es un lenguaje de marcado ligero que puede usar para agregar elementos de formato a documentos de texto sin formato. Es uno de los lenguajes de marcado m\u00e1s populares del mundo. Puede encontrar m\u00e1s informaci\u00f3n y documentaci\u00f3n completa aqu\u00ed . Linting Markdown tiene una forma espec\u00edfica de formatearse. Es importante respetar este formato, de lo contrario, algunos int\u00e9rpretes estrictos no mostrar\u00e1n correctamente el documento. Los linters a menudo se usan para ayudar a los desarrolladores a crear documentos correctamente al verificar la sintaxis, la gram\u00e1tica y el idioma ingl\u00e9s correctos de Markdown. Una buena configuraci\u00f3n incluye un linter markdown que se usa durante la edici\u00f3n y la verificaci\u00f3n del PR de compilaci\u00f3n, y un linter de gram\u00e1tica que se usa mientras se edita el documento. La siguiente es una lista de linters que podr\u00edan usarse en esta configuraci\u00f3n. markdownlint markdownlint es un linter para markdown que verifica la sintaxis de Markdown y tambi\u00e9n aplica reglas que hacen que el texto sea m\u00e1s legible. Markdownlint-cli es una CLI f\u00e1cil de usar basada en Markdownlint. Est\u00e1 disponible como ruby gem , un paquete npm , una CLI de Node.js y una extensi\u00f3n de VS Code . La extensi\u00f3n Prettier de VS Code tambi\u00e9n detecta todos los errores de markdownlint. Una lista completa de reglas de markdownlint est\u00e1 disponible aqu\u00ed . proselint proselint es una utilidad de l\u00ednea de comandos que comprueba jerga, errores ortogr\u00e1ficos, redundancia, lenguaje corporativo y otros problemas relacionados con el lenguaje. Est\u00e1 disponible como paquete de python y como paquete de node . VS Code Extensions Write Good Linter La extensi\u00f3n Write Good Linter se integra con VS Code para brindar consejos sobre gram\u00e1tica y lenguaje mientras se edita el documento. extensi\u00f3n markdownlint La extensi\u00f3n markdownlint examina los documentos de Markdown y muestra advertencias sobre violaciones de reglas durante la edici\u00f3n. Validaci\u00f3n de compilaci\u00f3n Linting para validaci\u00f3n de PR Para automatizar el linting con markdownlint para la validaci\u00f3n de PR en las acciones de GitHub como lo hacemos en este repositorio, use el siguiente YAML. name : Markdownlint on : push : paths : - \"**/*.md\" pull_request : paths : - \"**/*.md\" jobs : lint : runs-on : ubuntu-latest steps : - uses : actions/checkout@v2 - name : Use Node.js uses : actions/setup-node@v1 with : node-version : 12.x - name : Run Markdownlint run : | npm i -g markdownlint-cli markdownlint \"**/*.md\" --ignore node_modules Comprobaci\u00f3n de enlaces Para automatizar la verificaci\u00f3n de enlaces en sus archivos markdown, agregue la acci\u00f3n markdown-link-check a su pipeline de validaci\u00f3n: markdown-link-check : runs-on : ubuntu-latest steps : - uses : actions/checkout@master - uses : gaurav-nelson/github-action-markdown-link-check@v1 Puede encontrar m\u00e1s informaci\u00f3n sobre las opciones de acci\u00f3n de markdown-link-check en la p\u00e1gina de inicio de markdown-link-check Code Review Checklist Adem\u00e1s de la Checklist de Code Review (), tambi\u00e9n debe buscar estos elementos de revisi\u00f3n de c\u00f3digo espec\u00edficos de la documentaci\u00f3n: \u00bfEl documento es f\u00e1cil de leer y comprender y sigue buenas pautas de escritura? \u00bfHay una \u00fanica fuente de verdad o el contenido se repite en m\u00e1s de un documento? \u00bfLa documentaci\u00f3n est\u00e1 al d\u00eda con el c\u00f3digo? \u00bfLa documentaci\u00f3n es t\u00e9cnica y \u00e9ticamente correcta?","title":"Markdown Code Reviews"},{"location":"revisiones%20de%20codigo/recetas/markdown/#markdown-code-reviews","text":"","title":"Markdown Code Reviews"},{"location":"revisiones%20de%20codigo/recetas/markdown/#guia-de-estilo","text":"La documentaci\u00f3n se trata como cualquier otro c\u00f3digo fuente y se deben seguir las mismas reglas y listas de verificaci\u00f3n. La documentaci\u00f3n debe usar una buena sintaxis de Markdown para garantizar que se analice correctamente y seguir las pautas de un buen estilo de escritura para garantizar que el documento sea f\u00e1cil de leer y comprender.","title":"Gu\u00eda de estilo"},{"location":"revisiones%20de%20codigo/recetas/markdown/#markdown","text":"Markdown es un lenguaje de marcado ligero que puede usar para agregar elementos de formato a documentos de texto sin formato. Es uno de los lenguajes de marcado m\u00e1s populares del mundo. Puede encontrar m\u00e1s informaci\u00f3n y documentaci\u00f3n completa aqu\u00ed .","title":"Markdown"},{"location":"revisiones%20de%20codigo/recetas/markdown/#linting","text":"Markdown tiene una forma espec\u00edfica de formatearse. Es importante respetar este formato, de lo contrario, algunos int\u00e9rpretes estrictos no mostrar\u00e1n correctamente el documento. Los linters a menudo se usan para ayudar a los desarrolladores a crear documentos correctamente al verificar la sintaxis, la gram\u00e1tica y el idioma ingl\u00e9s correctos de Markdown. Una buena configuraci\u00f3n incluye un linter markdown que se usa durante la edici\u00f3n y la verificaci\u00f3n del PR de compilaci\u00f3n, y un linter de gram\u00e1tica que se usa mientras se edita el documento. La siguiente es una lista de linters que podr\u00edan usarse en esta configuraci\u00f3n.","title":"Linting"},{"location":"revisiones%20de%20codigo/recetas/markdown/#markdownlint","text":"markdownlint es un linter para markdown que verifica la sintaxis de Markdown y tambi\u00e9n aplica reglas que hacen que el texto sea m\u00e1s legible. Markdownlint-cli es una CLI f\u00e1cil de usar basada en Markdownlint. Est\u00e1 disponible como ruby gem , un paquete npm , una CLI de Node.js y una extensi\u00f3n de VS Code . La extensi\u00f3n Prettier de VS Code tambi\u00e9n detecta todos los errores de markdownlint. Una lista completa de reglas de markdownlint est\u00e1 disponible aqu\u00ed .","title":"markdownlint"},{"location":"revisiones%20de%20codigo/recetas/markdown/#proselint","text":"proselint es una utilidad de l\u00ednea de comandos que comprueba jerga, errores ortogr\u00e1ficos, redundancia, lenguaje corporativo y otros problemas relacionados con el lenguaje. Est\u00e1 disponible como paquete de python y como paquete de node .","title":"proselint"},{"location":"revisiones%20de%20codigo/recetas/markdown/#vs-code-extensions","text":"","title":"VS Code Extensions"},{"location":"revisiones%20de%20codigo/recetas/markdown/#write-good-linter","text":"La extensi\u00f3n Write Good Linter se integra con VS Code para brindar consejos sobre gram\u00e1tica y lenguaje mientras se edita el documento. extensi\u00f3n markdownlint La extensi\u00f3n markdownlint examina los documentos de Markdown y muestra advertencias sobre violaciones de reglas durante la edici\u00f3n.","title":"Write Good Linter"},{"location":"revisiones%20de%20codigo/recetas/markdown/#validacion-de-compilacion","text":"","title":"Validaci\u00f3n de compilaci\u00f3n"},{"location":"revisiones%20de%20codigo/recetas/markdown/#linting-para-validacion-de-pr","text":"Para automatizar el linting con markdownlint para la validaci\u00f3n de PR en las acciones de GitHub como lo hacemos en este repositorio, use el siguiente YAML. name : Markdownlint on : push : paths : - \"**/*.md\" pull_request : paths : - \"**/*.md\" jobs : lint : runs-on : ubuntu-latest steps : - uses : actions/checkout@v2 - name : Use Node.js uses : actions/setup-node@v1 with : node-version : 12.x - name : Run Markdownlint run : | npm i -g markdownlint-cli markdownlint \"**/*.md\" --ignore node_modules","title":"Linting para validaci\u00f3n de PR"},{"location":"revisiones%20de%20codigo/recetas/markdown/#comprobacion-de-enlaces","text":"Para automatizar la verificaci\u00f3n de enlaces en sus archivos markdown, agregue la acci\u00f3n markdown-link-check a su pipeline de validaci\u00f3n: markdown-link-check : runs-on : ubuntu-latest steps : - uses : actions/checkout@master - uses : gaurav-nelson/github-action-markdown-link-check@v1 Puede encontrar m\u00e1s informaci\u00f3n sobre las opciones de acci\u00f3n de markdown-link-check en la p\u00e1gina de inicio de markdown-link-check","title":"Comprobaci\u00f3n de enlaces"},{"location":"revisiones%20de%20codigo/recetas/markdown/#code-review-checklist","text":"Adem\u00e1s de la Checklist de Code Review (), tambi\u00e9n debe buscar estos elementos de revisi\u00f3n de c\u00f3digo espec\u00edficos de la documentaci\u00f3n: \u00bfEl documento es f\u00e1cil de leer y comprender y sigue buenas pautas de escritura? \u00bfHay una \u00fanica fuente de verdad o el contenido se repite en m\u00e1s de un documento? \u00bfLa documentaci\u00f3n est\u00e1 al d\u00eda con el c\u00f3digo? \u00bfLa documentaci\u00f3n es t\u00e9cnica y \u00e9ticamente correcta?","title":"Code Review Checklist"},{"location":"revisiones%20de%20codigo/recetas/python/","text":"Python Code Reviews Gu\u00eda de estilo Los desarrolladores deben seguir la gu\u00eda de estilo de PEP8 con sugerencias de tipo . El uso de sugerencias de tipo en conjunto con el linting evita errores comunes que son dif\u00edciles de depurar. Los proyectos deben verificar el c\u00f3digo de Python con herramientas automatizadas. Se debe agregar Linting para compilar la validaci\u00f3n, y tanto el formato de c\u00f3digo como el de Linting se pueden agregar a los pre-commit hooks y a VS Code. An\u00e1lisis de c\u00f3digo / Linting Los 2 linters de python m\u00e1s populares son Pylint y Flake8 . Ambos verifican el cumplimiento de PEP8 pero var\u00edan un poco en qu\u00e9 otras reglas verifican. En general, Pylint tiende a ser un poco m\u00e1s estricto y da m\u00e1s falsos positivos, pero ambas son buenas opciones. Tanto Pylint como Flake8 se pueden configurar en VS Code usando la extensi\u00f3n python de VS Code. Pylint Instalar Pylint pip install pylint Ejecutar Pylint pylint src # lint the source directory Flake8 Flake8 es un contenedor simple y r\u00e1pido de Pyflakes (para detectar errores de codificaci\u00f3n) y pycodestyle (para pep8). Instalar Flake8 pip install flake8 Agregar extensi\u00f3n para la herramienta pydocstyle (para doc strings ) a flake8. pip install flake8-docstrings Agregar extensi\u00f3n para la herramienta pep8-naming (para convenciones de nombre en pep8) a flake8. pip install pep8-naming Ejecutar Flake8 flake8 . # lint the whole project Formateo autom\u00e1tico de c\u00f3digo Black Black es una herramienta de formato de c\u00f3digo. Elimina toda la necesidad de que pycodestyle rega\u00f1e sobre el formato, por lo que el equipo puede concentrarse en el contenido frente al estilo. No es posible configurar black para sus propias necesidades de estilo. pip install black Formatear c\u00f3digo python black [ file/folder ] Autopep8 Autopep8 es m\u00e1s indulgente y permite una mayor configuraci\u00f3n si desea un formato menos estricto. pip install autopep8 Formatear c\u00f3digo python autopep8 [ file/folder ] --in-place yapf yapf (Yet Another Python Formatter) es un formateador de Python de Google basado en ideas de gofmt. Tambi\u00e9n es m\u00e1s configurable y una buena opci\u00f3n para el formato de c\u00f3digo autom\u00e1tico. pip install yapf Formatear c\u00f3digo python yapf [ file/folder ] --in-place VS Code Extensions [Python]((https://marketplace.visualstudio.com/items?itemName=ms-python.python) Es la extensi\u00f3n base que deber\u00eda haber instalado para el desarrollo de Python con VS Code. Permite intellisense, depuraci\u00f3n, linting (con los linters anteriores), pruebas con pytest o unittest y formateo de c\u00f3digo con los formateadores mencionados anteriormente. Pyright Esta extensi\u00f3n aumenta VS Code con verificaci\u00f3n de tipo est\u00e1tico cuando usa sugerencias de tipo. def add ( first_value : int , second_value : int ) -> int : return first_value + second_value Validaci\u00f3n de compilaci\u00f3n Para automatizar el linting con flake8 y las pruebas con pytest en Azure Devops, puede agregar el siguiente fragmento a su archivo azure-pipelines.yaml. trigger : branches : include : - develop - master paths : include : - src/* pool : vmImage : 'ubuntu-latest' jobs : - job : LintAndTest displayName : Lint and Test steps : - checkout : self lfs : true - task : UsePythonVersion@0 displayName : 'Set Python version to 3.6' inputs : versionSpec : '3.6' - script : pip3 install --user -r requirements.txt displayName : 'Install dependencies' - script : | # Install Flake8 pip3 install --user flake8 # Install PyTest pip3 install --user pytest displayName : 'Install Flake8 and PyTest' - script : | python3 -m flake8 displayName : 'Run Flake8 linter' - script : | # Run PyTest tester python3 -m pytest --junitxml=./test-results.xml displayName : 'Run PyTest Tester' - task : PublishTestResults@2 displayName : 'Publish PyTest results' condition : succeededOrFailed() inputs : testResultsFiles : '**/test-*.xml' testRunTitle : 'Publish test results for Python $(python.version)' Pre-commit hooks Pre-commit hooks le permiten formatear y lintear el c\u00f3digo localmente antes de enviar el PR. Agregar pre-commit hooks para su repositorio de python es f\u00e1cil usando el paquete pre-commit. Instale pre-commit y agr\u00e9guelo a requirements.txt pip install pre-commit Agregue un archivo .pre-commit-config.yaml en la ra\u00edz del repositorio, con las deseadas acciones previas al commit. repos : - repo : https://github.com/ambv/black rev : stable hooks : - id : black language_version : python3.6 - repo : https://github.com/pre-commit/pre-commit-hooks rev : v1.2.3 hooks : - id : flake8 Cada desarrollador que desee configurar pre-commit hooks puede ejecutar pre-commit install Code Review Checklist Adem\u00e1s de la Checklist de Code Review (), tambi\u00e9n debe buscar estos elementos de revisi\u00f3n de c\u00f3digo espec\u00edficos de python: \u00bfTodos los paquetes nuevos utilizados est\u00e1n incluidos en requirements.txt? \u00bfPasa el c\u00f3digo todas las comprobaciones lint? \u00bfLas funciones usan sugerencias de tipo y hay alg\u00fan error de sugerencia de tipo? \u00bfEl c\u00f3digo es legible y usa construcciones pythonic siempre que sea posible?","title":"Python Code Reviews"},{"location":"revisiones%20de%20codigo/recetas/python/#python-code-reviews","text":"","title":"Python Code Reviews"},{"location":"revisiones%20de%20codigo/recetas/python/#guia-de-estilo","text":"Los desarrolladores deben seguir la gu\u00eda de estilo de PEP8 con sugerencias de tipo . El uso de sugerencias de tipo en conjunto con el linting evita errores comunes que son dif\u00edciles de depurar. Los proyectos deben verificar el c\u00f3digo de Python con herramientas automatizadas. Se debe agregar Linting para compilar la validaci\u00f3n, y tanto el formato de c\u00f3digo como el de Linting se pueden agregar a los pre-commit hooks y a VS Code.","title":"Gu\u00eda de estilo"},{"location":"revisiones%20de%20codigo/recetas/python/#analisis-de-codigo-linting","text":"Los 2 linters de python m\u00e1s populares son Pylint y Flake8 . Ambos verifican el cumplimiento de PEP8 pero var\u00edan un poco en qu\u00e9 otras reglas verifican. En general, Pylint tiende a ser un poco m\u00e1s estricto y da m\u00e1s falsos positivos, pero ambas son buenas opciones. Tanto Pylint como Flake8 se pueden configurar en VS Code usando la extensi\u00f3n python de VS Code.","title":"An\u00e1lisis de c\u00f3digo / Linting"},{"location":"revisiones%20de%20codigo/recetas/python/#pylint","text":"Instalar Pylint pip install pylint Ejecutar Pylint pylint src # lint the source directory","title":"Pylint"},{"location":"revisiones%20de%20codigo/recetas/python/#flake8","text":"Flake8 es un contenedor simple y r\u00e1pido de Pyflakes (para detectar errores de codificaci\u00f3n) y pycodestyle (para pep8). Instalar Flake8 pip install flake8 Agregar extensi\u00f3n para la herramienta pydocstyle (para doc strings ) a flake8. pip install flake8-docstrings Agregar extensi\u00f3n para la herramienta pep8-naming (para convenciones de nombre en pep8) a flake8. pip install pep8-naming Ejecutar Flake8 flake8 . # lint the whole project","title":"Flake8"},{"location":"revisiones%20de%20codigo/recetas/python/#formateo-automatico-de-codigo","text":"","title":"Formateo autom\u00e1tico de c\u00f3digo"},{"location":"revisiones%20de%20codigo/recetas/python/#black","text":"Black es una herramienta de formato de c\u00f3digo. Elimina toda la necesidad de que pycodestyle rega\u00f1e sobre el formato, por lo que el equipo puede concentrarse en el contenido frente al estilo. No es posible configurar black para sus propias necesidades de estilo. pip install black Formatear c\u00f3digo python black [ file/folder ]","title":"Black"},{"location":"revisiones%20de%20codigo/recetas/python/#autopep8","text":"Autopep8 es m\u00e1s indulgente y permite una mayor configuraci\u00f3n si desea un formato menos estricto. pip install autopep8 Formatear c\u00f3digo python autopep8 [ file/folder ] --in-place","title":"Autopep8"},{"location":"revisiones%20de%20codigo/recetas/python/#yapf","text":"yapf (Yet Another Python Formatter) es un formateador de Python de Google basado en ideas de gofmt. Tambi\u00e9n es m\u00e1s configurable y una buena opci\u00f3n para el formato de c\u00f3digo autom\u00e1tico. pip install yapf Formatear c\u00f3digo python yapf [ file/folder ] --in-place","title":"yapf"},{"location":"revisiones%20de%20codigo/recetas/python/#vs-code-extensions","text":"","title":"VS Code Extensions"},{"location":"revisiones%20de%20codigo/recetas/python/#pythonhttpsmarketplacevisualstudiocomitemsitemnamems-pythonpython","text":"Es la extensi\u00f3n base que deber\u00eda haber instalado para el desarrollo de Python con VS Code. Permite intellisense, depuraci\u00f3n, linting (con los linters anteriores), pruebas con pytest o unittest y formateo de c\u00f3digo con los formateadores mencionados anteriormente.","title":"[Python]((https://marketplace.visualstudio.com/items?itemName=ms-python.python)"},{"location":"revisiones%20de%20codigo/recetas/python/#pyright","text":"Esta extensi\u00f3n aumenta VS Code con verificaci\u00f3n de tipo est\u00e1tico cuando usa sugerencias de tipo. def add ( first_value : int , second_value : int ) -> int : return first_value + second_value","title":"Pyright"},{"location":"revisiones%20de%20codigo/recetas/python/#validacion-de-compilacion","text":"Para automatizar el linting con flake8 y las pruebas con pytest en Azure Devops, puede agregar el siguiente fragmento a su archivo azure-pipelines.yaml. trigger : branches : include : - develop - master paths : include : - src/* pool : vmImage : 'ubuntu-latest' jobs : - job : LintAndTest displayName : Lint and Test steps : - checkout : self lfs : true - task : UsePythonVersion@0 displayName : 'Set Python version to 3.6' inputs : versionSpec : '3.6' - script : pip3 install --user -r requirements.txt displayName : 'Install dependencies' - script : | # Install Flake8 pip3 install --user flake8 # Install PyTest pip3 install --user pytest displayName : 'Install Flake8 and PyTest' - script : | python3 -m flake8 displayName : 'Run Flake8 linter' - script : | # Run PyTest tester python3 -m pytest --junitxml=./test-results.xml displayName : 'Run PyTest Tester' - task : PublishTestResults@2 displayName : 'Publish PyTest results' condition : succeededOrFailed() inputs : testResultsFiles : '**/test-*.xml' testRunTitle : 'Publish test results for Python $(python.version)'","title":"Validaci\u00f3n de compilaci\u00f3n"},{"location":"revisiones%20de%20codigo/recetas/python/#pre-commit-hooks","text":"Pre-commit hooks le permiten formatear y lintear el c\u00f3digo localmente antes de enviar el PR. Agregar pre-commit hooks para su repositorio de python es f\u00e1cil usando el paquete pre-commit. Instale pre-commit y agr\u00e9guelo a requirements.txt pip install pre-commit Agregue un archivo .pre-commit-config.yaml en la ra\u00edz del repositorio, con las deseadas acciones previas al commit. repos : - repo : https://github.com/ambv/black rev : stable hooks : - id : black language_version : python3.6 - repo : https://github.com/pre-commit/pre-commit-hooks rev : v1.2.3 hooks : - id : flake8 Cada desarrollador que desee configurar pre-commit hooks puede ejecutar pre-commit install","title":"Pre-commit hooks"},{"location":"revisiones%20de%20codigo/recetas/python/#code-review-checklist","text":"Adem\u00e1s de la Checklist de Code Review (), tambi\u00e9n debe buscar estos elementos de revisi\u00f3n de c\u00f3digo espec\u00edficos de python: \u00bfTodos los paquetes nuevos utilizados est\u00e1n incluidos en requirements.txt? \u00bfPasa el c\u00f3digo todas las comprobaciones lint? \u00bfLas funciones usan sugerencias de tipo y hay alg\u00fan error de sugerencia de tipo? \u00bfEl c\u00f3digo es legible y usa construcciones pythonic siempre que sea posible?","title":"Code Review Checklist"},{"location":"revisiones%20de%20codigo/recetas/terraform/","text":"Terraform Code Reviews Gu\u00eda de estilo Terraform style guide Los proyectos deben verificar los scripts de Terraform con herramientas automatizadas. An\u00e1lisis de c\u00f3digo / Linting TFLint TFLint es un linter de Terraform centrado en posibles errores, mejores pr\u00e1cticas, etc. Una vez que TFLint est\u00e1 instalado en el entorno, se puede invocar mediante la extensi\u00f3n de terraform de VS Code. VS Code Extensions Extensi\u00f3n Terraform Esta extensi\u00f3n proporciona capacidades de resaltado, linting, formateo y validaci\u00f3n de sintaxis. Extensi\u00f3n Azure Terraform Esta extensi\u00f3n proporciona compatibilidad con comandos de Terraform, visualizaci\u00f3n de gr\u00e1ficos de recursos e integraci\u00f3n de CloudShell dentro de VS Code. Validaci\u00f3n de compilaci\u00f3n El siguiente script de ejemplo se puede usar para instalar terraform y un linter que luego verifica el formato y los errores comunes. #! /bin/bash set -e SCRIPT_DIR = $( dirname \" $BASH_SOURCE \" ) cd \" $SCRIPT_DIR \" TF_VERSION = 0 .12.4 TF_LINT_VERSION = 0 .9.1 echo -e \"\\n\\n>>> Installing Terraform 0.12\" # Install terraform tooling for linting terraform wget -q https://releases.hashicorp.com/terraform/ ${ TF_VERSION } /terraform_ ${ TF_VERSION } _linux_amd64.zip -O /tmp/terraform.zip sudo unzip -q -o -d /usr/local/bin/ /tmp/terraform.zip echo \"\" echo -e \"\\n\\n>>> Install tflint (3rd party)\" wget -q https://github.com/wata727/tflint/releases/download/v ${ TF_LINT_VERSION } /tflint_linux_amd64.zip -O /tmp/tflint.zip sudo unzip -q -o -d /usr/local/bin/ /tmp/tflint.zip echo -e \"\\n\\n>>> Terraform version\" terraform -version echo -e \"\\n\\n>>> Terraform Format (if this fails use 'terraform fmt -recursive' command to resolve\" terraform fmt -recursive -diff -check echo -e \"\\n\\n>>> tflint\" tflint echo -e \"\\n\\n>>> Terraform init\" terraform init echo -e \"\\n\\n>>> Terraform validate\" terraform validate Code Review Checklist Adem\u00e1s de la Checklist de Code Review (), tambi\u00e9n debe buscar estos elementos de revisi\u00f3n de c\u00f3digo espec\u00edficos de Terraform: Proveedores \u00bfTodos los proveedores utilizados en los scripts de terraform est\u00e1n versionados para evitar cambios importantes en el futuro? Organizaci\u00f3n del repositorio \u00bfEl c\u00f3digo se dividi\u00f3 en m\u00f3dulos reutilizables? \u00bfLos m\u00f3dulos se dividen en archivos .tf separados cuando corresponde? El repositorio contiene un README.md que describe la arquitectura aprovisionada. Si el c\u00f3digo de Terraform se mezcla con el c\u00f3digo fuente de la aplicaci\u00f3n, \u00bfel c\u00f3digo de Terraform se a\u00edsla en una carpeta dedicada? Estado de Terraform \u00bfEl proyecto Terraform est\u00e1 configurado con Azure Storage como back-end de estado remoto? \u00bfLa clave de la cuenta de almacenamiento de back-end de estado remoto almacen\u00f3 una ubicaci\u00f3n segura (por ejemplo, Azure Key Vault)? \u00bfEl proyecto est\u00e1 configurado para usar archivos de estado en funci\u00f3n del entorno y la canalizaci\u00f3n de implementaci\u00f3n est\u00e1 configurada para proporcionar el nombre del archivo de estado de forma din\u00e1mica? Variables Si la infraestructura ser\u00e1 diferente seg\u00fan el entorno, los par\u00e1metros espec\u00edficos del entorno se proporcionan a trav\u00e9s de un archivo .tfvars. Todas las variables tienen informaci\u00f3n de tipo. Todas las variables tienen una descripci\u00f3n que indica el prop\u00f3sito de la variable y su uso. Los valores predeterminados no se proporcionan para las variables que debe proporcionar un usuario. Testing \u00bfExisten pruebas unitarias y de integraci\u00f3n que cubran el c\u00f3digo de Terraform? Nomenclatura y estructura de c\u00f3digo \u00bfLas definiciones de recursos y las fuentes de datos se utilizan correctamente en los scripts de Terraform? resource: Indica a Terraform que la configuraci\u00f3n actual se encarga de gestionar el ciclo de vida del objeto data: indica a Terraform que solo desea obtener una referencia al objeto existente, pero no desea administrarlo como parte de esta configuraci\u00f3n Los nombres de los recursos comienzan con el nombre del proveedor que los contiene seguido de un gui\u00f3n bajo. \u00bfLa funci\u00f3n try solo se usa con referencias de atributos simples y funciones de conversi\u00f3n de tipos? El uso excesivo de la funci\u00f3n para suprimir errores conducir\u00e1 a una configuraci\u00f3n que es dif\u00edcil de entender y mantener. \u00bfLas funciones de conversi\u00f3n de tipos expl\u00edcitas utilizadas para normalizar los tipos solo se devuelven en las salidas del m\u00f3dulo? Las conversiones de tipos expl\u00edcitas rara vez son necesarias en Terraform porque convertir\u00e1 los tipos autom\u00e1ticamente cuando sea necesario. \u00bfLa propiedad Sensitive en el esquema se establece en true para los campos que contienen informaci\u00f3n confidencial? Recomendaciones generales Intente evitar anidar la subconfiguraci\u00f3n dentro de los recursos. Cree una secci\u00f3n de recursos separada para los recursos, aunque se puedan declarar como subelementos de un recurso. Nunca codifique ning\u00fan valor en la configuraci\u00f3n. Declararlos en la secci\u00f3n locals si se necesita una variable varias veces como un valor est\u00e1tico y son internos a la configuraci\u00f3n. Los nombres de los recursos creados en Azure no deben estar codificados ni ser est\u00e1ticos. Estos nombres deben ser din\u00e1micos y proporcionados por el usuario mediante un bloque de variables . Esto es especialmente \u00fatil en las pruebas unitarias cuando se ejecutan varias pruebas en paralelo para intentar crear recursos en Azure pero necesitan nombres diferentes. Es una buena pr\u00e1ctica generar el ID de los recursos creados en Azure desde la configuraci\u00f3n. Esto es especialmente \u00fatil cuando se agregan bloques din\u00e1micos para subelementos/elementos secundarios al recurso principal. Utilice el bloque required_providers para establecer la dependencia de los proveedores junto con la versi\u00f3n predeterminada. Utilice el bloque terraform para declarar la dependencia del proveedor con la versi\u00f3n exacta y tambi\u00e9n la versi\u00f3n CLI de terraform necesaria para la configuraci\u00f3n. Valide los valores de las variables proporcionados seg\u00fan el uso y el tipo de variable. La validaci\u00f3n se puede hacer a las variables agregando un bloque validation . Valide que los SKU de los componentes sean los correctos.","title":"Terraform Code Reviews"},{"location":"revisiones%20de%20codigo/recetas/terraform/#terraform-code-reviews","text":"","title":"Terraform Code Reviews"},{"location":"revisiones%20de%20codigo/recetas/terraform/#guia-de-estilo","text":"Terraform style guide Los proyectos deben verificar los scripts de Terraform con herramientas automatizadas.","title":"Gu\u00eda de estilo"},{"location":"revisiones%20de%20codigo/recetas/terraform/#analisis-de-codigo-linting","text":"","title":"An\u00e1lisis de c\u00f3digo / Linting"},{"location":"revisiones%20de%20codigo/recetas/terraform/#tflint","text":"TFLint es un linter de Terraform centrado en posibles errores, mejores pr\u00e1cticas, etc. Una vez que TFLint est\u00e1 instalado en el entorno, se puede invocar mediante la extensi\u00f3n de terraform de VS Code.","title":"TFLint"},{"location":"revisiones%20de%20codigo/recetas/terraform/#vs-code-extensions","text":"","title":"VS Code Extensions"},{"location":"revisiones%20de%20codigo/recetas/terraform/#extension-terraform","text":"Esta extensi\u00f3n proporciona capacidades de resaltado, linting, formateo y validaci\u00f3n de sintaxis.","title":"Extensi\u00f3n Terraform"},{"location":"revisiones%20de%20codigo/recetas/terraform/#extension-azure-terraform","text":"Esta extensi\u00f3n proporciona compatibilidad con comandos de Terraform, visualizaci\u00f3n de gr\u00e1ficos de recursos e integraci\u00f3n de CloudShell dentro de VS Code.","title":"Extensi\u00f3n Azure Terraform"},{"location":"revisiones%20de%20codigo/recetas/terraform/#validacion-de-compilacion","text":"El siguiente script de ejemplo se puede usar para instalar terraform y un linter que luego verifica el formato y los errores comunes. #! /bin/bash set -e SCRIPT_DIR = $( dirname \" $BASH_SOURCE \" ) cd \" $SCRIPT_DIR \" TF_VERSION = 0 .12.4 TF_LINT_VERSION = 0 .9.1 echo -e \"\\n\\n>>> Installing Terraform 0.12\" # Install terraform tooling for linting terraform wget -q https://releases.hashicorp.com/terraform/ ${ TF_VERSION } /terraform_ ${ TF_VERSION } _linux_amd64.zip -O /tmp/terraform.zip sudo unzip -q -o -d /usr/local/bin/ /tmp/terraform.zip echo \"\" echo -e \"\\n\\n>>> Install tflint (3rd party)\" wget -q https://github.com/wata727/tflint/releases/download/v ${ TF_LINT_VERSION } /tflint_linux_amd64.zip -O /tmp/tflint.zip sudo unzip -q -o -d /usr/local/bin/ /tmp/tflint.zip echo -e \"\\n\\n>>> Terraform version\" terraform -version echo -e \"\\n\\n>>> Terraform Format (if this fails use 'terraform fmt -recursive' command to resolve\" terraform fmt -recursive -diff -check echo -e \"\\n\\n>>> tflint\" tflint echo -e \"\\n\\n>>> Terraform init\" terraform init echo -e \"\\n\\n>>> Terraform validate\" terraform validate","title":"Validaci\u00f3n de compilaci\u00f3n"},{"location":"revisiones%20de%20codigo/recetas/terraform/#code-review-checklist","text":"Adem\u00e1s de la Checklist de Code Review (), tambi\u00e9n debe buscar estos elementos de revisi\u00f3n de c\u00f3digo espec\u00edficos de Terraform:","title":"Code Review Checklist"},{"location":"revisiones%20de%20codigo/recetas/terraform/#proveedores","text":"\u00bfTodos los proveedores utilizados en los scripts de terraform est\u00e1n versionados para evitar cambios importantes en el futuro?","title":"Proveedores"},{"location":"revisiones%20de%20codigo/recetas/terraform/#organizacion-del-repositorio","text":"\u00bfEl c\u00f3digo se dividi\u00f3 en m\u00f3dulos reutilizables? \u00bfLos m\u00f3dulos se dividen en archivos .tf separados cuando corresponde? El repositorio contiene un README.md que describe la arquitectura aprovisionada. Si el c\u00f3digo de Terraform se mezcla con el c\u00f3digo fuente de la aplicaci\u00f3n, \u00bfel c\u00f3digo de Terraform se a\u00edsla en una carpeta dedicada?","title":"Organizaci\u00f3n del repositorio"},{"location":"revisiones%20de%20codigo/recetas/terraform/#estado-de-terraform","text":"\u00bfEl proyecto Terraform est\u00e1 configurado con Azure Storage como back-end de estado remoto? \u00bfLa clave de la cuenta de almacenamiento de back-end de estado remoto almacen\u00f3 una ubicaci\u00f3n segura (por ejemplo, Azure Key Vault)? \u00bfEl proyecto est\u00e1 configurado para usar archivos de estado en funci\u00f3n del entorno y la canalizaci\u00f3n de implementaci\u00f3n est\u00e1 configurada para proporcionar el nombre del archivo de estado de forma din\u00e1mica?","title":"Estado de Terraform"},{"location":"revisiones%20de%20codigo/recetas/terraform/#variables","text":"Si la infraestructura ser\u00e1 diferente seg\u00fan el entorno, los par\u00e1metros espec\u00edficos del entorno se proporcionan a trav\u00e9s de un archivo .tfvars. Todas las variables tienen informaci\u00f3n de tipo. Todas las variables tienen una descripci\u00f3n que indica el prop\u00f3sito de la variable y su uso. Los valores predeterminados no se proporcionan para las variables que debe proporcionar un usuario.","title":"Variables"},{"location":"revisiones%20de%20codigo/recetas/terraform/#testing","text":"\u00bfExisten pruebas unitarias y de integraci\u00f3n que cubran el c\u00f3digo de Terraform?","title":"Testing"},{"location":"revisiones%20de%20codigo/recetas/terraform/#nomenclatura-y-estructura-de-codigo","text":"\u00bfLas definiciones de recursos y las fuentes de datos se utilizan correctamente en los scripts de Terraform? resource: Indica a Terraform que la configuraci\u00f3n actual se encarga de gestionar el ciclo de vida del objeto data: indica a Terraform que solo desea obtener una referencia al objeto existente, pero no desea administrarlo como parte de esta configuraci\u00f3n Los nombres de los recursos comienzan con el nombre del proveedor que los contiene seguido de un gui\u00f3n bajo. \u00bfLa funci\u00f3n try solo se usa con referencias de atributos simples y funciones de conversi\u00f3n de tipos? El uso excesivo de la funci\u00f3n para suprimir errores conducir\u00e1 a una configuraci\u00f3n que es dif\u00edcil de entender y mantener. \u00bfLas funciones de conversi\u00f3n de tipos expl\u00edcitas utilizadas para normalizar los tipos solo se devuelven en las salidas del m\u00f3dulo? Las conversiones de tipos expl\u00edcitas rara vez son necesarias en Terraform porque convertir\u00e1 los tipos autom\u00e1ticamente cuando sea necesario. \u00bfLa propiedad Sensitive en el esquema se establece en true para los campos que contienen informaci\u00f3n confidencial?","title":"Nomenclatura y estructura de c\u00f3digo"},{"location":"revisiones%20de%20codigo/recetas/terraform/#recomendaciones-generales","text":"Intente evitar anidar la subconfiguraci\u00f3n dentro de los recursos. Cree una secci\u00f3n de recursos separada para los recursos, aunque se puedan declarar como subelementos de un recurso. Nunca codifique ning\u00fan valor en la configuraci\u00f3n. Declararlos en la secci\u00f3n locals si se necesita una variable varias veces como un valor est\u00e1tico y son internos a la configuraci\u00f3n. Los nombres de los recursos creados en Azure no deben estar codificados ni ser est\u00e1ticos. Estos nombres deben ser din\u00e1micos y proporcionados por el usuario mediante un bloque de variables . Esto es especialmente \u00fatil en las pruebas unitarias cuando se ejecutan varias pruebas en paralelo para intentar crear recursos en Azure pero necesitan nombres diferentes. Es una buena pr\u00e1ctica generar el ID de los recursos creados en Azure desde la configuraci\u00f3n. Esto es especialmente \u00fatil cuando se agregan bloques din\u00e1micos para subelementos/elementos secundarios al recurso principal. Utilice el bloque required_providers para establecer la dependencia de los proveedores junto con la versi\u00f3n predeterminada. Utilice el bloque terraform para declarar la dependencia del proveedor con la versi\u00f3n exacta y tambi\u00e9n la versi\u00f3n CLI de terraform necesaria para la configuraci\u00f3n. Valide los valores de las variables proporcionados seg\u00fan el uso y el tipo de variable. La validaci\u00f3n se puede hacer a las variables agregando un bloque validation . Valide que los SKU de los componentes sean los correctos.","title":"Recomendaciones generales"}]}